#!/usr/bin/env python3
"""
Credit Rating Risk Dashboard
============================

Streamlit-based dashboard for Korean Airlines credit rating monitoring:
1. Enterprise Hazard Curves visualization
2. 90-day Risk Top N Table  
3. Slack Webhook alerts for high-risk situations
4. Real-time monitoring for investment & risk teams

Author: Korean Airlines Credit Rating Analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import requests
import json
from typing import Dict, List, Tuple, Optional, Any
import warnings
import os
import logging

# Set up logging for debugging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Import our models
try:
    import sys
    import os
    # Add parent directories to path
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)  # src/
    root_dir = os.path.dirname(parent_dir)     # project root
    
    # Add all necessary paths in specific order
    paths_to_add = [
        parent_dir,  # src/
        root_dir,    # project root
        os.path.join(parent_dir, 'data'),    # src/data/
        os.path.join(parent_dir, 'utils'),   # src/utils/
        os.path.join(parent_dir, 'models'),  # src/models/
        os.path.join(parent_dir, 'rag'),     # src/rag/
        os.path.join(root_dir, 'config')     # config/
    ]
    
    for path in paths_to_add:
        if path not in sys.path:
            sys.path.insert(0, path)
    
    print(f"üîß [DASHBOARD] Added {len(paths_to_add)} paths to Python path")
    
    # Import cache system (after path setup)
    try:
        from data.dart_data_cache import get_global_cache, DARTDataCache
        CACHE_AVAILABLE = True
        print("‚úÖ Cache system loaded successfully")
    except ImportError:
        try:
            from src.data.dart_data_cache import get_global_cache, DARTDataCache
            CACHE_AVAILABLE = True
            print("‚úÖ Cache system loaded from src.data path")
        except ImportError:
            CACHE_AVAILABLE = False
            print("‚ùå Cache system not available")
    
    # Try different import strategies
    try:
        from models.rating_risk_scorer import RatingRiskScorer, FirmProfile
        from models.enhanced_multistate_model import EnhancedMultiStateModel
        from models.backtest_framework import CreditRatingBacktester
    except ImportError:
        # Try absolute imports from src
        from src.models.rating_risk_scorer import RatingRiskScorer, FirmProfile
        from src.models.enhanced_multistate_model import EnhancedMultiStateModel
        from src.models.backtest_framework import CreditRatingBacktester
    
    MODEL_AVAILABLE = True
    print("‚úÖ Model modules loaded successfully")
    
except ImportError as e:
    print(f"‚ùå Model modules not available: {e}")
    print(f"Current working directory: {os.getcwd()}")
    print(f"Python path: {sys.path[:5]}")  # Show first 5 paths
    MODEL_AVAILABLE = False

# Configuration
RISK_THRESHOLD = 0.15  # 15% change probability threshold for alerts
SLACK_WEBHOOK_URL = None  # Set this to your Slack webhook URL

# OpenAI Configuration

# Import prompt manager
try:
    from config.prompts import get_prompt_manager
    PROMPT_MANAGER_AVAILABLE = True
    print("‚úÖ Prompt manager loaded successfully")
except ImportError:
    try:
        import sys
        sys.path.insert(0, os.path.join(root_dir, 'config'))
        from prompts import get_prompt_manager
        PROMPT_MANAGER_AVAILABLE = True
        print("‚úÖ Prompt manager loaded with explicit path")
    except ImportError:
        try:
            from config.prompts import get_prompt_manager
            PROMPT_MANAGER_AVAILABLE = True
            print("‚úÖ Prompt manager loaded from config.prompts")
        except ImportError:
            PROMPT_MANAGER_AVAILABLE = False
            print("‚ùå Prompt manager not available")

# Import RAG system
try:
    from src.rag.airline_industry_rag import AirlineIndustryRAG
    RAG_AVAILABLE = True
    print("‚úÖ RAG system loaded successfully")
except ImportError:
    try:
        from rag.airline_industry_rag import AirlineIndustryRAG
        RAG_AVAILABLE = True
        print("‚úÖ RAG system loaded from rag path")
    except ImportError:
        try:
            import sys
            sys.path.insert(0, os.path.join(parent_dir, 'rag'))
            from airline_industry_rag import AirlineIndustryRAG
            RAG_AVAILABLE = True
            print("‚úÖ RAG system loaded with explicit path")
        except ImportError:
            try:
                from src.rag.airline_industry_rag import AirlineIndustryRAG
                RAG_AVAILABLE = True
                print("‚úÖ RAG system loaded from src.rag")
            except ImportError:
                RAG_AVAILABLE = False
                print("‚ùå RAG system not available")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your_openai_api_key_here")

class CreditRatingDashboard:
    """
    Main dashboard class for credit rating monitoring
    """
    
    def __init__(self):
        """Initialize dashboard"""
        self.risk_scorer = None
        self.current_scores = None
        self.historical_data = None
        
        # Initialize RAG system
        if RAG_AVAILABLE and OPENAI_API_KEY != "your_openai_api_key_here":
            try:
                self.rag_system = AirlineIndustryRAG(OPENAI_API_KEY)
                self.rag_available = True
                print("‚úÖ RAG system initialized successfully")
            except Exception as e:
                print(f"‚ùå RAG system initialization failed: {e}")
                self.rag_available = False
        else:
            self.rag_available = False
            if not RAG_AVAILABLE:
                print("‚ùå RAG system not available")
            if OPENAI_API_KEY == "your_openai_api_key_here":
                print("‚ùå OpenAI API key not set")
        
        # Initialize session state
        if 'last_update' not in st.session_state:
            st.session_state.last_update = datetime.now()
        if 'alert_history' not in st.session_state:
            st.session_state.alert_history = []
        if 'hazard_report' not in st.session_state:
            st.session_state.hazard_report = None
        if 'risk_table_report' not in st.session_state:
            st.session_state.risk_table_report = None
        if 'heatmap_report' not in st.session_state:
            st.session_state.heatmap_report = None
        if 'alerts_report' not in st.session_state:
            st.session_state.alerts_report = None
        if 'current_tab' not in st.session_state:
            st.session_state.current_tab = "üìà Hazard Curves"
        if 'hazard_companies_selection' not in st.session_state:
            st.session_state.hazard_companies_selection = None
        if 'table_companies_selection' not in st.session_state:
            st.session_state.table_companies_selection = None
        if 'heatmap_companies_selection' not in st.session_state:
            st.session_state.heatmap_companies_selection = None
        if 'alerts_threshold_value' not in st.session_state:
            st.session_state.alerts_threshold_value = None
        if 'models_loaded_status' not in st.session_state:
            st.session_state.models_loaded_status = False
        if 'rag_context' not in st.session_state:
            st.session_state.rag_context = None
        if 'rag_last_update' not in st.session_state:
            st.session_state.rag_last_update = None
    
    def load_models(self):
        """Load and initialize risk scoring models"""
        
        logger.info("[LOAD_MODELS] Starting model loading process...")
        
        if not MODEL_AVAILABLE:
            logger.error("[LOAD_MODELS] Models not available")
            st.error("Models not available")
            return False
        
        try:
            logger.info("[LOAD_MODELS] Creating spinner for model loading...")
            with st.spinner("üèãÔ∏è Loading risk scoring models..."):
                logger.info("[LOAD_MODELS] Initializing RatingRiskScorer...")
                
                # ÏïàÏ†ÑÌïú Î™®Îç∏ Î°úÎî© (Ï∫êÏãú Ïö∞ÏÑ†, ÌïÑÏöîÏãúÏóêÎßå DART Îç∞Ïù¥ÌÑ∞ ÏàòÏßë)
                try:
                    # ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ïÏùÑ ÏúÑÌïú ÏãúÎèÑ ÌöüÏàò Ï†úÌïú
                    max_retries = 2
                    retry_count = 0
                    
                    while retry_count < max_retries:
                        try:
                            logger.info(f"[LOAD_MODELS] Attempt {retry_count + 1} to create RatingRiskScorer...")
                            
                            # Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Î™®ÎãàÌÑ∞ÎßÅ
                            import psutil
                            process = psutil.Process()
                            memory_before = process.memory_info().rss / 1024 / 1024  # MB
                            logger.info(f"[LOAD_MODELS] Memory usage before: {memory_before:.2f} MB")
                            
                            # RatingRiskScorer ÏÉùÏÑ± (ÌÉÄÏûÑÏïÑÏõÉ Î≥¥Ìò∏)
                            import signal
                            import threading
                            import time
                            
                            # ÌÉÄÏûÑÏïÑÏõÉ ÏÑ§Ï†ï (5Î∂Ñ)
                            timeout_seconds = 300
                            result = [None]
                            exception = [None]
                            
                            def create_scorer():
                                try:
                                    result[0] = RatingRiskScorer(use_financial_data=True)
                                except Exception as e:
                                    exception[0] = e
                            
                            # Î≥ÑÎèÑ Ïä§Î†àÎìúÏóêÏÑú Ïã§Ìñâ
                            thread = threading.Thread(target=create_scorer)
                            thread.daemon = True
                            thread.start()
                            
                            # ÌÉÄÏûÑÏïÑÏõÉ ÎåÄÍ∏∞
                            thread.join(timeout_seconds)
                            
                            if thread.is_alive():
                                logger.error(f"[LOAD_MODELS] Timeout after {timeout_seconds} seconds")
                                st.error(f"‚ùå Model loading timed out after {timeout_seconds} seconds")
                                return False
                            
                            if exception[0] is not None:
                                raise exception[0]
                            
                            self.risk_scorer = result[0]
                            
                            # Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ ÌôïÏù∏
                            memory_after = process.memory_info().rss / 1024 / 1024  # MB
                            logger.info(f"[LOAD_MODELS] Memory usage after: {memory_after:.2f} MB")
                            logger.info(f"[LOAD_MODELS] Memory increase: {memory_after - memory_before:.2f} MB")
                            
                            logger.info("[LOAD_MODELS] RatingRiskScorer created successfully")
                            break
                            
                        except Exception as e:
                            retry_count += 1
                            logger.warning(f"[LOAD_MODELS] Attempt {retry_count} failed: {e}")
                            
                            if retry_count >= max_retries:
                                logger.error(f"[LOAD_MODELS] All {max_retries} attempts failed")
                                raise e
                            
                            # Ïû¨ÏãúÎèÑ Ï†Ñ Ïû†Ïãú ÎåÄÍ∏∞
                            time.sleep(2)
                    
                except Exception as model_error:
                    logger.error(f"[LOAD_MODELS] Model loading failed: {model_error}")
                    st.warning(f"‚ö†Ô∏è Model loading failed: {model_error}")
                    st.info("üí° Using sample data for demonstration")
                    return False
                    
            logger.info("[LOAD_MODELS] Model loading completed successfully")
            st.success("‚úÖ Models loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"[LOAD_MODELS] Error loading models: {e}")
            st.error(f"‚ùå Error loading models: {e}")
            st.info("üí° Using sample data for demonstration")
            return False
    
    def get_sample_firms(self) -> List[FirmProfile]:
        """Get sample Korean airline firms with current financial data"""
        
        return [
            FirmProfile(
                company_name="ÎåÄÌïúÌï≠Í≥µ",
                current_rating="A",
                debt_to_assets=0.65,
                current_ratio=0.8,
                roa=0.02,
                roe=0.05,
                operating_margin=0.03,
                equity_ratio=0.35,
                asset_turnover=0.6,
                interest_coverage=2.5,
                quick_ratio=0.7,
                working_capital_ratio=0.1
            ),
            FirmProfile(
                company_name="ÏïÑÏãúÏïÑÎÇòÌï≠Í≥µ",
                current_rating="B",
                debt_to_assets=0.85,
                current_ratio=0.6,
                roa=-0.02,
                roe=-0.05,
                operating_margin=-0.01,
                equity_ratio=0.15,
                asset_turnover=0.5,
                interest_coverage=1.2,
                quick_ratio=0.5,
                working_capital_ratio=-0.05
            ),
            FirmProfile(
                company_name="Ï†úÏ£ºÌï≠Í≥µ",
                current_rating="BBB",
                debt_to_assets=0.55,
                current_ratio=1.1,
                roa=0.04,
                roe=0.08,
                operating_margin=0.06,
                equity_ratio=0.45,
                asset_turnover=0.8,
                interest_coverage=3.5,
                quick_ratio=1.0,
                working_capital_ratio=0.15
            ),
            FirmProfile(
                company_name="Ìã∞Ïõ®Ïù¥Ìï≠Í≥µ",
                current_rating="BB",
                debt_to_assets=0.60,
                current_ratio=0.9,
                roa=0.01,
                roe=0.03,
                operating_margin=0.02,
                equity_ratio=0.40,
                asset_turnover=0.7,
                interest_coverage=2.0,
                quick_ratio=0.8,
                working_capital_ratio=0.05
            ),
            FirmProfile(
                company_name="ÏóêÏñ¥Î∂ÄÏÇ∞",
                current_rating="B",
                debt_to_assets=0.70,
                current_ratio=0.7,
                roa=-0.01,
                roe=0.01,
                operating_margin=0.01,
                equity_ratio=0.30,
                asset_turnover=0.6,
                interest_coverage=1.8,
                quick_ratio=0.6,
                working_capital_ratio=0.02
            )
        ]
    
    def calculate_current_risks(self, firms: List[FirmProfile]) -> pd.DataFrame:
        """Calculate current risk scores for all firms"""
        
        if self.risk_scorer is None:
            return pd.DataFrame()
        
        risk_data = []
        
        for firm in firms:
            try:
                risk_assessment = self.risk_scorer.score_firm(firm, horizon=90)
                
                risk_data.append({
                    'company_name': firm.company_name,
                    'current_rating': firm.current_rating,
                    'overall_risk': risk_assessment['overall_change_probability'],
                    'upgrade_prob': risk_assessment['upgrade_probability'],
                    'downgrade_prob': risk_assessment['downgrade_probability'],
                    'default_prob': risk_assessment['default_probability'],
                    'risk_classification': risk_assessment['risk_classification'],
                    'last_updated': datetime.now().strftime("%Y-%m-%d %H:%M")
                })
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Error calculating risk for {firm.company_name}: {e}")
                continue
        
        return pd.DataFrame(risk_data)
    
    def generate_gpt4_report(self, prompt: str, context_data: str) -> str:
        """Generate comprehensive report using GPT-4-Turbo for bank loan officers"""
        
        if not OPENAI_AVAILABLE:
            return "‚ùå OpenAI Ìå®ÌÇ§ÏßÄÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. `pip install openai`Î°ú ÏÑ§ÏπòÌï¥Ï£ºÏÑ∏Ïöî."
        
        # RAG Ïª®ÌÖçÏä§Ìä∏ Ï∂îÍ∞Ä
        rag_context = ""
        if self.rag_available:
            try:
                rag_context = self.rag_system.get_prompt_context()
            except Exception as e:
                st.warning(f"‚ö†Ô∏è RAG Ïª®ÌÖçÏä§Ìä∏ Î°úÎìú Ïò§Î•ò: {e}")
        
        # ÌîÑÎ°¨ÌîÑÌä∏ Îß§ÎãàÏ†Ä ÏÇ¨Ïö©
        if PROMPT_MANAGER_AVAILABLE:
            try:
                prompt_manager = get_prompt_manager()
                system_prompts = prompt_manager.get_system_prompt("comprehensive_report")
                system_prompt = {"role": "system", "content": system_prompts.get("comprehensive_report", "ÎãπÏã†ÏùÄ ÌïúÍµ≠ ÏãúÏ§ëÏùÄÌñâÏùò Í∏∞ÏóÖÍ∏àÏúµ ÎåÄÏ∂úÏã¨ÏÇ¨ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.")}
                user_prompt = prompt_manager.get_user_prompt("comprehensive_report", 
                                                           prompt=prompt, 
                                                           context_data=context_data)
                
                # RAG Ïª®ÌÖçÏä§Ìä∏Î•º ÏÇ¨Ïö©Ïûê ÌîÑÎ°¨ÌîÑÌä∏Ïóê Ï∂îÍ∞Ä
                if rag_context:
                    user_prompt += f"\n\n{rag_context}"
                    
            except Exception as e:
                st.warning(f"‚ö†Ô∏è ÌîÑÎ°¨ÌîÑÌä∏ Îß§ÎãàÏ†Ä Ïò§Î•ò, Í∏∞Î≥∏ ÌîÑÎ°¨ÌîÑÌä∏ ÏÇ¨Ïö©: {e}")
                # Í∏∞Î≥∏ ÌîÑÎ°¨ÌîÑÌä∏Î°ú Ìè¥Î∞±
                system_prompt = {"role": "system", "content": "ÎãπÏã†ÏùÄ ÌïúÍµ≠ ÏãúÏ§ëÏùÄÌñâÏùò Í∏∞ÏóÖÍ∏àÏúµ ÎåÄÏ∂úÏã¨ÏÇ¨ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§."}
                user_prompt = f"Î∂ÑÏÑù ÏöîÏ≤≠: {prompt}\n\nÎåÄÏãúÎ≥¥Îìú Îç∞Ïù¥ÌÑ∞: {context_data}"
                if rag_context:
                    user_prompt += f"\n\n{rag_context}"
        else:
            # Í∏∞Î≥∏ ÌîÑÎ°¨ÌîÑÌä∏ ÏÇ¨Ïö©
            system_prompt = {"role": "system", "content": "ÎãπÏã†ÏùÄ ÌïúÍµ≠ ÏãúÏ§ëÏùÄÌñâÏùò Í∏∞ÏóÖÍ∏àÏúµ ÎåÄÏ∂úÏã¨ÏÇ¨ Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§."}
            user_prompt = f"Î∂ÑÏÑù ÏöîÏ≤≠: {prompt}\n\nÎåÄÏãúÎ≥¥Îìú Îç∞Ïù¥ÌÑ∞: {context_data}"
            if rag_context:
                user_prompt += f"\n\n{rag_context}"
        
        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            response = client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[system_prompt, {"role": "user", "content": user_prompt}],
                max_tokens=4096,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"‚ùå Î†àÌè¨Ìä∏ ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}\n\nüí° OpenAI API ÌÇ§Í∞Ä Ïò¨Î∞îÎ•∏ÏßÄ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî."
    
    def generate_comprehensive_report(self, risk_df: pd.DataFrame, firms: List) -> str:
        """Generate comprehensive integrated report combining analysis and actionable recommendations"""
        
        if not OPENAI_AVAILABLE:
            return "‚ùå OpenAI Ìå®ÌÇ§ÏßÄÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. `pip install openai`Î°ú ÏÑ§ÏπòÌï¥Ï£ºÏÑ∏Ïöî."
        
        # Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù
        high_risk_firms = risk_df[risk_df['overall_risk'] > RISK_THRESHOLD]
        avg_risk = risk_df['overall_risk'].mean()
        max_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmax()]
        min_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmin()]
        
        # ÏóÖÍ∑∏Î†àÏù¥Îìú/Îã§Ïö¥Í∑∏Î†àÏù¥Îìú Í∞ÄÎä•ÏÑ± Î∂ÑÏÑù
        upgrade_candidates = risk_df[risk_df['upgrade_prob'] > 0.1].sort_values('upgrade_prob', ascending=False)
        downgrade_risks = risk_df[risk_df['downgrade_prob'] > 0.05].sort_values('downgrade_prob', ascending=False)
        
        # ÏµúÍ∑º ÏïåÎ¶º Ïù¥Î†•
        recent_alerts = st.session_state.get('alert_history', [])[-3:]
        
        # Î∂ÑÏÑù ÎåÄÏÉÅ Í∏∞ÏóÖÎ™Ö Î¶¨Ïä§Ìä∏ ÏÉùÏÑ±
        firm_names = [firm.company_name for firm in firms]
        
        # Í∞Å Í∏∞ÏóÖÏùò ÏÉÅÏÑ∏ Ïû¨Î¨¥Ï†ïÎ≥¥ ÏÉùÏÑ±
        detailed_firm_info = []
        for firm in firms:
            firm_detail = f"""
‚óà **{firm.company_name}** (ÌòÑÏû¨Îì±Í∏â: {firm.current_rating})
   Ïû¨Î¨¥Í±¥Ï†ÑÏÑ± ÏßÄÌëú:
   - Î∂ÄÏ±ÑÎπÑÏú®: {firm.debt_to_assets:.1%} | Ïú†ÎèôÎπÑÏú®: {firm.current_ratio:.2f} | ÎãπÏ¢åÎπÑÏú®: {firm.quick_ratio:.2f}
   - ROA: {firm.roa:.1%} | ROE: {firm.roe:.1%} | ÏòÅÏóÖÏù¥ÏùµÎ•†: {firm.operating_margin:.1%}
   - ÏûêÍ∏∞ÏûêÎ≥∏ÎπÑÏú®: {firm.equity_ratio:.1%} | ÏûêÏÇ∞ÌöåÏ†ÑÏú®: {firm.asset_turnover:.2f}
   - Ïù¥ÏûêÎ≥¥ÏÉÅÎ∞∞Ïú®: {firm.interest_coverage:.1f} | Ïö¥Ï†ÑÏûêÎ≥∏ÎπÑÏú®: {firm.working_capital_ratio:.1%}
            """
            
            # Ìï¥Îãπ Í∏∞ÏóÖÏùò ÏúÑÌóòÎèÑ Ï†ïÎ≥¥ Ï∂îÍ∞Ä
            firm_risk = risk_df[risk_df['company_name'] == firm.company_name]
            if not firm_risk.empty:
                risk_row = firm_risk.iloc[0]
                firm_detail += f"""
   Ïã†Ïö©ÏúÑÌóò ÌòÑÌô©:
   - 90Ïùº Ï†ÑÏ≤¥Î≥ÄÎèôÏúÑÌóò: {risk_row['overall_risk']:.3%}
   - Îì±Í∏âÏÉÅÏäπ ÌôïÎ•†: {risk_row['upgrade_prob']:.3%} | Îì±Í∏âÌïòÎùΩ ÌôïÎ•†: {risk_row['downgrade_prob']:.3%}
   - Î∂ÄÎèÑÎ∞úÏÉù ÌôïÎ•†: {risk_row['default_prob']:.3%} | ÏúÑÌóòÎ∂ÑÎ•ò: {risk_row['risk_classification']}
                """
            detailed_firm_info.append(firm_detail)
        
        # RAG Ïª®ÌÖçÏä§Ìä∏ Ï∂îÍ∞Ä
        rag_context = ""
        if self.rag_available:
            try:
                rag_context = self.rag_system.get_prompt_context()
            except Exception as e:
                st.warning(f"‚ö†Ô∏è RAG Ïª®ÌÖçÏä§Ìä∏ Î°úÎìú Ïò§Î•ò: {e}")
        
        # ÌîÑÎ°¨ÌîÑÌä∏ Îß§ÎãàÏ†Ä ÏÇ¨Ïö©
        if PROMPT_MANAGER_AVAILABLE:
            try:
                prompt_manager = get_prompt_manager()
                system_prompts = prompt_manager.get_system_prompt("comprehensive_report")
                system_prompt = {"role": "system", "content": system_prompts.get("comprehensive_report", "ÎãπÏã†ÏùÄ ÌïúÍµ≠ ÏãúÏ§ëÏùÄÌñâÏùò Í∏∞ÏóÖÍ∏àÏúµÌåÄÏû•ÏûÖÎãàÎã§.")}
                user_prompt = prompt_manager.get_user_prompt("comprehensive_report",
                    company_count=len(risk_df),
                    company_names=', '.join(firm_names),
                    current_date=datetime.now().strftime('%YÎÖÑ %mÏõî %dÏùº'),
                    avg_risk=avg_risk,
                    high_risk_count=len(high_risk_firms),
                    risk_threshold=RISK_THRESHOLD,
                    max_risk_company=max_risk_firm['company_name'],
                    max_risk_value=max_risk_firm['overall_risk'],
                    min_risk_company=min_risk_firm['company_name'],
                    min_risk_value=min_risk_firm['overall_risk'],
                    risk_std=risk_df['overall_risk'].std(),
                    detailed_firm_info=''.join(detailed_firm_info),
                    upgrade_candidates_info=upgrade_candidates[['company_name', 'upgrade_prob', 'current_rating']].to_string() if not upgrade_candidates.empty else "ÌòÑÏû¨ Îì±Í∏â Í∞úÏÑ†Ïù¥ ÏòàÏÉÅÎêòÎäî Í∏∞ÏóÖ ÏóÜÏùå",
                    downgrade_risks_info=downgrade_risks[['company_name', 'downgrade_prob', 'current_rating']].to_string() if not downgrade_risks.empty else "ÌòÑÏû¨ Îì±Í∏â ÏïÖÌôîÍ∞Ä Ïö∞Î†§ÎêòÎäî Í∏∞ÏóÖ ÏóÜÏùå",
                    risk_q25=risk_df['overall_risk'].quantile(0.25),
                    risk_q50=risk_df['overall_risk'].quantile(0.5),
                    risk_q75=risk_df['overall_risk'].quantile(0.75),
                    recent_alerts_info=f"ÏµúÍ∑º {len(recent_alerts)}Í±¥Ïùò Í≥†ÏúÑÌóò ÏïåÎ¶º Î∞úÏÉù - ÏãúÏä§ÌÖú ÌôúÏÑ± Î™®ÎãàÌÑ∞ÎßÅ Ï§ë" if recent_alerts else "ÏµúÍ∑º ÏïåÎ¶º ÏóÜÏùå - Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏïàÏ†ïÏ†Å Ïö¥ÏòÅ"
                )
                
                # RAG Ïª®ÌÖçÏä§Ìä∏Î•º ÏÇ¨Ïö©Ïûê ÌîÑÎ°¨ÌîÑÌä∏Ïóê Ï∂îÍ∞Ä
                if rag_context:
                    user_prompt += f"\n\n{rag_context}"
                    
            except Exception as e:
                st.warning(f"‚ö†Ô∏è ÌîÑÎ°¨ÌîÑÌä∏ Îß§ÎãàÏ†Ä Ïò§Î•ò, Í∏∞Î≥∏ ÌîÑÎ°¨ÌîÑÌä∏ ÏÇ¨Ïö©: {e}")
                # Í∏∞Î≥∏ ÌîÑÎ°¨ÌîÑÌä∏Î°ú Ìè¥Î∞±
                system_prompt = {"role": "system", "content": "ÎãπÏã†ÏùÄ ÌïúÍµ≠ ÏãúÏ§ëÏùÄÌñâÏùò Í∏∞ÏóÖÍ∏àÏúµÌåÄÏû•ÏûÖÎãàÎã§."}
                user_prompt = f"Ìï≠Í≥µÏóÖÍ≥Ñ Ïã†Ïö©ÏúÑÌóò Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏Î•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî. Îç∞Ïù¥ÌÑ∞: {risk_df.to_string()}"
                if rag_context:
                    user_prompt += f"\n\n{rag_context}"
        else:
            # Í∏∞Î≥∏ ÌîÑÎ°¨ÌîÑÌä∏ ÏÇ¨Ïö©
            system_prompt = {"role": "system", "content": "ÎãπÏã†ÏùÄ ÌïúÍµ≠ ÏãúÏ§ëÏùÄÌñâÏùò Í∏∞ÏóÖÍ∏àÏúµÌåÄÏû•ÏûÖÎãàÎã§."}
            user_prompt = f"Ìï≠Í≥µÏóÖÍ≥Ñ Ïã†Ïö©ÏúÑÌóò Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏Î•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî. Îç∞Ïù¥ÌÑ∞: {risk_df.to_string()}"
            if rag_context:
                user_prompt += f"\n\n{rag_context}"

        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            response = client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[system_prompt, {"role": "user", "content": user_prompt}],
                max_tokens=4096,  # ÌÜ†ÌÅ∞ Ï†úÌïú Î¨∏Ï†ú Ìï¥Í≤∞
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"‚ùå Ï¢ÖÌï©Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}\n\nüí° OpenAI API ÌÇ§Í∞Ä Ïò¨Î∞îÎ•∏ÏßÄ ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî."
    
    def generate_hazard_curves_report(self, firms: List[FirmProfile]) -> str:
        """Generate comprehensive hazard curves report for bank loan officers"""
        
        if self.risk_scorer is None:
            return "‚ùå Î™®Îç∏Ïù¥ Î°úÎìúÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Î®ºÏ†Ä Î™®Îç∏ÏùÑ Î°úÎìúÌï¥Ï£ºÏÑ∏Ïöî."
        
        # Ï†ÑÏ≤¥ ÌôîÎ©¥ ÌëúÏãú Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
        risk_data = []
        horizons = [30, 60, 90, 120, 180, 270, 365]
        
        for firm in firms:
            # Í∞Å Í∏∞ÏóÖÏùò Ïû¨Î¨¥Ï†ïÎ≥¥
            firm_info = {
                'company': firm.company_name,
                'current_rating': firm.current_rating,
                'debt_to_assets': firm.debt_to_assets,
                'current_ratio': firm.current_ratio,
                'roa': firm.roa,
                'roe': firm.roe,
                'operating_margin': firm.operating_margin,
                'equity_ratio': firm.equity_ratio,
                'asset_turnover': firm.asset_turnover,
                'interest_coverage': firm.interest_coverage,
                'quick_ratio': firm.quick_ratio,
                'working_capital_ratio': firm.working_capital_ratio
            }
            
            # ÏãúÍ≥ÑÏó¥ ÏúÑÌóòÎèÑ Îç∞Ïù¥ÌÑ∞
            horizon_risks = []
            for horizon in horizons:
                try:
                    risk = self.risk_scorer.score_firm(firm, horizon=horizon)
                    horizon_risks.append({
                        'horizon': horizon,
                        'overall_risk': risk['overall_change_probability'],
                        'upgrade_prob': risk['upgrade_probability'],
                        'downgrade_prob': risk['downgrade_probability'],
                        'default_prob': risk['default_probability'],
                        'risk_classification': risk['risk_classification']
                    })
                except Exception as e:
                    continue
            
            firm_info['horizon_risks'] = horizon_risks
            risk_data.append(firm_info)
        
        # Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÌÜµÍ≥Ñ
        all_90d_risks = []
        all_365d_risks = []
        
        for firm_data in risk_data:
            for risk in firm_data['horizon_risks']:
                if risk['horizon'] == 90:
                    all_90d_risks.append(risk['overall_risk'])
                elif risk['horizon'] == 365:
                    all_365d_risks.append(risk['overall_risk'])
        
        # ÎåÄÏãúÎ≥¥Îìú ÌôîÎ©¥ ÌëúÏãú Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤¥ Ï†ïÎ¶¨
        context = f"""
=== ÎåÄÏ∂úÏã¨ÏÇ¨Ïö© Hazard Curves Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞ ===

ÏÑ†ÌÉù Î∂ÑÏÑù ÎåÄÏÉÅ: {len(firms)}Í∞ú Ìï≠Í≥µÏÇ¨ ({', '.join([f.company_name for f in firms])})
Î∂ÑÏÑù ÏãúÍ≥Ñ: 30Ïùº, 60Ïùº, 90Ïùº, 120Ïùº, 180Ïùº, 270Ïùº, 365Ïùº

=== Í∞Å Ìï≠Í≥µÏÇ¨Î≥Ñ ÏÉÅÏÑ∏ Ï†ïÎ≥¥ ===
"""
        
        for firm_data in risk_data:
            context += f"""
‚óà {firm_data['company']} (ÌòÑÏû¨Îì±Í∏â: {firm_data['current_rating']})
  [Ïû¨Î¨¥ÏßÄÌëú]
  - Î∂ÄÏ±ÑÎπÑÏú®: {firm_data['debt_to_assets']:.1%}
  - Ïú†ÎèôÎπÑÏú®: {firm_data['current_ratio']:.2f}
  - ROA: {firm_data['roa']:.1%}
  - ROE: {firm_data['roe']:.1%}
  - ÏòÅÏóÖÏù¥ÏùµÎ•†: {firm_data['operating_margin']:.1%}
  - ÏûêÍ∏∞ÏûêÎ≥∏ÎπÑÏú®: {firm_data['equity_ratio']:.1%}
  - ÏûêÏÇ∞ÌöåÏ†ÑÏú®: {firm_data['asset_turnover']:.2f}
  - Ïù¥ÏûêÎ≥¥ÏÉÅÎ∞∞Ïú®: {firm_data['interest_coverage']:.1f}
  - ÎãπÏ¢åÎπÑÏú®: {firm_data['quick_ratio']:.2f}
  - Ïö¥Ï†ÑÏûêÎ≥∏ÎπÑÏú®: {firm_data['working_capital_ratio']:.1%}
  
  [ÏãúÍ≥ÑÏó¥ Ïã†Ïö©ÏúÑÌóò Ï†ÑÎßù]"""
            
            for risk in firm_data['horizon_risks']:
                context += f"""
  - {risk['horizon']:3d}Ïùº ÌõÑ: Ï†ÑÏ≤¥Î≥ÄÎèô {risk['overall_risk']:.2%}, Îì±Í∏âÏÉÅÏäπ {risk['upgrade_prob']:.2%}, Îì±Í∏âÌïòÎùΩ {risk['downgrade_prob']:.2%}, Î∂ÄÎèÑÏúÑÌóò {risk['default_prob']:.3%} ({risk['risk_classification']})"""
        
        context += f"""

=== Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏúÑÌóò ÏßëÍ≥Ñ ===
- 90Ïùº ÌèâÍ∑†ÏúÑÌóòÎèÑ: {np.mean(all_90d_risks):.2%}
- 90Ïùº ÏµúÎåÄÏúÑÌóòÎèÑ: {np.max(all_90d_risks):.2%}
- 90Ïùº ÏµúÏÜåÏúÑÌóòÎèÑ: {np.min(all_90d_risks):.2%}
- 365Ïùº ÌèâÍ∑†ÏúÑÌóòÎèÑ: {np.mean(all_365d_risks):.2%}
- 365Ïùº ÏµúÎåÄÏúÑÌóòÎèÑ: {np.max(all_365d_risks):.2%}
- 365Ïùº ÏµúÏÜåÏúÑÌóòÎèÑ: {np.min(all_365d_risks):.2%}

=== Ï∞®Ìä∏ Ìï¥ÏÑù Í∞ÄÏù¥Îìú (ÎåÄÏãúÎ≥¥Îìú ÌôîÎ©¥ Í∏∞Ï§Ä) ===
- Overall Risk: 90Ïùº ÎÇ¥ Ïã†Ïö©Îì±Í∏â Î≥ÄÎèô ÌôïÎ•† (ÎåÄÏ∂úÏã¨ÏÇ¨ ÌïµÏã¨ÏßÄÌëú)
- Upgrade Probability: Îì±Í∏â Í∞úÏÑ† Í∞ÄÎä•ÏÑ± (Í∏çÏ†ïÏ†Å Ïã†Ìò∏)
- Downgrade Probability: Îì±Í∏â ÏïÖÌôî ÏúÑÌóò (Ïó¨Ïã† Ï£ºÏùòÏßÄÌëú)
- Default Risk: Î∂ÄÎèÑ Î∞úÏÉù Í∞ÄÎä•ÏÑ± (Ïó¨Ïã†ÏÜêÏã§ ÏßÅÍ≤∞)
"""
        
        prompt = """ÎåÄÏãúÎ≥¥ÎìúÏùò Hazard Curves ÌÉ≠ÏóêÏÑú ÌëúÏãúÎêòÎäî ÏãúÍ≥ÑÏó¥ Ïã†Ïö©ÏúÑÌóò Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Î∞òÏúºÎ°ú, 
        ÏùÄÌñâ ÎåÄÏ∂úÏã¨ÏÇ¨ Î∞è Ïó¨Ïã†Í¥ÄÎ¶¨ Í¥ÄÏ†êÏóêÏÑú Îã§Ïùå ÏÇ¨Ìï≠ÏùÑ ÏÉÅÏÑ∏ Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî:
        1) Í∞Å Ìï≠Í≥µÏÇ¨Î≥Ñ ÏãúÍ∞ÑÎåÄÎ≥Ñ Ïã†Ïö©ÏúÑÌóò Í∂§Ï†Å Î∂ÑÏÑù Î∞è Ïó¨Ïã†Ïã¨ÏÇ¨ Îì±Í∏â ÌåêÏ†ï
        2) Ïû¨Î¨¥ÏßÄÌëúÏôÄ ÏúÑÌóòÎèÑ Î≥ÄÌôîÏùò ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Î∂ÑÏÑù 
        3) Îã®Í∏∞(30-90Ïùº) vs Ïû•Í∏∞(270-365Ïùº) ÏúÑÌóòÌå®ÌÑ¥ Ï∞®Ïù¥Ï†ê Î∞è ÎåÄÏ∂úÎßåÍ∏∞ ÏÑ§Ï†ï Í∂åÍ≥†
        4) Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ Í¥ÄÏ†êÏóêÏÑúÏùò Ìï≠Í≥µÏóÖÍ≥Ñ Ïó¨Ïã† ÏßëÏ§ëÎèÑ Î¶¨Ïä§ÌÅ¨ ÌèâÍ∞Ä"""
        
        return self.generate_gpt4_report(prompt, context)
    
    def generate_risk_table_report(self, risk_df: pd.DataFrame) -> str:
        """Generate comprehensive risk table report for bank loan officers"""
        
        if risk_df.empty:
            return "‚ùå Î∂ÑÏÑùÌï† Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§."
        
        # ÏúÑÌóòÎèÑ ÏàúÏúºÎ°ú Ï†ïÎ†¨ (ÎåÄÏãúÎ≥¥ÎìúÏôÄ ÎèôÏùº)
        sorted_df = risk_df.sort_values('overall_risk', ascending=False)
        
        # ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
        avg_risk = sorted_df['overall_risk'].mean()
        max_risk = sorted_df['overall_risk'].max()
        min_risk = sorted_df['overall_risk'].min()
        std_risk = sorted_df['overall_risk'].std()
        
        # ÏûÑÍ≥ÑÍ∞í Ï†ïÎ≥¥
        high_risk_count = len(sorted_df[sorted_df['overall_risk'] > RISK_THRESHOLD])
        warning_risk_count = len(sorted_df[(sorted_df['overall_risk'] >= RISK_THRESHOLD * 0.7) & 
                                          (sorted_df['overall_risk'] <= RISK_THRESHOLD)])
        
        # ÎåÄÏãúÎ≥¥Îìú ÌôîÎ©¥ ÌëúÏãú Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤¥ Ï†ïÎ¶¨
        context = f"""
=== ÎåÄÏ∂úÏã¨ÏÇ¨Ïö© 90Ïùº ÏúÑÌóòÎèÑ ÌÖåÏù¥Î∏î Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞ ===

Î∂ÑÏÑù ÎåÄÏÉÅ: {len(risk_df)}Í∞ú Ìï≠Í≥µÏÇ¨
Î∂ÑÏÑù Í∏∞Ï§Ä: 90Ïùº Ïã†Ïö©Îì±Í∏â Î≥ÄÎèô ÌôïÎ•†
ÌòÑÏû¨ ÏïåÎ¶º ÏûÑÍ≥ÑÍ∞í: {RISK_THRESHOLD:.1%}
Îç∞Ïù¥ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏: {sorted_df['last_updated'].iloc[0] if 'last_updated' in sorted_df.columns else 'Ïã§ÏãúÍ∞Ñ'}

=== Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏúÑÌóòÎèÑ ÌÜµÍ≥Ñ ===
- ÌèâÍ∑† ÏúÑÌóòÎèÑ: {avg_risk:.2%}
- ÏµúÎåÄ ÏúÑÌóòÎèÑ: {max_risk:.2%} 
- ÏµúÏÜå ÏúÑÌóòÎèÑ: {min_risk:.2%}
- ÌëúÏ§ÄÌé∏Ï∞®: {std_risk:.2%}
- Í≥†ÏúÑÌóò Í∏∞ÏóÖÏàò (>{RISK_THRESHOLD:.1%}): {high_risk_count}Í∞ú
- Ï£ºÏùò Í∏∞ÏóÖÏàò ({RISK_THRESHOLD*0.7:.1%}~{RISK_THRESHOLD:.1%}): {warning_risk_count}Í∞ú

=== ÏúÑÌóòÎèÑ ÏàúÏúÑÎ≥Ñ ÏÉÅÏÑ∏ Î∂ÑÏÑù (ÎåÄÏãúÎ≥¥Îìú ÌÖåÏù¥Î∏î Í∏∞Ï§Ä) ===
"""
        
        for rank, (idx, row) in enumerate(sorted_df.iterrows(), 1):
            # ÏúÑÌóòÎì±Í∏â Î∂ÑÎ•ò
            if row['overall_risk'] > RISK_THRESHOLD:
                risk_level = "üî¥ Í≥†ÏúÑÌóò"
            elif row['overall_risk'] > RISK_THRESHOLD * 0.7:
                risk_level = "üü° Ï£ºÏùò"
            else:
                risk_level = "üü¢ ÏïàÏ†Ñ"
                
            context += f"""
[{rank}ÏúÑ] {row['company_name']} ({risk_level})
  - ÌòÑÏû¨ Ïã†Ïö©Îì±Í∏â: {row['current_rating']}
  - Ï†ÑÏ≤¥ Î≥ÄÎèôÏúÑÌóò: {row['overall_risk']:.3%} 
  - Îì±Í∏â ÏÉÅÏäπÌôïÎ•†: {row['upgrade_prob']:.3%}
  - Îì±Í∏â ÌïòÎùΩÌôïÎ•†: {row['downgrade_prob']:.3%}
  - Î∂ÄÎèÑ ÏúÑÌóòÌôïÎ•†: {row['default_prob']:.3%}
  - ÏúÑÌóòÎèÑ Î∂ÑÎ•ò: {row['risk_classification']}
  - ÏóÖÎç∞Ïù¥Ìä∏: {row.get('last_updated', 'N/A')}
"""
        
        # Ï∂îÍ∞Ä Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞
        context += f"""

=== ÎåÄÏãúÎ≥¥Îìú Progress Bar Ìï¥ÏÑù ===
- Overall Risk: 90Ïùº ÎÇ¥ Ïã†Ïö©Îì±Í∏â Î≥ÄÎèô Í∞ÄÎä•ÏÑ± (0~50% Î≤îÏúÑ ÌëúÏãú)
- Upgrade ‚ÜóÔ∏è: Îì±Í∏â Í∞úÏÑ† ÌôïÎ•† (0~30% Î≤îÏúÑ ÌëúÏãú) 
- Downgrade ‚ÜòÔ∏è: Îì±Í∏â ÏïÖÌôî ÌôïÎ•† (0~30% Î≤îÏúÑ ÌëúÏãú)
- Default ‚ùå: Î∂ÄÎèÑ Î∞úÏÉù ÌôïÎ•† (0~10% Î≤îÏúÑ ÌëúÏãú)

=== ÏÉâÏÉÅ ÏΩîÎî© Í∏∞Ï§Ä ===
- Îπ®Í∞ÑÏÉâ ÌïòÏù¥ÎùºÏù¥Ìä∏: ÏûÑÍ≥ÑÍ∞í({RISK_THRESHOLD:.1%}) Ï¥àÍ≥º Í∏∞ÏóÖ
- ÎÖ∏ÎûÄÏÉâ ÌïòÏù¥ÎùºÏù¥Ìä∏: ÏûÑÍ≥ÑÍ∞íÏùò 70% Ïù¥ÏÉÅ Í∏∞ÏóÖ  
- ÏùºÎ∞ò ÌëúÏãú: ÏïàÏ†Ñ Î≤îÏúÑ Í∏∞ÏóÖ

=== CSV Îã§Ïö¥Î°úÎìú Îç∞Ïù¥ÌÑ∞ Ìè¨Ìï® Ìï≠Î™© ===
Î™®Îì† ÏàòÏπò Îç∞Ïù¥ÌÑ∞, ÏóÖÎç∞Ïù¥Ìä∏ ÏãúÍ∞Ñ, ÏúÑÌóòÎ∂ÑÎ•òÍ∞Ä Excel Ïó∞Îèô Í∞ÄÎä•
"""
        
        prompt = """ÎåÄÏãúÎ≥¥ÎìúÏùò Risk Table ÌÉ≠ÏóêÏÑú ÌëúÏãúÎêòÎäî 90Ïùº ÏúÑÌóòÎèÑ ÏàúÏúÑ Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Î∞òÏúºÎ°ú,
        ÏùÄÌñâ ÎåÄÏ∂úÏã¨ÏÇ¨ Î∞è Ïó¨Ïã†Í¥ÄÎ¶¨ Í¥ÄÏ†êÏóêÏÑú Îã§Ïùå ÏÇ¨Ìï≠ÏùÑ ÏÉÅÏÑ∏ Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî:
        1) Í∞Å Ìï≠Í≥µÏÇ¨Î≥Ñ 90Ïùº Ïã†Ïö©ÏúÑÌóò ÏàúÏúÑ Î∞è Ïó¨Ïã†Ïã¨ÏÇ¨ ÏäπÏù∏ Í∂åÍ≥†Îì±Í∏â 
        2) Progress Bar ÏàòÏπò Í∏∞Î∞ò Îã¥Î≥¥/Î≥¥Ï¶ù ÏöîÍµ¨ÏÇ¨Ìï≠ Ï∞®Îì± Ï†ÅÏö© Î∞©Ïïà
        3) Í≥†ÏúÑÌóò/Ï£ºÏùò/ÏïàÏ†Ñ Í∑∏Î£πÎ≥Ñ Ïó¨Ïã†ÌïúÎèÑ Î∞è Í∏àÎ¶¨ Ï∞®Îì± Ï†ïÏ±Ö Í∂åÍ≥†
        4) Ï†ïÍ∏∞ Î™®ÎãàÌÑ∞ÎßÅ Ï£ºÍ∏∞ Î∞è Ï°∞Í∏∞Í≤ΩÎ≥¥ ÏãúÏä§ÌÖú Ïö¥ÏòÅ Î∞©Ïïà
        5) ÏóÖÍ≥Ñ ÎÇ¥ ÏÉÅÎåÄÏ†Å Ïã†Ïö©ÎèÑ ÏàúÏúÑÎ•º Í≥†Î†§Ìïú Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ Ïû¨Î∞∞Î∂Ñ Ï†ÑÎûµ"""
        
        return self.generate_gpt4_report(prompt, context)
    
    def generate_heatmap_report(self, risk_df: pd.DataFrame) -> str:
        """Generate comprehensive heatmap report for bank loan officers"""
        
        if risk_df.empty:
            return "‚ùå Î∂ÑÏÑùÌï† Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§."
        
        # ÏúÑÌóò Ïú†ÌòïÎ≥Ñ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞
        upgrade_stats = {
            'mean': risk_df['upgrade_prob'].mean(),
            'max': risk_df['upgrade_prob'].max(),
            'min': risk_df['upgrade_prob'].min(),
            'std': risk_df['upgrade_prob'].std()
        }
        
        downgrade_stats = {
            'mean': risk_df['downgrade_prob'].mean(),
            'max': risk_df['downgrade_prob'].max(), 
            'min': risk_df['downgrade_prob'].min(),
            'std': risk_df['downgrade_prob'].std()
        }
        
        default_stats = {
            'mean': risk_df['default_prob'].mean(),
            'max': risk_df['default_prob'].max(),
            'min': risk_df['default_prob'].min(),
            'std': risk_df['default_prob'].std()
        }
        
        # ÏµúÍ≥†/ÏµúÏ†Ä ÏúÑÌóò Í∏∞ÏóÖ ÏãùÎ≥Ñ
        highest_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmax()]
        lowest_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmin()]
        highest_upgrade_firm = risk_df.loc[risk_df['upgrade_prob'].idxmax()]
        highest_downgrade_firm = risk_df.loc[risk_df['downgrade_prob'].idxmax()]
        
        # ÎåÄÏãúÎ≥¥Îìú ÌôîÎ©¥ ÌëúÏãú Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤¥ Ï†ïÎ¶¨
        context = f"""
=== ÎåÄÏ∂úÏã¨ÏÇ¨Ïö© ÏúÑÌóò ÌûàÌä∏Îßµ Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞ ===

Î∂ÑÏÑù ÎåÄÏÉÅ: {len(risk_df)}Í∞ú Ìï≠Í≥µÏÇ¨
ÌûàÌä∏Îßµ Íµ¨ÏÑ±: Í∏∞ÏóÖ(Ìñâ) √ó ÏúÑÌóòÏú†Ìòï(Ïó¥) Îß§Ìä∏Î¶≠Ïä§
ÏÉâÏÉÅ Í∞ïÎèÑ: ÏúÑÌóòÎèÑ ÎÜíÏùÑÏàòÎ°ù ÏßÑÌïú ÏÉâÏÉÅ ÌëúÏãú

=== Í∞Å Ìï≠Í≥µÏÇ¨Î≥Ñ ÏúÑÌóò Îß§Ìä∏Î¶≠Ïä§ (ÎåÄÏãúÎ≥¥Îìú ÌûàÌä∏Îßµ Í∏∞Ï§Ä) ===
"""
        
        for idx, row in risk_df.iterrows():
            # Í∞Å ÏúÑÌóòÏú†ÌòïÎ≥Ñ ÏÉÅÎåÄÏ†Å ÏúÑÏπò Í≥ÑÏÇ∞
            upgrade_percentile = (risk_df['upgrade_prob'] <= row['upgrade_prob']).mean() * 100
            downgrade_percentile = (risk_df['downgrade_prob'] <= row['downgrade_prob']).mean() * 100
            default_percentile = (risk_df['default_prob'] <= row['default_prob']).mean() * 100
            overall_percentile = (risk_df['overall_risk'] <= row['overall_risk']).mean() * 100
            
            context += f"""
‚óà {row['company_name']} (Îì±Í∏â: {row['current_rating']})
  [ÏúÑÌóòÏú†ÌòïÎ≥Ñ Ï†àÎåÄÏπò]
  - Îì±Í∏âÏÉÅÏäπ ÌôïÎ•†: {row['upgrade_prob']:.3%} (ÏóÖÍ≥Ñ ÏÉÅÏúÑ {100-upgrade_percentile:.0f}%)
  - Îì±Í∏âÌïòÎùΩ ÌôïÎ•†: {row['downgrade_prob']:.3%} (ÏóÖÍ≥Ñ ÏÉÅÏúÑ {100-downgrade_percentile:.0f}%)  
  - Î∂ÄÎèÑÎ∞úÏÉù ÌôïÎ•†: {row['default_prob']:.3%} (ÏóÖÍ≥Ñ ÏÉÅÏúÑ {100-default_percentile:.0f}%)
  - Ï†ÑÏ≤¥Î≥ÄÎèô ÌôïÎ•†: {row['overall_risk']:.3%} (ÏóÖÍ≥Ñ ÏÉÅÏúÑ {100-overall_percentile:.0f}%)
  
  [ÌûàÌä∏Îßµ ÏÉâÏÉÅ Ìï¥ÏÑù]
  - ÏÉÅÏäπÏúÑÌóò: {'üü¢ Ïó∞ÌïúÏÉâ' if row['upgrade_prob'] < upgrade_stats['mean'] else 'üü° Ï§ëÍ∞ÑÏÉâ' if row['upgrade_prob'] < upgrade_stats['mean'] + upgrade_stats['std'] else 'üü† ÏßÑÌïúÏÉâ'}
  - ÌïòÎùΩÏúÑÌóò: {'üü¢ Ïó∞ÌïúÏÉâ' if row['downgrade_prob'] < downgrade_stats['mean'] else 'üü° Ï§ëÍ∞ÑÏÉâ' if row['downgrade_prob'] < downgrade_stats['mean'] + downgrade_stats['std'] else 'üî¥ ÏßÑÌïúÏÉâ'}
  - Î∂ÄÎèÑÏúÑÌóò: {'üü¢ Ïó∞ÌïúÏÉâ' if row['default_prob'] < default_stats['mean'] else 'üü° Ï§ëÍ∞ÑÏÉâ' if row['default_prob'] < default_stats['mean'] + default_stats['std'] else 'üî¥ ÏßÑÌïúÏÉâ'}
"""
        
        context += f"""

=== Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏúÑÌóò Î∂ÑÌè¨ ÌÜµÍ≥Ñ ===

[Îì±Í∏âÏÉÅÏäπ ÏúÑÌóò Î∂ÑÌè¨]
- ÌèâÍ∑†: {upgrade_stats['mean']:.3%}
- ÏµúÎåÄ: {upgrade_stats['max']:.3%} ({highest_upgrade_firm['company_name']})
- ÏµúÏÜå: {upgrade_stats['min']:.3%}
- ÌëúÏ§ÄÌé∏Ï∞®: {upgrade_stats['std']:.3%}

[Îì±Í∏âÌïòÎùΩ ÏúÑÌóò Î∂ÑÌè¨]  
- ÌèâÍ∑†: {downgrade_stats['mean']:.3%}
- ÏµúÎåÄ: {downgrade_stats['max']:.3%} ({highest_downgrade_firm['company_name']})
- ÏµúÏÜå: {downgrade_stats['min']:.3%}
- ÌëúÏ§ÄÌé∏Ï∞®: {downgrade_stats['std']:.3%}

[Î∂ÄÎèÑÎ∞úÏÉù ÏúÑÌóò Î∂ÑÌè¨]
- ÌèâÍ∑†: {default_stats['mean']:.3%}
- ÏµúÎåÄ: {default_stats['max']:.3%}
- ÏµúÏÜå: {default_stats['min']:.3%}  
- ÌëúÏ§ÄÌé∏Ï∞®: {default_stats['std']:.3%}

=== ÏúÑÌóò ÏßëÏ§ëÎèÑ Î∂ÑÏÑù ===
- ÏµúÍ≥† Ï¢ÖÌï©ÏúÑÌóò: {highest_risk_firm['company_name']} ({highest_risk_firm['overall_risk']:.3%})
- ÏµúÏ†Ä Ï¢ÖÌï©ÏúÑÌóò: {lowest_risk_firm['company_name']} ({lowest_risk_firm['overall_risk']:.3%})
- ÏúÑÌóòÎèÑ Í≤©Ï∞®: {highest_risk_firm['overall_risk'] - lowest_risk_firm['overall_risk']:.3%}p

=== ÎåÄÏãúÎ≥¥Îìú ÌûàÏä§ÌÜ†Í∑∏Îû® Ï†ïÎ≥¥ ===
- Î∂ÑÌè¨ Íµ¨Í∞Ñ: 10Íµ¨Í∞ÑÏúºÎ°ú ÎÇòÎàÑÏñ¥ ÌëúÏãú
- ÏïåÎ¶º ÏûÑÍ≥ÑÍ∞í: {RISK_THRESHOLD:.1%} (Îπ®Í∞Ñ Ï†êÏÑ†ÏúºÎ°ú ÌëúÏãú)
- ÏûÑÍ≥ÑÍ∞í Ï¥àÍ≥º Í∏∞ÏóÖ: {len(risk_df[risk_df['overall_risk'] > RISK_THRESHOLD])}Í∞ú
"""
        
        prompt = """ÎåÄÏãúÎ≥¥ÎìúÏùò Heatmap ÌÉ≠ÏóêÏÑú ÌëúÏãúÎêòÎäî Í∏∞ÏóÖ√óÏúÑÌóòÏú†Ìòï Îß§Ìä∏Î¶≠Ïä§ÏôÄ ÏúÑÌóòÎ∂ÑÌè¨ ÌûàÏä§ÌÜ†Í∑∏Îû®ÏùÑ Í∏∞Î∞òÏúºÎ°ú,
        ÏùÄÌñâ ÎåÄÏ∂úÏã¨ÏÇ¨ Î∞è Ïó¨Ïã†Í¥ÄÎ¶¨ Í¥ÄÏ†êÏóêÏÑú Îã§Ïùå ÏÇ¨Ìï≠ÏùÑ ÏÉÅÏÑ∏ Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî:
        1) ÏúÑÌóòÏú†ÌòïÎ≥Ñ(ÏÉÅÏäπ/ÌïòÎùΩ/Î∂ÄÎèÑ) ÏÉâÏÉÅ Í∞ïÎèÑ Í∏∞Ï§Ä Ïó¨Ïã†Ïã¨ÏÇ¨ Ï∞®Îì± Ï†ïÏ±Ö ÏàòÎ¶Ω Î∞©Ïïà
        2) Í∞Å Ìï≠Í≥µÏÇ¨Ïùò ÏÉÅÎåÄÏ†Å ÏúÑÌóò Ìè¨ÏßÄÏÖò Í∏∞Î∞ò Ïó¨Ïã†ÌïúÎèÑ Î∞∞Î∂Ñ Ï†ÑÎûµ
        3) Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏúÑÌóò ÏßëÏ§ëÎèÑ Î∞è Î∂ÑÏÇ∞Ìà¨Ïûê Í∞úÏÑ† Î∞©Ìñ•
        4) ÌûàÏä§ÌÜ†Í∑∏Îû® Î∂ÑÌè¨ Ìå®ÌÑ¥ÏùÑ ÌôúÏö©Ìïú ÏóÖÏ¢ÖÎ≥Ñ Ïó¨Ïã† Í∞ÄÏù¥ÎìúÎùºÏù∏ ÏÑ§Ï†ï
        5) ÏúÑÌóòÎèÑ Í≤©Ï∞® Î∂ÑÏÑùÏùÑ ÌÜµÌïú ÌîÑÎ¶¨ÎØ∏ÏóÑ/ÎîîÏä§Ïπ¥Ïö¥Ìä∏ Í∏àÎ¶¨ Ï†ÅÏö© Í∏∞Ï§Ä"""
        
        return self.generate_gpt4_report(prompt, context)
    
    def generate_alerts_report(self, risk_df: pd.DataFrame, threshold: float) -> str:
        """Generate comprehensive alerts report for bank loan officers"""
        
        if risk_df.empty:
            return "‚ùå Î∂ÑÏÑùÌï† Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§."
        
        # ÏúÑÌóòÎèÑÎ≥Ñ Í∏∞ÏóÖ Î∂ÑÎ•ò
        high_risk_firms = risk_df[risk_df['overall_risk'] > threshold]
        warning_firms = risk_df[(risk_df['overall_risk'] >= threshold * 0.8) & (risk_df['overall_risk'] <= threshold)]
        safe_firms = risk_df[risk_df['overall_risk'] < threshold * 0.8]
        
        # ÏïåÎ¶º Ïù¥Î†• Ï†ïÎ≥¥ (ÏÑ∏ÏÖò Ïä§ÌÖåÏù¥Ìä∏ÏóêÏÑú)
        alert_history_count = len(st.session_state.get('alert_history', []))
        last_alert_time = st.session_state.get('alert_history', [])[-1]['timestamp'].strftime('%Y-%m-%d %H:%M') if alert_history_count > 0 else 'ÏóÜÏùå'
        
        # ÎåÄÏãúÎ≥¥Îìú ÌôîÎ©¥ ÌëúÏãú Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤¥ Ï†ïÎ¶¨
        context = f"""
=== ÎåÄÏ∂úÏã¨ÏÇ¨Ïö© ÏïåÎ¶º Í¥ÄÎ¶¨ ÏãúÏä§ÌÖú Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞ ===

ÌòÑÏû¨ ÏïåÎ¶º ÏûÑÍ≥ÑÍ∞í: {threshold:.1%}
Ï¥ù Î∂ÑÏÑù ÎåÄÏÉÅ: {len(risk_df)}Í∞ú Ìï≠Í≥µÏÇ¨
ÏãúÏä§ÌÖú ÏÉÅÌÉú: {'üî¥ ÏïåÎ¶º Î∞úÏÉù' if len(high_risk_firms) > 0 else 'üü¢ Ï†ïÏÉÅ Ïö¥ÏòÅ'}
ÎßàÏßÄÎßâ ÏïåÎ¶º: {last_alert_time}
Ï¥ù ÏïåÎ¶º Ïù¥Î†•: {alert_history_count}Í±¥

=== ÏúÑÌóòÎèÑÎ≥Ñ Í∏∞ÏóÖ Î∂ÑÎ•ò ÌòÑÌô© ===

üî¥ Í≥†ÏúÑÌóòÍµ∞ (ÏûÑÍ≥ÑÍ∞í {threshold:.1%} Ï¥àÍ≥º): {len(high_risk_firms)}Í∞ú
üü° Ï£ºÏùòÍµ∞ (ÏûÑÍ≥ÑÍ∞íÏùò 80%~100%): {len(warning_firms)}Í∞ú  
üü¢ ÏïàÏ†ÑÍµ∞ (ÏûÑÍ≥ÑÍ∞íÏùò 80% ÎØ∏Îßå): {len(safe_firms)}Í∞ú

=== Í≥†ÏúÑÌóò Í∏∞ÏóÖ ÏÉÅÏÑ∏ Ï†ïÎ≥¥ ===
"""
        
        if len(high_risk_firms) > 0:
            for idx, row in high_risk_firms.iterrows():
                excess_risk = row['overall_risk'] - threshold
                context += f"""
‚óà {row['company_name']} (Îì±Í∏â: {row['current_rating']}) üö® Ï¶âÏãúÎåÄÏùëÌïÑÏöî
  - ÌòÑÏû¨ ÏúÑÌóòÎèÑ: {row['overall_risk']:.3%}
  - ÏûÑÍ≥ÑÍ∞í Ï¥àÍ≥ºÌè≠: +{excess_risk:.3%}p ({excess_risk/threshold*100:+.1f}%)
  - Îì±Í∏âÏÉÅÏäπ ÌôïÎ•†: {row['upgrade_prob']:.3%}
  - Îì±Í∏âÌïòÎùΩ ÌôïÎ•†: {row['downgrade_prob']:.3%}
  - Î∂ÄÎèÑÎ∞úÏÉù ÌôïÎ•†: {row['default_prob']:.3%}
  - ÏúÑÌóòÎèÑ Î∂ÑÎ•ò: {row['risk_classification']}
  - Í∂åÍ≥†Ï°∞Ïπò: Ïó¨Ïã†ÌïúÎèÑ Ïû¨Í≤ÄÌÜ†, Îã¥Î≥¥Î≥¥Í∞ï, Î™®ÎãàÌÑ∞ÎßÅ Í∞ïÌôî
"""
        else:
            context += "‚úÖ ÌòÑÏû¨ Í≥†ÏúÑÌóò ÏûÑÍ≥ÑÍ∞íÏùÑ Ï¥àÍ≥ºÌïòÎäî Í∏∞ÏóÖÏù¥ ÏóÜÏäµÎãàÎã§.\n"
        
        context += "\n=== Ï£ºÏùò Í∏∞ÏóÖ Î™®ÎãàÌÑ∞ÎßÅ ÎåÄÏÉÅ ===\n"
        
        if len(warning_firms) > 0:
            for idx, row in warning_firms.iterrows():
                remaining_buffer = threshold - row['overall_risk']
                context += f"""
‚óà {row['company_name']} (Îì±Í∏â: {row['current_rating']}) ‚ö° ÏòàÎ∞©Ï†ÅÎ™®ÎãàÌÑ∞ÎßÅ
  - ÌòÑÏû¨ ÏúÑÌóòÎèÑ: {row['overall_risk']:.3%}
  - ÏûÑÍ≥ÑÍ∞íÍπåÏßÄ Ïó¨Ïú†: {remaining_buffer:.3%}p
  - Ï£ºÏöî ÏúÑÌóòÏöîÏÜå: {'Îì±Í∏âÌïòÎùΩ' if row['downgrade_prob'] > row['upgrade_prob'] else 'Îì±Í∏âÏÉÅÏäπ'}
  - Í∂åÍ≥†Ï°∞Ïπò: Ï†ïÍ∏∞Ï†êÍ≤Ä Í∞ïÌôî, Ïû¨Î¨¥Ï†úÌëú Î∂ÑÍ∏∞Î≥Ñ Ï†úÏ∂ú
"""
        else:
            context += "‚úÖ ÌòÑÏû¨ Ï£ºÏùò ÏàòÏ§ÄÏóê Ìï¥ÎãπÌïòÎäî Í∏∞ÏóÖÏù¥ ÏóÜÏäµÎãàÎã§.\n"
        
        # Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÌÜµÍ≥Ñ
        context += f"""

=== Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ ÏïåÎ¶º ÏãúÏä§ÌÖú ÌÜµÍ≥Ñ ===
- ÌèâÍ∑† ÏúÑÌóòÎèÑ: {risk_df['overall_risk'].mean():.3%}
- ÏµúÎåÄ ÏúÑÌóòÎèÑ: {risk_df['overall_risk'].max():.3%} ({risk_df.loc[risk_df['overall_risk'].idxmax(), 'company_name']})
- ÏµúÏÜå ÏúÑÌóòÎèÑ: {risk_df['overall_risk'].min():.3%} ({risk_df.loc[risk_df['overall_risk'].idxmin(), 'company_name']})
- ÏúÑÌóòÎèÑ ÌëúÏ§ÄÌé∏Ï∞®: {risk_df['overall_risk'].std():.3%}
- ÏûÑÍ≥ÑÍ∞í ÌôúÏö©Î•†: {len(high_risk_firms)/len(risk_df)*100:.1f}% (Ï¥àÍ≥º Í∏∞ÏóÖ ÎπÑÏú®)

=== ÎåÄÏãúÎ≥¥Îìú ÏïåÎ¶º ÏÑ§Ï†ï Ï†ïÎ≥¥ ===
- Slack ÏõπÌõÖ: {'‚úÖ Ïó∞ÎèôÏôÑÎ£å' if st.session_state.get('slack_webhook_url') else '‚ùå ÎØ∏ÏÑ§Ï†ï'}
- ÏûêÎèôÏÉàÎ°úÍ≥†Ïπ®: 30Ï¥à Í∞ÑÍ≤©
- ÏïåÎ¶º Î≤ÑÌäº: ÏàòÎèô Î∞úÏÜ° Í∞ÄÎä•
- ÏûÑÍ≥ÑÍ∞í Ï°∞Ï†ï: 5%~30% Î≤îÏúÑÏóêÏÑú Ïã§ÏãúÍ∞Ñ Î≥ÄÍ≤Ω Í∞ÄÎä•
- ÏïåÎ¶º Ïù¥Î†•: ÏµúÍ∑º 5Í±¥ ÌëúÏãú, ÏÑ∏ÏÖòÎ≥Ñ Ï†ÄÏû•

=== ÏµúÍ∑º ÏïåÎ¶º Ïù¥Î†• ÏöîÏïΩ ===
"""
        
        if alert_history_count > 0:
            recent_alerts = st.session_state.get('alert_history', [])[-3:]  # ÏµúÍ∑º 3Í±¥
            for i, alert in enumerate(reversed(recent_alerts), 1):
                context += f"""
[{i}] {alert['timestamp'].strftime('%m/%d %H:%M')} - {len(alert['firms'])}Í∞ú Í∏∞ÏóÖ ÏïåÎ¶º
    ÎåÄÏÉÅ: {', '.join(alert['firms'])}
"""
        else:
            context += "ÏïÑÏßÅ Î∞úÏÜ°Îêú ÏïåÎ¶ºÏù¥ ÏóÜÏäµÎãàÎã§.\n"
        
        prompt = f"""ÎåÄÏãúÎ≥¥ÎìúÏùò Alerts ÌÉ≠ÏóêÏÑú ÌëúÏãúÎêòÎäî ÏïåÎ¶º Í¥ÄÎ¶¨ ÏãúÏä§ÌÖú Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Î∞òÏúºÎ°ú,
        ÏùÄÌñâ ÎåÄÏ∂úÏã¨ÏÇ¨ Î∞è Ïó¨Ïã†Í¥ÄÎ¶¨ Í¥ÄÏ†êÏóêÏÑú Îã§Ïùå ÏÇ¨Ìï≠ÏùÑ ÏÉÅÏÑ∏ Î∂ÑÏÑùÌï¥Ï£ºÏÑ∏Ïöî:
        1) ÌòÑÏû¨ ÏûÑÍ≥ÑÍ∞í({threshold:.1%}) Í∏∞Ï§Ä Í≥†ÏúÑÌóò/Ï£ºÏùò Í∏∞ÏóÖÏóê ÎåÄÌïú Ï¶âÏãú Ïó¨Ïã†Ï°∞Ïπò Î∞©Ïïà
        2) ÏïåÎ¶º Î∞úÏÉù ÎπàÎèÑÏôÄ Ìå®ÌÑ¥ Î∂ÑÏÑùÏùÑ ÌÜµÌïú Ï°∞Í∏∞Í≤ΩÎ≥¥ ÏãúÏä§ÌÖú Ìö®Í≥ºÏÑ± ÌèâÍ∞Ä  
        3) ÏúÑÌóòÎèÑÎ≥Ñ Ï∞®Îì± Î™®ÎãàÌÑ∞ÎßÅ Ï£ºÍ∏∞ Î∞è Î≥¥Í≥†Ï≤¥Í≥Ñ ÏàòÎ¶Ω Î∞©Ïïà
        4) Slack ÏïåÎ¶º Ïó∞ÎèôÏùÑ ÌÜµÌïú Ïã§ÏãúÍ∞Ñ ÎåÄÏùëÏ≤¥Í≥Ñ Íµ¨Ï∂ï Î∞è Ïö¥ÏòÅ ÌîÑÎ°úÏÑ∏Ïä§
        5) ÏûÑÍ≥ÑÍ∞í Ï°∞Ï†ï Î∞è ÏïåÎ¶º ÎØºÍ∞êÎèÑ ÏµúÏ†ÅÌôîÎ•º ÏúÑÌïú Î∞±ÌÖåÏä§ÌåÖ Í≤∞Í≥º Î∞òÏòÅ Î∞©Ïïà
        6) Ìè¨Ìä∏Ìè¥Î¶¨Ïò§ Ï†ÑÏ≤¥ Í¥ÄÏ†êÏóêÏÑúÏùò ÏúÑÌóò ÏßëÏ§ëÎèÑ ÏôÑÌôî Î∞è Î∂ÑÏÇ∞ Ï†ÑÎûµ"""
        
        return self.generate_gpt4_report(prompt, context)
    
    def generate_hazard_curves(self, firms: List[FirmProfile]) -> go.Figure:
        """Generate hazard curves for all firms"""
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=['Overall Risk Over Time', 'Upgrade Probability', 'Downgrade Probability', 'Default Risk'],
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # Generate time horizons (1 to 365 days)
        horizons = [30, 60, 90, 120, 180, 270, 365]
        colors = px.colors.qualitative.Set1
        
        # üîß Data collection for dynamic scaling
        all_overall_risks = []
        all_upgrade_probs = []
        all_downgrade_probs = []
        all_default_probs = []
        firm_data = []  # Store data for each firm
        
        for i, firm in enumerate(firms):
            if self.risk_scorer is None:
                continue
                
            overall_risks = []
            upgrade_probs = []
            downgrade_probs = []
            default_probs = []
            
            for horizon in horizons:
                try:
                    risk_assessment = self.risk_scorer.score_firm(firm, horizon=horizon)
                    
                    # üîç DEBUG: Graph value check
                    print(f"  üîç GRAPH DEBUG {firm.company_name} @ {horizon}d:")
                    print(f"    - Overall: {risk_assessment['overall_change_probability']:.6f}")
                    print(f"    - Upgrade: {risk_assessment['upgrade_probability']:.6f}")  
                    print(f"    - Downgrade: {risk_assessment['downgrade_probability']:.6f}")
                    print(f"    - Default: {risk_assessment['default_probability']:.6f}")
                    
                    overall_risk = risk_assessment['overall_change_probability']
                    upgrade_prob = risk_assessment['upgrade_probability']
                    downgrade_prob = risk_assessment['downgrade_probability']
                    default_prob = risk_assessment['default_probability']
                    
                    overall_risks.append(overall_risk)
                    upgrade_probs.append(upgrade_prob)
                    downgrade_probs.append(downgrade_prob)
                    default_probs.append(default_prob)
                    
                    # üîß Collect all values for dynamic scaling
                    all_overall_risks.append(overall_risk)
                    all_upgrade_probs.append(upgrade_prob)
                    all_downgrade_probs.append(downgrade_prob)
                    all_default_probs.append(default_prob)
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è Error getting risk assessment for {firm.company_name}: {e}")
                    # Fallback to simulated curves
                    base_risk = 0.05 + i * 0.02
                    overall_risk = base_risk * (1 + horizon/365)
                    upgrade_prob = base_risk * 0.6 * (1 + horizon/365)
                    downgrade_prob = base_risk * 0.4 * (1 + horizon/365)
                    default_prob = base_risk * 0.1 * (1 + horizon/365)
                    
                    overall_risks.append(overall_risk)
                    upgrade_probs.append(upgrade_prob)
                    downgrade_probs.append(downgrade_prob)
                    default_probs.append(default_prob)
                    
                    # Collect fallback values too
                    all_overall_risks.append(overall_risk)
                    all_upgrade_probs.append(upgrade_prob)
                    all_downgrade_probs.append(downgrade_prob)
                    all_default_probs.append(default_prob)
            
            # Store data for this firm
            firm_data.append({
                'name': firm.company_name,
                'overall_risks': overall_risks,
                'upgrade_probs': upgrade_probs,
                'downgrade_probs': downgrade_probs,
                'default_probs': default_probs
            })
            
            color = colors[i % len(colors)]
            
            # Overall risk curve
            fig.add_trace(
                go.Scatter(x=horizons, y=overall_risks, name=firm.company_name, 
                          line=dict(color=color), legendgroup=firm.company_name),
                row=1, col=1
            )
            
            # Upgrade probability
            fig.add_trace(
                go.Scatter(x=horizons, y=upgrade_probs, name=firm.company_name, 
                          line=dict(color=color), legendgroup=firm.company_name, showlegend=False),
                row=1, col=2
            )
            
            # Downgrade probability
            fig.add_trace(
                go.Scatter(x=horizons, y=downgrade_probs, name=firm.company_name, 
                          line=dict(color=color), legendgroup=firm.company_name, showlegend=False),
                row=2, col=1
            )
            
            # Default risk
            fig.add_trace(
                go.Scatter(x=horizons, y=default_probs, name=firm.company_name, 
                          line=dict(color=color), legendgroup=firm.company_name, showlegend=False),
                row=2, col=2
            )
        
        # Update layout
        fig.update_layout(
            title="Korean Airlines Credit Risk Hazard Curves",
            height=800,
            showlegend=True
        )
        
        # üîß Dynamic scale calculation with safety margins
        def calculate_dynamic_range(values, margin_factor=0.1, min_range=0.01):
            """Calculate dynamic range with margin"""
            if not values or all(v == 0 for v in values):
                return [0, min_range]
            
            min_val = min(values)
            max_val = max(values)
            
            # Add margin (10% by default)
            value_range = max_val - min_val
            margin = max(value_range * margin_factor, min_range * 0.1)
            
            # Ensure minimum range for visibility
            if value_range < min_range:
                center = (min_val + max_val) / 2
                return [max(0, center - min_range/2), center + min_range/2]
            
            return [max(0, min_val - margin), max_val + margin]
        
        # Calculate dynamic ranges for each subplot
        overall_range = calculate_dynamic_range(all_overall_risks, margin_factor=0.15)
        upgrade_range = calculate_dynamic_range(all_upgrade_probs, margin_factor=0.2, min_range=0.01)
        downgrade_range = calculate_dynamic_range(all_downgrade_probs, margin_factor=0.15)
        default_range = calculate_dynamic_range(all_default_probs, margin_factor=0.3, min_range=0.005)
        
        print(f"üîß Dynamic ranges calculated:")
        print(f"  Overall: [{overall_range[0]:.4f}, {overall_range[1]:.4f}]")
        print(f"  Upgrade: [{upgrade_range[0]:.4f}, {upgrade_range[1]:.4f}]")
        print(f"  Downgrade: [{downgrade_range[0]:.4f}, {downgrade_range[1]:.4f}]")
        print(f"  Default: [{default_range[0]:.6f}, {default_range[1]:.6f}]")
        
        # Update axes with dynamic scales
        fig.update_xaxes(title_text="Days", row=1, col=1)
        fig.update_yaxes(title_text="Probability", range=overall_range, row=1, col=1)
        
        fig.update_xaxes(title_text="Days", row=1, col=2)
        fig.update_yaxes(title_text="Probability", range=upgrade_range, row=1, col=2)
        
        fig.update_xaxes(title_text="Days", row=2, col=1)
        fig.update_yaxes(title_text="Probability", range=downgrade_range, row=2, col=1)
        
        fig.update_xaxes(title_text="Days", row=2, col=2)
        fig.update_yaxes(title_text="Probability", range=default_range, row=2, col=2)
        
        return fig
    
    def create_risk_heatmap(self, risk_df: pd.DataFrame) -> go.Figure:
        """Create risk heatmap visualization"""
        
        if risk_df.empty:
            return go.Figure()
        
        # Prepare data for heatmap
        heatmap_data = risk_df[['company_name', 'upgrade_prob', 'downgrade_prob', 'default_prob']].copy()
        heatmap_data = heatmap_data.set_index('company_name').T
        
        fig = go.Figure(data=go.Heatmap(
            z=heatmap_data.values,
            x=heatmap_data.columns,
            y=['Upgrade Risk', 'Downgrade Risk', 'Default Risk'],
            colorscale='RdYlBu_r',
            text=np.round(heatmap_data.values, 3),
            texttemplate="%{text}",
            textfont={"size": 12},
            colorbar=dict(title="Probability")
        ))
        
        fig.update_layout(
            title="Risk Heatmap - Korean Airlines",
            xaxis_title="Airlines",
            yaxis_title="Risk Type",
            height=400
        )
        
        return fig
    
    def send_slack_alert(self, high_risk_firms: pd.DataFrame):
        """Send Slack webhook alert for high-risk firms"""
        
        if SLACK_WEBHOOK_URL is None:
            st.info("üí° Slack webhook not configured. Set SLACK_WEBHOOK_URL to enable alerts.")
            return False
        
        if high_risk_firms.empty:
            return True
        
        # Prepare alert message
        alert_text = "üö® *Credit Rating Risk Alert - Korean Airlines*\n\n"
        alert_text += f"*High Risk Firms (>{RISK_THRESHOLD:.1%} change probability):*\n"
        
        for _, firm in high_risk_firms.iterrows():
            alert_text += (
                f"‚Ä¢ *{firm['company_name']}* ({firm['current_rating']}): "
                f"{firm['overall_risk']:.1%} risk, "
                f"Downgrade: {firm['downgrade_prob']:.1%}\n"
            )
        
        alert_text += f"\n_Generated at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_"
        
        # Slack message payload
        payload = {
            "text": alert_text,
            "username": "Credit Risk Monitor",
            "icon_emoji": ":warning:",
            "channel": "#risk-monitoring"
        }
        
        try:
            response = requests.post(SLACK_WEBHOOK_URL, json=payload, timeout=10)
            if response.status_code == 200:
                st.success(f"‚úÖ Slack alert sent for {len(high_risk_firms)} high-risk firms")
                
                # Log to session state
                st.session_state.alert_history.append({
                    'timestamp': datetime.now(),
                    'firms': high_risk_firms['company_name'].tolist(),
                    'message': alert_text
                })
                
                return True
            else:
                st.error(f"‚ùå Slack alert failed: {response.status_code}")
                return False
                
        except Exception as e:
            st.error(f"‚ùå Error sending Slack alert: {e}")
            return False
    
    def run_dashboard(self):
        """Main dashboard application"""
        
        logger.info("[DASHBOARD] Starting dashboard run...")
        logger.info(f"[DASHBOARD] Current session_state keys: {list(st.session_state.keys())}")
        
        # Page configuration (only set once)
        try:
            st.set_page_config(
                page_title="Korean Airlines Credit Risk Dashboard",
                page_icon="‚úàÔ∏è",
                layout="wide",
                initial_sidebar_state="expanded"
            )
        except Exception as e:
            pass  # Config already set
        
        # Header
        st.title("‚úàÔ∏è Korean Airlines Credit Risk Dashboard")
        st.markdown("---")
        
        # Sidebar
        st.sidebar.header("üéõÔ∏è Control Panel")
        
        # Model loading/unloading using buttons
        if not st.session_state.models_loaded_status:
            if st.sidebar.button("üîÑ Enable Models", key="enable_models_btn", help="Load and enable the risk models"):
                with st.spinner("üèãÔ∏è Loading models..."):
                    success = self.load_models()
                    if success:
                        st.session_state.models_loaded_status = True
                        st.success("‚úÖ Models loaded successfully!")
                    else:
                        st.error("‚ùå Failed to load models")
        else:
            st.sidebar.success("‚úÖ Models Enabled")
            if st.sidebar.button("üî¥ Disable Models", key="disable_models_btn", help="Disable the risk models"):
                st.session_state.models_loaded_status = False
                self.risk_scorer = None
                st.info("üîÑ Models disabled")
        
        # Data source information
        st.sidebar.markdown("---")
        st.sidebar.subheader("üìä Data Source")
        
        try:
            # Try different import paths for config
            try:
                from config.config import USE_REAL_DATA
            except ImportError:
                from config import USE_REAL_DATA
            if USE_REAL_DATA:
                st.sidebar.success("üéØ **Real DART Data Mode**")
                st.sidebar.info("Using actual financial statements from DART API")
            else:
                st.sidebar.warning("‚ö° **Fast Dummy Data Mode**")
                st.sidebar.info("Using synthetic data for development")
        except ImportError:
            st.sidebar.warning("‚ö° **Fast Dummy Data Mode**")
            st.sidebar.info("Using synthetic data for development")
        
        st.sidebar.markdown("""
        **üí° To switch data mode:**
        Edit `config.py` and change:
        ```python
        USE_REAL_DATA = True   # Real data
        USE_REAL_DATA = False  # Dummy data
        ```
        Then restart the dashboard.
        """)
        
        # Risk threshold setting
        st.sidebar.markdown("---")
        global RISK_THRESHOLD, SLACK_WEBHOOK_URL
        old_threshold = RISK_THRESHOLD
        RISK_THRESHOLD = st.sidebar.slider(
            "‚ö†Ô∏è Alert Threshold", 
            min_value=0.05, 
            max_value=0.30, 
            value=RISK_THRESHOLD, 
            step=0.01,
            format="%.2f",
            key="risk_threshold_slider"
        )
        if old_threshold != RISK_THRESHOLD:
            logger.info(f"[SIDEBAR] Risk threshold changed from {old_threshold} to {RISK_THRESHOLD}")
        
        # Slack webhook configuration
        slack_url = st.sidebar.text_input(
            "üì± Slack Webhook URL", 
            value=SLACK_WEBHOOK_URL or "",
            type="password",
            help="Enter your Slack webhook URL for alerts"
        )
        
        if slack_url:
            SLACK_WEBHOOK_URL = slack_url
        
        # Auto-refresh
        auto_refresh = st.sidebar.checkbox("üîÑ Auto Refresh (30s)", value=False, key="auto_refresh_checkbox")
        
        if auto_refresh:
            logger.info("[WIDGET] Auto-refresh enabled")
            st.sidebar.info("Auto-refresh enabled")
            # Note: In production, you'd implement proper auto-refresh
        
        # DART Îç∞Ïù¥ÌÑ∞ Ï∫êÏãú Í¥ÄÎ¶¨
            st.sidebar.markdown("---")
            st.sidebar.subheader("üíæ DART Îç∞Ïù¥ÌÑ∞ Ï∫êÏãú")
        
        # Ï∫êÏãú ÏãúÏä§ÌÖú ÏÉÅÌÉú ÌëúÏãú
        if CACHE_AVAILABLE:
            st.sidebar.success("‚úÖ Ï∫êÏãú ÏãúÏä§ÌÖú ÌôúÏÑ±Ìôî")
            
            # Ï∫êÏãú ÌôúÏÑ±Ìôî/ÎπÑÌôúÏÑ±Ìôî ÌÜ†Í∏Ä
            cache_enabled = st.sidebar.checkbox(
                "üíæ Ï∫êÏãú ÏãúÏä§ÌÖú ÏÇ¨Ïö©", 
                value=True, 
                key="cache_enabled_checkbox",
                help="DART API Îç∞Ïù¥ÌÑ∞Î•º Ï∫êÏãúÌïòÏó¨ Ï§ëÎ≥µ ÏöîÏ≤≠ÏùÑ Î∞©ÏßÄÌï©ÎãàÎã§"
            )
            
            try:
                cache = get_global_cache()
                cache_stats = cache.get_cache_stats()
                
                # Ï∫êÏãú ÌÜµÍ≥Ñ ÌëúÏãú
                st.sidebar.info(f"""
                **üìä Ï∫êÏãú ÌòÑÌô©**
                - Ï¥ù ÏóîÌä∏Î¶¨: {cache_stats['total_entries']}Í∞ú
                - Ïú†Ìö®Ìïú Îç∞Ïù¥ÌÑ∞: {cache_stats['valid_entries']}Í∞ú
                - ÎßåÎ£åÎêú Îç∞Ïù¥ÌÑ∞: {cache_stats['expired_entries']}Í∞ú
                - Ï¥ù ÌÅ¨Í∏∞: {cache_stats['total_size_mb']} MB
                - Ï∫êÏãú Í∏∞Í∞Ñ: {cache_stats['cache_duration_hours']}ÏãúÍ∞Ñ
                """)
                
                # Ï∫êÏãú Í¥ÄÎ¶¨ Î≤ÑÌäºÎì§
                col1, col2 = st.sidebar.columns(2)
                
                with col1:
                    if st.button("üßπ ÎßåÎ£å Ï†ïÎ¶¨", key="cleanup_cache_btn", help="ÎßåÎ£åÎêú Ï∫êÏãú ÏóîÌä∏Î¶¨Î•º Ï†ïÎ¶¨Ìï©ÎãàÎã§"):
                        removed_count = cache.cleanup_expired_cache()
                        if removed_count > 0:
                            st.success(f"‚úÖ {removed_count}Í∞ú Ìï≠Î™© Ï†ïÎ¶¨Îê®")
                        else:
                            st.info("üîç Ï†ïÎ¶¨Ìï† ÎßåÎ£å Ìï≠Î™© ÏóÜÏùå")
                        st.rerun()
                
                with col2:
                    if st.button("üóëÔ∏è Ï†ÑÏ≤¥ ÏÇ≠Ï†ú", key="clear_all_cache_btn", help="Î™®Îì† Ï∫êÏãúÎ•º ÏÇ≠Ï†úÌï©ÎãàÎã§"):
                        removed_count = cache.clear_all_cache()
                        if removed_count > 0:
                            st.success(f"‚úÖ {removed_count}Í∞ú Ìï≠Î™© ÏÇ≠Ï†úÎê®")
                        else:
                            st.info("üîç ÏÇ≠Ï†úÌï† Ìï≠Î™© ÏóÜÏùå")
                        st.rerun()
                
                # Ï∫êÏãú ÏÑ§Ï†ï Ï†ïÎ≥¥
                with st.sidebar.expander("‚öôÔ∏è Ï∫êÏãú ÏÑ§Ï†ï"):
                    st.text(f"üìÅ Ï∫êÏãú ÎîîÎ†âÌÜ†Î¶¨: {cache.cache_dir}")
                    st.text(f"‚è±Ô∏è Ï∫êÏãú Ïú†Ìö®ÏãúÍ∞Ñ: {cache.cache_duration.total_seconds() / 3600:.1f}ÏãúÍ∞Ñ")
                    st.text(f"üìä Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌååÏùº: {os.path.basename(cache.metadata_file)}")
                
                # Ï∫êÏãú ÏÑ∏Î∂Ä Ï†ïÎ≥¥ (ÌôïÏû• Í∞ÄÎä•)
                with st.sidebar.expander("üìã Ï∫êÏãú ÏÑ∏Î∂Ä Ï†ïÎ≥¥"):
                    entries = cache.list_cached_entries()
                    if entries:
                        for entry in entries[:5]:  # ÏµúÍ∑º 5Í∞úÎßå ÌëúÏãú
                            status = "‚úÖ" if entry['is_valid'] else "‚è∞"
                            st.text(f"{status} {entry['company_name']} {entry['year']}")
                        
                        if len(entries) > 5:
                            st.text(f"...Î∞è {len(entries)-5}Í∞ú Îçî")
                    else:
                        st.text("Ï∫êÏãúÎêú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§")
                
            except Exception as e:
                st.sidebar.error(f"Ï∫êÏãú Ï†ïÎ≥¥ Î°úÎìú Ïã§Ìå®: {e}")
        else:
            st.sidebar.error("‚ùå Ï∫êÏãú ÏãúÏä§ÌÖú ÎπÑÌôúÏÑ±Ìôî")
            st.sidebar.info("""
            **Ï∫êÏãú ÏãúÏä§ÌÖú ÌôúÏÑ±Ìôî Î∞©Î≤ï:**
            1. `src/data/dart_data_cache.py` ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏
            2. Python Í≤ΩÎ°ú ÏÑ§Ï†ï ÌôïÏù∏
            3. ÎåÄÏãúÎ≥¥Îìú Ïû¨ÏãúÏûë
            """)
        
        # RAG ÏãúÏä§ÌÖú Í¥ÄÎ¶¨
        st.sidebar.markdown("---")
        st.sidebar.subheader("üîç RAG ÏãúÏä§ÌÖú (Ìï≠Í≥µÏóÖÍ≥Ñ Í≤ÄÏÉâ)")
        
        if self.rag_available:
            st.sidebar.success("‚úÖ RAG ÏãúÏä§ÌÖú ÌôúÏÑ±Ìôî")
            
            try:
                # RAG Ï∫êÏãú Ï†ïÎ≥¥
                cache_info = self.rag_system.get_cache_info()
                
                # RAG ÏÉÅÌÉú ÌëúÏãú
                status_icon = "‚úÖ" if cache_info['cache_valid'] else "‚è∞"
                st.sidebar.info(f"""
                **üîç RAG ÏãúÏä§ÌÖú ÌòÑÌô©**
                - ÏÉÅÌÉú: {status_icon} {'ÏµúÏã† Ï†ïÎ≥¥' if cache_info['cache_valid'] else 'ÏóÖÎç∞Ïù¥Ìä∏ ÌïÑÏöî'}
                - ÎßàÏßÄÎßâ ÏóÖÎç∞Ïù¥Ìä∏: {cache_info['last_update']}
                - Ï≤òÎ¶¨Îêú Í∏∞ÏÇ¨: {cache_info['articles_processed']}Í∞ú
                - ÏÉÅÌÉú: {cache_info['status']}
                """)
                
                # RAG Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏ Î≤ÑÌäº
                if st.sidebar.button("üîÑ Ìï≠Í≥µÏóÖÍ≥Ñ Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏", key="update_rag_btn", help="ÏµúÏã† Ìï≠Í≥µÏóÖÍ≥Ñ Ï†ïÎ≥¥Î•º Í≤ÄÏÉâÌïòÍ≥† ÏöîÏïΩÌï©ÎãàÎã§"):
                    with st.spinner("Ìï≠Í≥µÏóÖÍ≥Ñ Ï†ïÎ≥¥ Í≤ÄÏÉâ Î∞è ÏöîÏïΩ Ï§ë..."):
                        try:
                            context = self.rag_system.get_airline_industry_context(force_update=True)
                            st.session_state.rag_context = context
                            st.session_state.rag_last_update = datetime.now()
                            st.success("‚úÖ Ìï≠Í≥µÏóÖÍ≥Ñ Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å")
                            st.rerun()
                        except Exception as e:
                            st.error(f"‚ùå ÏóÖÎç∞Ïù¥Ìä∏ Ïã§Ìå®: {e}")
                
                # RAG ÏÉÅÏÑ∏ Ï†ïÎ≥¥
                with st.sidebar.expander("üìã RAG ÏÉÅÏÑ∏ Ï†ïÎ≥¥"):
                    if st.session_state.rag_context:
                        context = st.session_state.rag_context
                        st.text("**Í≤ÄÏÉâ ÌÇ§ÏõåÎìú:**")
                        for keyword in context.get('search_keywords', [])[:3]:
                            st.text(f"‚Ä¢ {keyword}")
                        
                        st.text("**ÌïµÏã¨ Ìè¨Ïù∏Ìä∏:**")
                        for point in context.get('key_points', [])[:3]:
                            st.text(f"‚Ä¢ {point}")
                        
                        st.text("**Ï†ïÎ≥¥ Ï∂úÏ≤ò:**")
                        for source in context.get('sources', [])[:2]:
                            st.text(f"‚Ä¢ {source[:50]}...")
                    else:
                        st.text("RAG Ï†ïÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§")
                
                # RAG ÏÑ§Ï†ï
                with st.sidebar.expander("‚öôÔ∏è RAG ÏÑ§Ï†ï"):
                    st.text(f"üìÅ Ï∫êÏãú ÎîîÎ†âÌÜ†Î¶¨: {self.rag_system.cache_dir}")
                    st.text(f"‚è±Ô∏è Ï∫êÏãú Ïú†Ìö®ÏãúÍ∞Ñ: {self.rag_system.cache_duration}")
                    st.text(f"üîç Í≤ÄÏÉâ ÏóîÏßÑ: ÎÑ§Ïù¥Î≤Ñ Îâ¥Ïä§ + Íµ¨Í∏Ä")
                    st.text(f"üìù ÏöîÏïΩ Î™®Îç∏: GPT-4o-mini")
                        
            except Exception as e:
                st.sidebar.error(f"RAG ÏãúÏä§ÌÖú Ïò§Î•ò: {e}")
        else:
            st.sidebar.error("‚ùå RAG ÏãúÏä§ÌÖú ÎπÑÌôúÏÑ±Ìôî")
            st.sidebar.info("""
            **RAG ÏãúÏä§ÌÖú ÌôúÏÑ±Ìôî Î∞©Î≤ï:**
            1. `src/rag/` ÎîîÎ†âÌÜ†Î¶¨Í∞Ä Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏
            2. OpenAI API ÌÇ§Í∞Ä ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÎäîÏßÄ ÌôïÏù∏
            3. ÌïÑÏöîÌïú Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò: `pip install requests beautifulsoup4`
            4. ÎåÄÏãúÎ≥¥Îìú Ïû¨ÏãúÏûë
            """)
        
        # ÌîÑÎ°¨ÌîÑÌä∏ Í¥ÄÎ¶¨ ÏãúÏä§ÌÖú UI
        st.sidebar.subheader("ü§ñ GPT ÌîÑÎ°¨ÌîÑÌä∏ Í¥ÄÎ¶¨")
        
        if PROMPT_MANAGER_AVAILABLE:
            st.sidebar.success("‚úÖ ÌîÑÎ°¨ÌîÑÌä∏ Îß§ÎãàÏ†Ä ÌôúÏÑ±Ìôî")
            
            try:
                prompt_manager = get_prompt_manager()
                prompt_info = prompt_manager.get_prompt_info()
                
                # ÌîÑÎ°¨ÌîÑÌä∏ ÏãúÏä§ÌÖú Ï†ïÎ≥¥ ÌëúÏãú
                st.sidebar.info(f"""
                **üìä ÌîÑÎ°¨ÌîÑÌä∏ ÌòÑÌô©**
                - ÌòÑÏû¨ ÎÇ†Ïßú: {prompt_info['market_context']['current_date']}
                - ÏãúÏû• Îã®Í≥Ñ: {prompt_info['market_context']['market_phase']}
                - ÏÇ¨Ïö© Í∞ÄÎä•Ìïú ÌîÑÎ°¨ÌîÑÌä∏: {len(prompt_info['available_prompt_types'])}Í∞ú
                - ÎßàÏßÄÎßâ ÏóÖÎç∞Ïù¥Ìä∏: {prompt_info['last_updated'][:19]}
                """)
                
                # ÏãúÏû• Ïª®ÌÖçÏä§Ìä∏ ÏóÖÎç∞Ïù¥Ìä∏ Î≤ÑÌäº
                if st.sidebar.button("üîÑ ÏãúÏû• Ïª®ÌÖçÏä§Ìä∏ ÏóÖÎç∞Ïù¥Ìä∏", key="update_market_context_btn", help="ÌòÑÏû¨ ÏãúÏû• ÏÉÅÌô©ÏùÑ Î∞òÏòÅÌïòÏó¨ ÌîÑÎ°¨ÌîÑÌä∏Î•º ÏóÖÎç∞Ïù¥Ìä∏Ìï©ÎãàÎã§"):
                    prompt_manager.update_market_context()
                    st.success("‚úÖ ÏãúÏû• Ïª®ÌÖçÏä§Ìä∏ ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å")
                    st.rerun()
                
                # ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï Ï†ïÎ≥¥
                with st.sidebar.expander("‚öôÔ∏è ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï"):
                    st.text(f"üìÅ ÌîÑÎ°¨ÌîÑÌä∏ ÎîîÎ†âÌÜ†Î¶¨: {prompt_info['prompts_directory']}")
                    st.text(f"üìä Ï£ºÏöî Ïö∞Î†§ÏÇ¨Ìï≠: {', '.join(prompt_info['market_context']['key_concerns'][:3])}...")
                    st.text(f"üé≤ ÏãúÎÇòÎ¶¨Ïò§ ÌôïÎ•†: ÎÇôÍ¥Ä {prompt_info['market_context']['scenario_probabilities']['optimistic']*100:.0%}, Í∏∞Î≥∏ {prompt_info['market_context']['scenario_probabilities']['baseline']*100:.0%}, ÎπÑÍ¥Ä {prompt_info['market_context']['scenario_probabilities']['pessimistic']*100:.0%}")
                
                # ÏãúÏû• Ìä∏Î†åÎìú Ï†ïÎ≥¥
                with st.sidebar.expander("üìà ÏãúÏû• Ìä∏Î†åÎìú"):
                    for trend in prompt_info['market_context']['industry_trends']:
                        st.text(f"‚Ä¢ {trend}")
                
            except Exception as e:
                st.sidebar.error(f"ÌîÑÎ°¨ÌîÑÌä∏ Îß§ÎãàÏ†Ä Ïò§Î•ò: {e}")
        else:
            st.sidebar.error("‚ùå ÌîÑÎ°¨ÌîÑÌä∏ Îß§ÎãàÏ†Ä ÎπÑÌôúÏÑ±Ìôî")
            st.sidebar.info("""
            **ÌîÑÎ°¨ÌîÑÌä∏ Îß§ÎãàÏ†Ä ÌôúÏÑ±Ìôî Î∞©Î≤ï:**
            1. `config/prompts.py` ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏
            2. Python Í≤ΩÎ°ú ÏÑ§Ï†ï ÌôïÏù∏
            3. ÎåÄÏãúÎ≥¥Îìú Ïû¨ÏãúÏûë
            """)
        
        # Main content
        if not MODEL_AVAILABLE:
            st.error("‚ùå Model modules are not available. Please check your installation.")
            return
        
        if not st.session_state.models_loaded_status or self.risk_scorer is None:
            st.info("üí° Please enable models using the checkbox in the sidebar to start analysis.")
            return
        
        # Get current data
        firms = self.get_sample_firms()
        
        with st.spinner("üìä Calculating current risk scores..."):
            risk_df = self.calculate_current_risks(firms)
        
        if risk_df.empty:
            st.error("‚ùå No risk data available")
            return
        
        # Key metrics row
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_risk = risk_df['overall_risk'].mean()
            st.metric("üìä Average Risk", f"{avg_risk:.1%}")
        
        with col2:
            high_risk_count = len(risk_df[risk_df['overall_risk'] > RISK_THRESHOLD])
            st.metric("‚ö†Ô∏è High Risk Firms", high_risk_count)
        
        with col3:
            max_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmax(), 'company_name']
            max_risk_value = risk_df['overall_risk'].max()
            st.metric("üî• Highest Risk", f"{max_risk_firm}", f"{max_risk_value:.1%}")
        
        with col4:
            last_update = datetime.now().strftime("%H:%M:%S")
            st.metric("üïê Last Update", last_update)
        
        st.markdown("---")
        
        # Tab interface
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìà Hazard Curves", "üìã Risk Table", "üî• Heatmap", "üö® Alerts", "üìä Ï¢ÖÌï©Î¶¨Ìè¨Ìä∏"])
        
        with tab1:
            # Company selection
            company_names = [firm.company_name for firm in firms]
            selected_companies = st.multiselect(
                "‚úàÔ∏è Select Airlines to Display",
                options=company_names,
                default=company_names,  # All companies selected by default
                help="Choose which airlines to show in the hazard curves",
                key="hazard_companies_multiselect"
            )
            
            if selected_companies:
                # Filter firms based on selection
                selected_firms = [firm for firm in firms if firm.company_name in selected_companies]
                
                with st.spinner("Generating hazard curves..."):
                    hazard_fig = self.generate_hazard_curves(selected_firms)
                
                st.plotly_chart(hazard_fig, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Please select at least one airline to display hazard curves.")
            
            # Interpretation
            st.info("""
            **üìä How to read the curves:**
            - **Overall Risk**: Probability of any rating change
            - **Upgrade Probability**: Chance of rating improvement  
            - **Downgrade Probability**: Risk of rating deterioration
            - **Default Risk**: Probability of default event
            """)
        
        with tab2:
            # Company selection for risk table
            table_companies = st.multiselect(
                "‚úàÔ∏è Select Airlines for Risk Table",
                options=company_names,
                default=company_names,  # All companies selected by default
                help="Choose which airlines to include in the risk table",
                key="table_selection"
            )
            
            if table_companies:
                # Filter and sort by overall risk (descending)
                filtered_table_df = risk_df[risk_df['company_name'].isin(table_companies)]
                risk_df_sorted = filtered_table_df.sort_values('overall_risk', ascending=False)
            else:
                st.warning("‚ö†Ô∏è Please select at least one airline for the risk table.")
                return
            
            # Style the dataframe
            def style_risk_table(df):
                def highlight_risk(val):
                    if val > RISK_THRESHOLD:
                        return 'background-color: #ffcccc; font-weight: bold'
                    elif val > RISK_THRESHOLD * 0.7:
                        return 'background-color: #fff2cc'
                    return ''
                
                return df.style.map(highlight_risk, subset=['overall_risk', 'downgrade_prob'])
            
            # Display table
            st.dataframe(
                style_risk_table(risk_df_sorted),
                use_container_width=True,
                column_config={
                    "overall_risk": st.column_config.ProgressColumn(
                        "Overall Risk",
                        help="90-day rating change probability",
                        min_value=0,
                        max_value=0.5,
                        format="%.3f"
                    ),
                    "upgrade_prob": st.column_config.ProgressColumn(
                        "Upgrade ‚ÜóÔ∏è",
                        min_value=0,
                        max_value=0.3,
                        format="%.3f"
                    ),
                    "downgrade_prob": st.column_config.ProgressColumn(
                        "Downgrade ‚ÜòÔ∏è",
                        min_value=0,
                        max_value=0.3,
                        format="%.3f"
                    ),
                    "default_prob": st.column_config.ProgressColumn(
                        "Default ‚ùå",
                        min_value=0,
                        max_value=0.1,
                        format="%.3f"
                    )
                }
            )
            
            # Export functionality
            csv = risk_df_sorted.to_csv(index=False)
            st.download_button(
                label="üì• Download CSV",
                data=csv,
                file_name=f"korean_airlines_risk_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
        
        with tab3:
            # Company selection for heatmap
            heatmap_companies = st.multiselect(
                "‚úàÔ∏è Select Airlines for Heatmap",
                options=company_names,
                default=company_names,  # All companies selected by default
                help="Choose which airlines to include in the heatmap",
                key="heatmap_selection"
            )
            
            if heatmap_companies:
                # Filter risk data based on selection
                filtered_risk_df = risk_df[risk_df['company_name'].isin(heatmap_companies)]
                heatmap_fig = self.create_risk_heatmap(filtered_risk_df)
                st.plotly_chart(heatmap_fig, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Please select at least one airline for the heatmap.")
            
            # Risk distribution chart
            st.subheader("üìä Risk Distribution")
            
            fig_dist = px.histogram(
                risk_df, 
                x='overall_risk', 
                nbins=10,
                title="Distribution of 90-Day Risk Scores",
                labels={'overall_risk': 'Risk Probability', 'count': 'Number of Firms'}
            )
            fig_dist.add_vline(x=RISK_THRESHOLD, line_dash="dash", line_color="red", 
                              annotation_text=f"Alert Threshold ({RISK_THRESHOLD:.1%})")
            
            st.plotly_chart(fig_dist, use_container_width=True)
        
        with tab4:
            # High risk firms
            high_risk_firms = risk_df[risk_df['overall_risk'] > RISK_THRESHOLD]
            
            if not high_risk_firms.empty:
                st.error(f"‚ö†Ô∏è {len(high_risk_firms)} firms exceed risk threshold ({RISK_THRESHOLD:.1%})")
                
                # Send alert button
                if st.button("üì± Send Slack Alert", key="send_slack_alert_btn"):
                    self.send_slack_alert(high_risk_firms)
                
                # Display high risk firms
                st.dataframe(high_risk_firms, use_container_width=True)
                
            else:
                st.success("‚úÖ No firms currently exceed the risk threshold")
            
            # Alert history
            st.subheader("üìú Alert History")
            
            if st.session_state.alert_history:
                for i, alert in enumerate(reversed(st.session_state.alert_history[-5:])):  # Last 5 alerts
                    with st.expander(f"Alert {len(st.session_state.alert_history)-i}: {alert['timestamp'].strftime('%Y-%m-%d %H:%M')}"):
                        st.write(f"**Firms:** {', '.join(alert['firms'])}")
                        st.text(alert['message'])
            else:
                st.info("No alerts sent yet")
        
        with tab5:
            st.markdown("### üéØ Ï¢ÖÌï© ÏúÑÌóò Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏")
            st.markdown("*ÌïúÍµ≠ Ìï≠Í≥µÏóÖÍ≥Ñ Ïã†Ïö©ÏúÑÌóò Ï¢ÖÌï© ÌèâÍ∞Ä Î∞è ÎåÄÏ∂ú Í∂åÍ≥†ÏÇ¨Ìï≠*")
            
            # Ìï≠Í≥µÏÇ¨ ÏÑ†ÌÉù Ï≤¥ÌÅ¨Î∞ïÏä§
            st.markdown("#### ‚úàÔ∏è Î∂ÑÏÑù ÎåÄÏÉÅ Ìï≠Í≥µÏÇ¨ ÏÑ†ÌÉù")
            st.info("üí° Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± Ï†ÑÏóê Î∂ÑÏÑùÌï† Ìï≠Í≥µÏÇ¨Î•º ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî. (ÏµúÏÜå 1Í∞ú Ïù¥ÏÉÅ ÏÑ†ÌÉù ÌïÑÏàò)")
            
            # Ï≤¥ÌÅ¨Î∞ïÏä§ Ïª¨ÎüºÏúºÎ°ú Î∞∞Ïπò
            col1, col2, col3, col4, col5 = st.columns(5)
            
            selected_airlines = []
            with col1:
                if st.checkbox("ÎåÄÌïúÌï≠Í≥µ", key="report_kal", value=True):
                    selected_airlines.append("ÎåÄÌïúÌï≠Í≥µ")
            with col2:
                if st.checkbox("ÏïÑÏãúÏïÑÎÇòÌï≠Í≥µ", key="report_asiana", value=True):
                    selected_airlines.append("ÏïÑÏãúÏïÑÎÇòÌï≠Í≥µ")
            with col3:
                if st.checkbox("Ï†úÏ£ºÌï≠Í≥µ", key="report_jeju", value=True):
                    selected_airlines.append("Ï†úÏ£ºÌï≠Í≥µ")
            with col4:
                if st.checkbox("Ìã∞Ïõ®Ïù¥Ìï≠Í≥µ", key="report_tway", value=True):
                    selected_airlines.append("Ìã∞Ïõ®Ïù¥Ìï≠Í≥µ")
            with col5:
                if st.checkbox("ÏóêÏñ¥Î∂ÄÏÇ∞", key="report_airbusan", value=True):  
                    selected_airlines.append("ÏóêÏñ¥Î∂ÄÏÇ∞")
            
            # ÏÑ†ÌÉùÎêú Ìï≠Í≥µÏÇ¨ ÌëúÏãú
            if selected_airlines:
                st.success(f"‚úÖ ÏÑ†ÌÉùÎêú Ìï≠Í≥µÏÇ¨: {', '.join(selected_airlines)} ({len(selected_airlines)}Í∞ú)")
            else:
                st.warning("‚ö†Ô∏è Î∂ÑÏÑùÌï† Ìï≠Í≥µÏÇ¨Î•º ÏµúÏÜå 1Í∞ú Ïù¥ÏÉÅ ÏÑ†ÌÉùÌï¥Ï£ºÏÑ∏Ïöî.")
            
            # Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± Î≤ÑÌäº (ÏÑ†ÌÉùÎêú Ìï≠Í≥µÏÇ¨Í∞Ä ÏûàÏùÑ ÎïåÎßå ÌôúÏÑ±Ìôî)
            if selected_airlines:
                if st.button("üìã Ï¢ÖÌï©Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±ÌïòÍ∏∞", key="comprehensive_report_btn", type="primary"):
                    # ÏÑ†ÌÉùÎêú Ìï≠Í≥µÏÇ¨Ïóê Ìï¥ÎãπÌïòÎäî Îç∞Ïù¥ÌÑ∞Îßå ÌïÑÌÑ∞ÎßÅ
                    selected_risk_df = risk_df[risk_df['company_name'].isin(selected_airlines)]
                    selected_firms = [firm for firm in firms if firm.company_name in selected_airlines]
                    
                    with st.spinner("üß† AIÍ∞Ä Ï¢ÖÌï© Î∂ÑÏÑù Î¶¨Ìè¨Ìä∏Î•º ÏûëÏÑ± Ï§ëÏûÖÎãàÎã§..."):
                        comprehensive_report = self.generate_comprehensive_report(selected_risk_df, selected_firms)
                        st.session_state.comprehensive_report = comprehensive_report
                        st.session_state.last_selected_airlines = selected_airlines.copy()
                        
                    # ÏÑ†ÌÉùÎêú Ìï≠Í≥µÏÇ¨ ÌôïÏù∏ Î©îÏãúÏßÄ Ï∂îÍ∞Ä
                    st.info(f"üìä Î∂ÑÏÑù ÏôÑÎ£å: {', '.join(selected_airlines)} ({len(selected_airlines)}Í∞ú Ìï≠Î™© Í∏∞Ï§ÄÏúºÎ°ú Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±)")
            else:
                st.button("üìã Ï¢ÖÌï©Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±ÌïòÍ∏∞", key="comprehensive_report_btn_disabled", disabled=True, help="Ìï≠Í≥µÏÇ¨Î•º ÏÑ†ÌÉùÌïú ÌõÑ Î¶¨Ìè¨Ìä∏Î•º ÏÉùÏÑ±Ìï† Ïàò ÏûàÏäµÎãàÎã§.")
            
            # Î¶¨Ìè¨Ìä∏ ÌëúÏãú
            if 'comprehensive_report' in st.session_state and st.session_state.comprehensive_report:
                st.markdown("---")
                
                # Î∂ÑÏÑù ÎåÄÏÉÅ Ìï≠Í≥µÏÇ¨ ÌëúÏãú
                if 'last_selected_airlines' in st.session_state:
                    selected_count = len(st.session_state.last_selected_airlines)
                    st.success(f"üéØ **Î∂ÑÏÑù ÎåÄÏÉÅ**: {', '.join(st.session_state.last_selected_airlines)} (Ï¥ù {selected_count}Í∞ú Ìï≠Í≥µÏÇ¨)")
                
                st.markdown(st.session_state.comprehensive_report, unsafe_allow_html=True)
                
                # Î¶¨Ìè¨Ìä∏ ÏßÄÏö∞Í∏∞ Î≤ÑÌäº
                if st.button("üóëÔ∏è Î¶¨Ìè¨Ìä∏ ÏßÄÏö∞Í∏∞", key="clear_comprehensive_report"):
                    st.session_state.comprehensive_report = None
                    st.rerun()
            else:
                st.info("üí° Ï¢ÖÌï©Î¶¨Ìè¨Ìä∏Î•º ÏÉùÏÑ±ÌïòÎ†§Î©¥ ÏúÑÏùò Î≤ÑÌäºÏùÑ ÌÅ¥Î¶≠Ìï¥Ï£ºÏÑ∏Ïöî.")
        
        # Footer
        st.markdown("---")
        
        # Show data source information
        try:
            # Try different import paths for config
            try:
                from config.config import USE_REAL_DATA
            except ImportError:
                from config import USE_REAL_DATA
            data_source = "üéØ Real DART Financial Data" if USE_REAL_DATA else "‚ö° Fast Dummy Data (Development Mode)"
        except ImportError:
            data_source = "‚ö° Fast Dummy Data (Development Mode)"
        
        st.markdown(f"""
        **üè¢ Korean Airlines Credit Risk Dashboard** | 
        Data refreshed: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} | 
        Model: Multi-State Hazard with Financial Covariates | 
        Source: {data_source}
        """)

def main():
    """Main application entry point"""
    # Create dashboard instance only once per session  
    if 'dashboard_instance' not in st.session_state:
        st.session_state.dashboard_instance = CreditRatingDashboard()
    
    st.session_state.dashboard_instance.run_dashboard()

if __name__ == "__main__":
    main() 