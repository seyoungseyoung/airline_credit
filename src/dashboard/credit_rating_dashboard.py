#!/usr/bin/env python3
"""
Credit Rating Risk Dashboard
============================

Streamlit-based dashboard for Korean Airlines credit rating monitoring:
1. Enterprise Hazard Curves visualization
2. 90-day Risk Top N Table  
3. Slack Webhook alerts for high-risk situations
4. Real-time monitoring for investment & risk teams

Author: Korean Airlines Credit Rating Analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import requests
import json
from typing import Dict, List, Tuple, Optional, Any
import warnings
import os
import logging

# Set up logging for debugging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Import our models
try:
    import sys
    import os
    # Add parent directories to path
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)  # src/
    root_dir = os.path.dirname(parent_dir)     # project root
    
    # Add all necessary paths in specific order
    paths_to_add = [
        parent_dir,  # src/
        root_dir,    # project root
        os.path.join(parent_dir, 'data'),    # src/data/
        os.path.join(parent_dir, 'utils'),   # src/utils/
        os.path.join(parent_dir, 'models'),  # src/models/
        os.path.join(parent_dir, 'rag'),     # src/rag/
        os.path.join(root_dir, 'config')     # config/
    ]
    
    for path in paths_to_add:
        if path not in sys.path:
            sys.path.insert(0, path)
    
    print(f"ğŸ”§ [DASHBOARD] Added {len(paths_to_add)} paths to Python path")
    
    # Import cache system (after path setup)
    try:
        from data.dart_data_cache import get_global_cache, DARTDataCache
        CACHE_AVAILABLE = True
        print("âœ… Cache system loaded successfully")
    except ImportError:
        try:
            from src.data.dart_data_cache import get_global_cache, DARTDataCache
            CACHE_AVAILABLE = True
            print("âœ… Cache system loaded from src.data path")
        except ImportError:
            CACHE_AVAILABLE = False
            print("âŒ Cache system not available")
    
    # Try different import strategies
    try:
        from models.rating_risk_scorer import RatingRiskScorer, FirmProfile
        from models.enhanced_multistate_model import EnhancedMultiStateModel
        from models.backtest_framework import CreditRatingBacktester
    except ImportError:
        # Try absolute imports from src
        from src.models.rating_risk_scorer import RatingRiskScorer, FirmProfile
        from src.models.enhanced_multistate_model import EnhancedMultiStateModel
        from src.models.backtest_framework import CreditRatingBacktester
    
    MODEL_AVAILABLE = True
    print("âœ… Model modules loaded successfully")
    
except ImportError as e:
    print(f"âŒ Model modules not available: {e}")
    print(f"Current working directory: {os.getcwd()}")
    print(f"Python path: {sys.path[:5]}")  # Show first 5 paths
    MODEL_AVAILABLE = False

# Configuration
RISK_THRESHOLD = 0.15  # 15% change probability threshold for alerts
SLACK_WEBHOOK_URL = None  # Set this to your Slack webhook URL

# OpenAI Configuration

# Import prompt manager
try:
    from config.prompts import get_prompt_manager
    PROMPT_MANAGER_AVAILABLE = True
    print("âœ… Prompt manager loaded successfully")
except ImportError:
    try:
        import sys
        sys.path.insert(0, os.path.join(root_dir, 'config'))
        from prompts import get_prompt_manager
        PROMPT_MANAGER_AVAILABLE = True
        print("âœ… Prompt manager loaded with explicit path")
    except ImportError:
        try:
            from config.prompts import get_prompt_manager
            PROMPT_MANAGER_AVAILABLE = True
            print("âœ… Prompt manager loaded from config.prompts")
        except ImportError:
            PROMPT_MANAGER_AVAILABLE = False
            print("âŒ Prompt manager not available")

# Import RAG system
try:
    from src.rag.airline_industry_rag import AirlineIndustryRAG
    RAG_AVAILABLE = True
    print("âœ… RAG system loaded successfully")
except ImportError:
    try:
        from rag.airline_industry_rag import AirlineIndustryRAG
        RAG_AVAILABLE = True
        print("âœ… RAG system loaded from rag path")
    except ImportError:
        try:
            import sys
            sys.path.insert(0, os.path.join(parent_dir, 'rag'))
            from airline_industry_rag import AirlineIndustryRAG
            RAG_AVAILABLE = True
            print("âœ… RAG system loaded with explicit path")
        except ImportError:
            try:
                from src.rag.airline_industry_rag import AirlineIndustryRAG
                RAG_AVAILABLE = True
                print("âœ… RAG system loaded from src.rag")
            except ImportError:
                RAG_AVAILABLE = False
                print("âŒ RAG system not available")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your_openai_api_key_here")

class CreditRatingDashboard:
    """
    Main dashboard class for credit rating monitoring
    """
    
    def __init__(self):
        """Initialize dashboard"""
        self.risk_scorer = None
        self.current_scores = None
        self.historical_data = None
        
        # Initialize RAG system
        if RAG_AVAILABLE and OPENAI_API_KEY != "your_openai_api_key_here":
            try:
                self.rag_system = AirlineIndustryRAG(OPENAI_API_KEY)
                self.rag_available = True
                print("âœ… RAG system initialized successfully")
            except Exception as e:
                print(f"âŒ RAG system initialization failed: {e}")
                self.rag_available = False
        else:
            self.rag_available = False
            if not RAG_AVAILABLE:
                print("âŒ RAG system not available")
            if OPENAI_API_KEY == "your_openai_api_key_here":
                print("âŒ OpenAI API key not set")
        
        # Initialize session state
        if 'last_update' not in st.session_state:
            st.session_state.last_update = datetime.now()
        if 'alert_history' not in st.session_state:
            st.session_state.alert_history = []
        if 'hazard_report' not in st.session_state:
            st.session_state.hazard_report = None
        if 'risk_table_report' not in st.session_state:
            st.session_state.risk_table_report = None
        if 'heatmap_report' not in st.session_state:
            st.session_state.heatmap_report = None
        if 'alerts_report' not in st.session_state:
            st.session_state.alerts_report = None
        if 'current_tab' not in st.session_state:
            st.session_state.current_tab = "ğŸ“ˆ Hazard Curves"
        if 'hazard_companies_selection' not in st.session_state:
            st.session_state.hazard_companies_selection = None
        if 'table_companies_selection' not in st.session_state:
            st.session_state.table_companies_selection = None
        if 'heatmap_companies_selection' not in st.session_state:
            st.session_state.heatmap_companies_selection = None
        if 'alerts_threshold_value' not in st.session_state:
            st.session_state.alerts_threshold_value = None
        if 'models_loaded_status' not in st.session_state:
            st.session_state.models_loaded_status = False
        if 'rag_context' not in st.session_state:
            st.session_state.rag_context = None
        if 'rag_last_update' not in st.session_state:
            st.session_state.rag_last_update = None
    
    def load_models(self):
        """Load and initialize risk scoring models"""
        
        logger.info("[LOAD_MODELS] Starting model loading process...")
        
        if not MODEL_AVAILABLE:
            logger.error("[LOAD_MODELS] Models not available")
            st.error("Models not available")
            return False
        
        try:
            logger.info("[LOAD_MODELS] Creating spinner for model loading...")
            with st.spinner("ğŸ‹ï¸ Loading risk scoring models..."):
                logger.info("[LOAD_MODELS] Initializing RatingRiskScorer...")
                
                # ì•ˆì „í•œ ëª¨ë¸ ë¡œë”© (ìºì‹œ ìš°ì„ , í•„ìš”ì‹œì—ë§Œ DART ë°ì´í„° ìˆ˜ì§‘)
                try:
                    # íƒ€ì„ì•„ì›ƒ ì„¤ì •ì„ ìœ„í•œ ì‹œë„ íšŸìˆ˜ ì œí•œ
                    max_retries = 2
                    retry_count = 0
                    
                    while retry_count < max_retries:
                        try:
                            logger.info(f"[LOAD_MODELS] Attempt {retry_count + 1} to create RatingRiskScorer...")
                            
                            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
                            import psutil
                            process = psutil.Process()
                            memory_before = process.memory_info().rss / 1024 / 1024  # MB
                            logger.info(f"[LOAD_MODELS] Memory usage before: {memory_before:.2f} MB")
                            
                            # RatingRiskScorer ìƒì„± (íƒ€ì„ì•„ì›ƒ ë³´í˜¸)
                            import signal
                            import threading
                            import time
                            
                            # íƒ€ì„ì•„ì›ƒ ì„¤ì • (5ë¶„)
                            timeout_seconds = 300
                            result = [None]
                            exception = [None]
                            
                            def create_scorer():
                                try:
                                    result[0] = RatingRiskScorer(use_financial_data=True)
                                except Exception as e:
                                    exception[0] = e
                            
                            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                            thread = threading.Thread(target=create_scorer)
                            thread.daemon = True
                            thread.start()
                            
                            # íƒ€ì„ì•„ì›ƒ ëŒ€ê¸°
                            thread.join(timeout_seconds)
                            
                            if thread.is_alive():
                                logger.error(f"[LOAD_MODELS] Timeout after {timeout_seconds} seconds")
                                st.error(f"âŒ Model loading timed out after {timeout_seconds} seconds")
                                return False
                            
                            if exception[0] is not None:
                                raise exception[0]
                            
                            self.risk_scorer = result[0]
                            
                            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
                            memory_after = process.memory_info().rss / 1024 / 1024  # MB
                            logger.info(f"[LOAD_MODELS] Memory usage after: {memory_after:.2f} MB")
                            logger.info(f"[LOAD_MODELS] Memory increase: {memory_after - memory_before:.2f} MB")
                            
                            logger.info("[LOAD_MODELS] RatingRiskScorer created successfully")
                            break
                            
                        except Exception as e:
                            retry_count += 1
                            logger.warning(f"[LOAD_MODELS] Attempt {retry_count} failed: {e}")
                            
                            if retry_count >= max_retries:
                                logger.error(f"[LOAD_MODELS] All {max_retries} attempts failed")
                                raise e
                            
                            # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
                            time.sleep(2)
                    
                except Exception as model_error:
                    logger.error(f"[LOAD_MODELS] Model loading failed: {model_error}")
                    st.warning(f"âš ï¸ Model loading failed: {model_error}")
                    st.info("ğŸ’¡ Using sample data for demonstration")
                    return False
                    
            logger.info("[LOAD_MODELS] Model loading completed successfully")
            st.success("âœ… Models loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"[LOAD_MODELS] Error loading models: {e}")
            st.error(f"âŒ Error loading models: {e}")
            st.info("ğŸ’¡ Using sample data for demonstration")
            return False
    
    def get_sample_firms(self) -> List[FirmProfile]:
        """Get sample Korean airline firms with current financial data"""
        
        return [
            FirmProfile(
                company_name="ëŒ€í•œí•­ê³µ",
                current_rating="A",
                debt_to_assets=0.65,
                current_ratio=0.8,
                roa=0.02,
                roe=0.05,
                operating_margin=0.03,
                equity_ratio=0.35,
                asset_turnover=0.6,
                interest_coverage=2.5,
                quick_ratio=0.7,
                working_capital_ratio=0.1
            ),
            FirmProfile(
                company_name="ì•„ì‹œì•„ë‚˜í•­ê³µ",
                current_rating="B",
                debt_to_assets=0.85,
                current_ratio=0.6,
                roa=-0.02,
                roe=-0.05,
                operating_margin=-0.01,
                equity_ratio=0.15,
                asset_turnover=0.5,
                interest_coverage=1.2,
                quick_ratio=0.5,
                working_capital_ratio=-0.05
            ),
            FirmProfile(
                company_name="ì œì£¼í•­ê³µ",
                current_rating="BBB",
                debt_to_assets=0.55,
                current_ratio=1.1,
                roa=0.04,
                roe=0.08,
                operating_margin=0.06,
                equity_ratio=0.45,
                asset_turnover=0.8,
                interest_coverage=3.5,
                quick_ratio=1.0,
                working_capital_ratio=0.15
            ),
            FirmProfile(
                company_name="í‹°ì›¨ì´í•­ê³µ",
                current_rating="BB",
                debt_to_assets=0.60,
                current_ratio=0.9,
                roa=0.01,
                roe=0.03,
                operating_margin=0.02,
                equity_ratio=0.40,
                asset_turnover=0.7,
                interest_coverage=2.0,
                quick_ratio=0.8,
                working_capital_ratio=0.05
            ),
            FirmProfile(
                company_name="ì—ì–´ë¶€ì‚°",
                current_rating="B",
                debt_to_assets=0.70,
                current_ratio=0.7,
                roa=-0.01,
                roe=0.01,
                operating_margin=0.01,
                equity_ratio=0.30,
                asset_turnover=0.6,
                interest_coverage=1.8,
                quick_ratio=0.6,
                working_capital_ratio=0.02
            )
        ]
    
    def calculate_current_risks(self, firms: List[FirmProfile]) -> pd.DataFrame:
        """Calculate current risk scores for all firms"""
        
        if self.risk_scorer is None:
            return pd.DataFrame()
        
        risk_data = []
        
        for firm in firms:
            try:
                risk_assessment = self.risk_scorer.score_firm(firm, horizon=90)
                
                risk_data.append({
                    'company_name': firm.company_name,
                    'current_rating': firm.current_rating,
                    'overall_risk': risk_assessment['overall_change_probability'],
                    'upgrade_prob': risk_assessment['upgrade_probability'],
                    'downgrade_prob': risk_assessment['downgrade_probability'],
                    'default_prob': risk_assessment['default_probability'],
                    'risk_classification': risk_assessment['risk_classification'],
                    'last_updated': datetime.now().strftime("%Y-%m-%d %H:%M")
                })
                
            except Exception as e:
                st.warning(f"âš ï¸ Error calculating risk for {firm.company_name}: {e}")
                continue
        
        return pd.DataFrame(risk_data)
    
    def generate_gpt4_report(self, prompt: str, context_data: str) -> str:
        """Generate comprehensive report using GPT-4-Turbo for bank loan officers"""
        
        if not OPENAI_AVAILABLE:
            return "âŒ OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `pip install openai`ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        rag_context = ""
        if self.rag_available:
            try:
                rag_context = self.rag_system.get_prompt_context()
            except Exception as e:
                st.warning(f"âš ï¸ RAG ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        # í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©
        if PROMPT_MANAGER_AVAILABLE:
            try:
                prompt_manager = get_prompt_manager()
                system_prompts = prompt_manager.get_system_prompt("comprehensive_report")
                system_prompt = {"role": "system", "content": system_prompts.get("comprehensive_report", "ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¤‘ì€í–‰ì˜ ê¸°ì—…ê¸ˆìœµ ëŒ€ì¶œì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")}
                user_prompt = prompt_manager.get_user_prompt("comprehensive_report", 
                                                           prompt=prompt, 
                                                           context_data=context_data)
                
                # RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
                if rag_context:
                    user_prompt += f"\n\n{rag_context}"
                    
            except Exception as e:
                st.warning(f"âš ï¸ í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì˜¤ë¥˜, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©: {e}")
                # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ í´ë°±
                system_prompt = {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¤‘ì€í–‰ì˜ ê¸°ì—…ê¸ˆìœµ ëŒ€ì¶œì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."}
                user_prompt = f"ë¶„ì„ ìš”ì²­: {prompt}\n\nëŒ€ì‹œë³´ë“œ ë°ì´í„°: {context_data}"
                if rag_context:
                    user_prompt += f"\n\n{rag_context}"
        else:
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            system_prompt = {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¤‘ì€í–‰ì˜ ê¸°ì—…ê¸ˆìœµ ëŒ€ì¶œì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."}
            user_prompt = f"ë¶„ì„ ìš”ì²­: {prompt}\n\nëŒ€ì‹œë³´ë“œ ë°ì´í„°: {context_data}"
            if rag_context:
                user_prompt += f"\n\n{rag_context}"
        
        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            response = client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[system_prompt, {"role": "user", "content": user_prompt}],
                max_tokens=4096,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"âŒ ë ˆí¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\nğŸ’¡ OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    def generate_comprehensive_report(self, risk_df: pd.DataFrame, firms: List) -> str:
        """Generate comprehensive integrated report combining analysis and actionable recommendations"""
        
        if not OPENAI_AVAILABLE:
            return "âŒ OpenAI íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `pip install openai`ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        
        # ë°ì´í„° ë¶„ì„
        high_risk_firms = risk_df[risk_df['overall_risk'] > RISK_THRESHOLD]
        avg_risk = risk_df['overall_risk'].mean()
        max_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmax()]
        min_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmin()]
        
        # ì—…ê·¸ë ˆì´ë“œ/ë‹¤ìš´ê·¸ë ˆì´ë“œ ê°€ëŠ¥ì„± ë¶„ì„
        upgrade_candidates = risk_df[risk_df['upgrade_prob'] > 0.1].sort_values('upgrade_prob', ascending=False)
        downgrade_risks = risk_df[risk_df['downgrade_prob'] > 0.05].sort_values('downgrade_prob', ascending=False)
        
        # ìµœê·¼ ì•Œë¦¼ ì´ë ¥
        recent_alerts = st.session_state.get('alert_history', [])[-3:]
        
        # ë¶„ì„ ëŒ€ìƒ ê¸°ì—…ëª… ë¦¬ìŠ¤íŠ¸ ìƒì„±
        firm_names = [firm.company_name for firm in firms]
        
        # ê° ê¸°ì—…ì˜ ìƒì„¸ ì¬ë¬´ì •ë³´ ìƒì„±
        detailed_firm_info = []
        for firm in firms:
            firm_detail = f"""
â—ˆ **{firm.company_name}** (í˜„ì¬ë“±ê¸‰: {firm.current_rating})
   ì¬ë¬´ê±´ì „ì„± ì§€í‘œ:
   - ë¶€ì±„ë¹„ìœ¨: {firm.debt_to_assets:.1%} | ìœ ë™ë¹„ìœ¨: {firm.current_ratio:.2f} | ë‹¹ì¢Œë¹„ìœ¨: {firm.quick_ratio:.2f}
   - ROA: {firm.roa:.1%} | ROE: {firm.roe:.1%} | ì˜ì—…ì´ìµë¥ : {firm.operating_margin:.1%}
   - ìê¸°ìë³¸ë¹„ìœ¨: {firm.equity_ratio:.1%} | ìì‚°íšŒì „ìœ¨: {firm.asset_turnover:.2f}
   - ì´ìë³´ìƒë°°ìœ¨: {firm.interest_coverage:.1f} | ìš´ì „ìë³¸ë¹„ìœ¨: {firm.working_capital_ratio:.1%}
            """
            
            # í•´ë‹¹ ê¸°ì—…ì˜ ìœ„í—˜ë„ ì •ë³´ ì¶”ê°€
            firm_risk = risk_df[risk_df['company_name'] == firm.company_name]
            if not firm_risk.empty:
                risk_row = firm_risk.iloc[0]
                firm_detail += f"""
   ì‹ ìš©ìœ„í—˜ í˜„í™©:
   - 90ì¼ ì „ì²´ë³€ë™ìœ„í—˜: {risk_row['overall_risk']:.3%}
   - ë“±ê¸‰ìƒìŠ¹ í™•ë¥ : {risk_row['upgrade_prob']:.3%} | ë“±ê¸‰í•˜ë½ í™•ë¥ : {risk_row['downgrade_prob']:.3%}
   - ë¶€ë„ë°œìƒ í™•ë¥ : {risk_row['default_prob']:.3%} | ìœ„í—˜ë¶„ë¥˜: {risk_row['risk_classification']}
                """
            detailed_firm_info.append(firm_detail)
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        rag_context = ""
        if self.rag_available:
            try:
                rag_context = self.rag_system.get_prompt_context()
            except Exception as e:
                st.warning(f"âš ï¸ RAG ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        # í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©
        if PROMPT_MANAGER_AVAILABLE:
            try:
                prompt_manager = get_prompt_manager()
                system_prompts = prompt_manager.get_system_prompt("comprehensive_report")
                system_prompt = {"role": "system", "content": system_prompts.get("comprehensive_report", "ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¤‘ì€í–‰ì˜ ê¸°ì—…ê¸ˆìœµíŒ€ì¥ì…ë‹ˆë‹¤.")}
                user_prompt = prompt_manager.get_user_prompt("comprehensive_report",
                    company_count=len(risk_df),
                    company_names=', '.join(firm_names),
                    current_date=datetime.now().strftime('%Yë…„ %mì›” %dì¼'),
                    avg_risk=avg_risk,
                    high_risk_count=len(high_risk_firms),
                    risk_threshold=RISK_THRESHOLD,
                    max_risk_company=max_risk_firm['company_name'],
                    max_risk_value=max_risk_firm['overall_risk'],
                    min_risk_company=min_risk_firm['company_name'],
                    min_risk_value=min_risk_firm['overall_risk'],
                    risk_std=risk_df['overall_risk'].std(),
                    detailed_firm_info=''.join(detailed_firm_info),
                    upgrade_candidates_info=upgrade_candidates[['company_name', 'upgrade_prob', 'current_rating']].to_string() if not upgrade_candidates.empty else "í˜„ì¬ ë“±ê¸‰ ê°œì„ ì´ ì˜ˆìƒë˜ëŠ” ê¸°ì—… ì—†ìŒ",
                    downgrade_risks_info=downgrade_risks[['company_name', 'downgrade_prob', 'current_rating']].to_string() if not downgrade_risks.empty else "í˜„ì¬ ë“±ê¸‰ ì•…í™”ê°€ ìš°ë ¤ë˜ëŠ” ê¸°ì—… ì—†ìŒ",
                    risk_q25=risk_df['overall_risk'].quantile(0.25),
                    risk_q50=risk_df['overall_risk'].quantile(0.5),
                    risk_q75=risk_df['overall_risk'].quantile(0.75),
                    recent_alerts_info=f"ìµœê·¼ {len(recent_alerts)}ê±´ì˜ ê³ ìœ„í—˜ ì•Œë¦¼ ë°œìƒ - ì‹œìŠ¤í…œ í™œì„± ëª¨ë‹ˆí„°ë§ ì¤‘" if recent_alerts else "ìµœê·¼ ì•Œë¦¼ ì—†ìŒ - í¬íŠ¸í´ë¦¬ì˜¤ ì•ˆì •ì  ìš´ì˜"
                )
                
                # RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
                if rag_context:
                    user_prompt += f"\n\n{rag_context}"
                    
            except Exception as e:
                st.warning(f"âš ï¸ í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì˜¤ë¥˜, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©: {e}")
                # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ í´ë°±
                system_prompt = {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¤‘ì€í–‰ì˜ ê¸°ì—…ê¸ˆìœµíŒ€ì¥ì…ë‹ˆë‹¤."}
                user_prompt = f"í•­ê³µì—…ê³„ ì‹ ìš©ìœ„í—˜ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë°ì´í„°: {risk_df.to_string()}"
                if rag_context:
                    user_prompt += f"\n\n{rag_context}"
        else:
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            system_prompt = {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ ì‹œì¤‘ì€í–‰ì˜ ê¸°ì—…ê¸ˆìœµíŒ€ì¥ì…ë‹ˆë‹¤."}
            user_prompt = f"í•­ê³µì—…ê³„ ì‹ ìš©ìœ„í—˜ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ë°ì´í„°: {risk_df.to_string()}"
            if rag_context:
                user_prompt += f"\n\n{rag_context}"

        try:
            client = OpenAI(api_key=OPENAI_API_KEY)
            
            response = client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[system_prompt, {"role": "user", "content": user_prompt}],
                max_tokens=4096,  # í† í° ì œí•œ ë¬¸ì œ í•´ê²°
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"âŒ ì¢…í•©ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\nğŸ’¡ OpenAI API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    def generate_hazard_curves_report(self, firms: List[FirmProfile]) -> str:
        """Generate comprehensive hazard curves report for bank loan officers"""
        
        if self.risk_scorer is None:
            return "âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”."
        
        # ì „ì²´ í™”ë©´ í‘œì‹œ ë°ì´í„° ìˆ˜ì§‘
        risk_data = []
        horizons = [30, 60, 90, 120, 180, 270, 365]
        
        for firm in firms:
            # ê° ê¸°ì—…ì˜ ì¬ë¬´ì •ë³´
            firm_info = {
                'company': firm.company_name,
                'current_rating': firm.current_rating,
                'debt_to_assets': firm.debt_to_assets,
                'current_ratio': firm.current_ratio,
                'roa': firm.roa,
                'roe': firm.roe,
                'operating_margin': firm.operating_margin,
                'equity_ratio': firm.equity_ratio,
                'asset_turnover': firm.asset_turnover,
                'interest_coverage': firm.interest_coverage,
                'quick_ratio': firm.quick_ratio,
                'working_capital_ratio': firm.working_capital_ratio
            }
            
            # ì‹œê³„ì—´ ìœ„í—˜ë„ ë°ì´í„°
            horizon_risks = []
            for horizon in horizons:
                try:
                    risk = self.risk_scorer.score_firm(firm, horizon=horizon)
                    horizon_risks.append({
                        'horizon': horizon,
                        'overall_risk': risk['overall_change_probability'],
                        'upgrade_prob': risk['upgrade_probability'],
                        'downgrade_prob': risk['downgrade_probability'],
                        'default_prob': risk['default_probability'],
                        'risk_classification': risk['risk_classification']
                    })
                except Exception as e:
                    continue
            
            firm_info['horizon_risks'] = horizon_risks
            risk_data.append(firm_info)
        
        # í¬íŠ¸í´ë¦¬ì˜¤ í†µê³„
        all_90d_risks = []
        all_365d_risks = []
        
        for firm_data in risk_data:
            for risk in firm_data['horizon_risks']:
                if risk['horizon'] == 90:
                    all_90d_risks.append(risk['overall_risk'])
                elif risk['horizon'] == 365:
                    all_365d_risks.append(risk['overall_risk'])
        
        # ëŒ€ì‹œë³´ë“œ í™”ë©´ í‘œì‹œ ë°ì´í„° ì „ì²´ ì •ë¦¬
        context = f"""
=== ëŒ€ì¶œì‹¬ì‚¬ìš© Hazard Curves ë¶„ì„ ë°ì´í„° ===

ì„ íƒ ë¶„ì„ ëŒ€ìƒ: {len(firms)}ê°œ í•­ê³µì‚¬ ({', '.join([f.company_name for f in firms])})
ë¶„ì„ ì‹œê³„: 30ì¼, 60ì¼, 90ì¼, 120ì¼, 180ì¼, 270ì¼, 365ì¼

=== ê° í•­ê³µì‚¬ë³„ ìƒì„¸ ì •ë³´ ===
"""
        
        for firm_data in risk_data:
            context += f"""
â—ˆ {firm_data['company']} (í˜„ì¬ë“±ê¸‰: {firm_data['current_rating']})
  [ì¬ë¬´ì§€í‘œ]
  - ë¶€ì±„ë¹„ìœ¨: {firm_data['debt_to_assets']:.1%}
  - ìœ ë™ë¹„ìœ¨: {firm_data['current_ratio']:.2f}
  - ROA: {firm_data['roa']:.1%}
  - ROE: {firm_data['roe']:.1%}
  - ì˜ì—…ì´ìµë¥ : {firm_data['operating_margin']:.1%}
  - ìê¸°ìë³¸ë¹„ìœ¨: {firm_data['equity_ratio']:.1%}
  - ìì‚°íšŒì „ìœ¨: {firm_data['asset_turnover']:.2f}
  - ì´ìë³´ìƒë°°ìœ¨: {firm_data['interest_coverage']:.1f}
  - ë‹¹ì¢Œë¹„ìœ¨: {firm_data['quick_ratio']:.2f}
  - ìš´ì „ìë³¸ë¹„ìœ¨: {firm_data['working_capital_ratio']:.1%}
  
  [ì‹œê³„ì—´ ì‹ ìš©ìœ„í—˜ ì „ë§]"""
            
            for risk in firm_data['horizon_risks']:
                context += f"""
  - {risk['horizon']:3d}ì¼ í›„: ì „ì²´ë³€ë™ {risk['overall_risk']:.2%}, ë“±ê¸‰ìƒìŠ¹ {risk['upgrade_prob']:.2%}, ë“±ê¸‰í•˜ë½ {risk['downgrade_prob']:.2%}, ë¶€ë„ìœ„í—˜ {risk['default_prob']:.3%} ({risk['risk_classification']})"""
        
        context += f"""

=== í¬íŠ¸í´ë¦¬ì˜¤ ìœ„í—˜ ì§‘ê³„ ===
- 90ì¼ í‰ê· ìœ„í—˜ë„: {np.mean(all_90d_risks):.2%}
- 90ì¼ ìµœëŒ€ìœ„í—˜ë„: {np.max(all_90d_risks):.2%}
- 90ì¼ ìµœì†Œìœ„í—˜ë„: {np.min(all_90d_risks):.2%}
- 365ì¼ í‰ê· ìœ„í—˜ë„: {np.mean(all_365d_risks):.2%}
- 365ì¼ ìµœëŒ€ìœ„í—˜ë„: {np.max(all_365d_risks):.2%}
- 365ì¼ ìµœì†Œìœ„í—˜ë„: {np.min(all_365d_risks):.2%}

=== ì°¨íŠ¸ í•´ì„ ê°€ì´ë“œ (ëŒ€ì‹œë³´ë“œ í™”ë©´ ê¸°ì¤€) ===
- Overall Risk: 90ì¼ ë‚´ ì‹ ìš©ë“±ê¸‰ ë³€ë™ í™•ë¥  (ëŒ€ì¶œì‹¬ì‚¬ í•µì‹¬ì§€í‘œ)
- Upgrade Probability: ë“±ê¸‰ ê°œì„  ê°€ëŠ¥ì„± (ê¸ì •ì  ì‹ í˜¸)
- Downgrade Probability: ë“±ê¸‰ ì•…í™” ìœ„í—˜ (ì—¬ì‹  ì£¼ì˜ì§€í‘œ)
- Default Risk: ë¶€ë„ ë°œìƒ ê°€ëŠ¥ì„± (ì—¬ì‹ ì†ì‹¤ ì§ê²°)
"""
        
        prompt = """ëŒ€ì‹œë³´ë“œì˜ Hazard Curves íƒ­ì—ì„œ í‘œì‹œë˜ëŠ” ì‹œê³„ì—´ ì‹ ìš©ìœ„í—˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, 
        ì€í–‰ ëŒ€ì¶œì‹¬ì‚¬ ë° ì—¬ì‹ ê´€ë¦¬ ê´€ì ì—ì„œ ë‹¤ìŒ ì‚¬í•­ì„ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1) ê° í•­ê³µì‚¬ë³„ ì‹œê°„ëŒ€ë³„ ì‹ ìš©ìœ„í—˜ ê¶¤ì  ë¶„ì„ ë° ì—¬ì‹ ì‹¬ì‚¬ ë“±ê¸‰ íŒì •
        2) ì¬ë¬´ì§€í‘œì™€ ìœ„í—˜ë„ ë³€í™”ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ 
        3) ë‹¨ê¸°(30-90ì¼) vs ì¥ê¸°(270-365ì¼) ìœ„í—˜íŒ¨í„´ ì°¨ì´ì  ë° ëŒ€ì¶œë§Œê¸° ì„¤ì • ê¶Œê³ 
        4) í¬íŠ¸í´ë¦¬ì˜¤ ê´€ì ì—ì„œì˜ í•­ê³µì—…ê³„ ì—¬ì‹  ì§‘ì¤‘ë„ ë¦¬ìŠ¤í¬ í‰ê°€"""
        
        return self.generate_gpt4_report(prompt, context)
    
    def generate_risk_table_report(self, risk_df: pd.DataFrame) -> str:
        """Generate comprehensive risk table report for bank loan officers"""
        
        if risk_df.empty:
            return "âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ìœ„í—˜ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (ëŒ€ì‹œë³´ë“œì™€ ë™ì¼)
        sorted_df = risk_df.sort_values('overall_risk', ascending=False)
        
        # í†µê³„ ê³„ì‚°
        avg_risk = sorted_df['overall_risk'].mean()
        max_risk = sorted_df['overall_risk'].max()
        min_risk = sorted_df['overall_risk'].min()
        std_risk = sorted_df['overall_risk'].std()
        
        # ì„ê³„ê°’ ì •ë³´
        high_risk_count = len(sorted_df[sorted_df['overall_risk'] > RISK_THRESHOLD])
        warning_risk_count = len(sorted_df[(sorted_df['overall_risk'] >= RISK_THRESHOLD * 0.7) & 
                                          (sorted_df['overall_risk'] <= RISK_THRESHOLD)])
        
        # ëŒ€ì‹œë³´ë“œ í™”ë©´ í‘œì‹œ ë°ì´í„° ì „ì²´ ì •ë¦¬
        context = f"""
=== ëŒ€ì¶œì‹¬ì‚¬ìš© 90ì¼ ìœ„í—˜ë„ í…Œì´ë¸” ë¶„ì„ ë°ì´í„° ===

ë¶„ì„ ëŒ€ìƒ: {len(risk_df)}ê°œ í•­ê³µì‚¬
ë¶„ì„ ê¸°ì¤€: 90ì¼ ì‹ ìš©ë“±ê¸‰ ë³€ë™ í™•ë¥ 
í˜„ì¬ ì•Œë¦¼ ì„ê³„ê°’: {RISK_THRESHOLD:.1%}
ë°ì´í„° ì—…ë°ì´íŠ¸: {sorted_df['last_updated'].iloc[0] if 'last_updated' in sorted_df.columns else 'ì‹¤ì‹œê°„'}

=== í¬íŠ¸í´ë¦¬ì˜¤ ìœ„í—˜ë„ í†µê³„ ===
- í‰ê·  ìœ„í—˜ë„: {avg_risk:.2%}
- ìµœëŒ€ ìœ„í—˜ë„: {max_risk:.2%} 
- ìµœì†Œ ìœ„í—˜ë„: {min_risk:.2%}
- í‘œì¤€í¸ì°¨: {std_risk:.2%}
- ê³ ìœ„í—˜ ê¸°ì—…ìˆ˜ (>{RISK_THRESHOLD:.1%}): {high_risk_count}ê°œ
- ì£¼ì˜ ê¸°ì—…ìˆ˜ ({RISK_THRESHOLD*0.7:.1%}~{RISK_THRESHOLD:.1%}): {warning_risk_count}ê°œ

=== ìœ„í—˜ë„ ìˆœìœ„ë³„ ìƒì„¸ ë¶„ì„ (ëŒ€ì‹œë³´ë“œ í…Œì´ë¸” ê¸°ì¤€) ===
"""
        
        for rank, (idx, row) in enumerate(sorted_df.iterrows(), 1):
            # ìœ„í—˜ë“±ê¸‰ ë¶„ë¥˜
            if row['overall_risk'] > RISK_THRESHOLD:
                risk_level = "ğŸ”´ ê³ ìœ„í—˜"
            elif row['overall_risk'] > RISK_THRESHOLD * 0.7:
                risk_level = "ğŸŸ¡ ì£¼ì˜"
            else:
                risk_level = "ğŸŸ¢ ì•ˆì „"
                
            context += f"""
[{rank}ìœ„] {row['company_name']} ({risk_level})
  - í˜„ì¬ ì‹ ìš©ë“±ê¸‰: {row['current_rating']}
  - ì „ì²´ ë³€ë™ìœ„í—˜: {row['overall_risk']:.3%} 
  - ë“±ê¸‰ ìƒìŠ¹í™•ë¥ : {row['upgrade_prob']:.3%}
  - ë“±ê¸‰ í•˜ë½í™•ë¥ : {row['downgrade_prob']:.3%}
  - ë¶€ë„ ìœ„í—˜í™•ë¥ : {row['default_prob']:.3%}
  - ìœ„í—˜ë„ ë¶„ë¥˜: {row['risk_classification']}
  - ì—…ë°ì´íŠ¸: {row.get('last_updated', 'N/A')}
"""
        
        # ì¶”ê°€ ë¶„ì„ ë°ì´í„°
        context += f"""

=== ëŒ€ì‹œë³´ë“œ Progress Bar í•´ì„ ===
- Overall Risk: 90ì¼ ë‚´ ì‹ ìš©ë“±ê¸‰ ë³€ë™ ê°€ëŠ¥ì„± (0~50% ë²”ìœ„ í‘œì‹œ)
- Upgrade â†—ï¸: ë“±ê¸‰ ê°œì„  í™•ë¥  (0~30% ë²”ìœ„ í‘œì‹œ) 
- Downgrade â†˜ï¸: ë“±ê¸‰ ì•…í™” í™•ë¥  (0~30% ë²”ìœ„ í‘œì‹œ)
- Default âŒ: ë¶€ë„ ë°œìƒ í™•ë¥  (0~10% ë²”ìœ„ í‘œì‹œ)

=== ìƒ‰ìƒ ì½”ë”© ê¸°ì¤€ ===
- ë¹¨ê°„ìƒ‰ í•˜ì´ë¼ì´íŠ¸: ì„ê³„ê°’({RISK_THRESHOLD:.1%}) ì´ˆê³¼ ê¸°ì—…
- ë…¸ë€ìƒ‰ í•˜ì´ë¼ì´íŠ¸: ì„ê³„ê°’ì˜ 70% ì´ìƒ ê¸°ì—…  
- ì¼ë°˜ í‘œì‹œ: ì•ˆì „ ë²”ìœ„ ê¸°ì—…

=== CSV ë‹¤ìš´ë¡œë“œ ë°ì´í„° í¬í•¨ í•­ëª© ===
ëª¨ë“  ìˆ˜ì¹˜ ë°ì´í„°, ì—…ë°ì´íŠ¸ ì‹œê°„, ìœ„í—˜ë¶„ë¥˜ê°€ Excel ì—°ë™ ê°€ëŠ¥
"""
        
        prompt = """ëŒ€ì‹œë³´ë“œì˜ Risk Table íƒ­ì—ì„œ í‘œì‹œë˜ëŠ” 90ì¼ ìœ„í—˜ë„ ìˆœìœ„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ,
        ì€í–‰ ëŒ€ì¶œì‹¬ì‚¬ ë° ì—¬ì‹ ê´€ë¦¬ ê´€ì ì—ì„œ ë‹¤ìŒ ì‚¬í•­ì„ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1) ê° í•­ê³µì‚¬ë³„ 90ì¼ ì‹ ìš©ìœ„í—˜ ìˆœìœ„ ë° ì—¬ì‹ ì‹¬ì‚¬ ìŠ¹ì¸ ê¶Œê³ ë“±ê¸‰ 
        2) Progress Bar ìˆ˜ì¹˜ ê¸°ë°˜ ë‹´ë³´/ë³´ì¦ ìš”êµ¬ì‚¬í•­ ì°¨ë“± ì ìš© ë°©ì•ˆ
        3) ê³ ìœ„í—˜/ì£¼ì˜/ì•ˆì „ ê·¸ë£¹ë³„ ì—¬ì‹ í•œë„ ë° ê¸ˆë¦¬ ì°¨ë“± ì •ì±… ê¶Œê³ 
        4) ì •ê¸° ëª¨ë‹ˆí„°ë§ ì£¼ê¸° ë° ì¡°ê¸°ê²½ë³´ ì‹œìŠ¤í…œ ìš´ì˜ ë°©ì•ˆ
        5) ì—…ê³„ ë‚´ ìƒëŒ€ì  ì‹ ìš©ë„ ìˆœìœ„ë¥¼ ê³ ë ¤í•œ í¬íŠ¸í´ë¦¬ì˜¤ ì¬ë°°ë¶„ ì „ëµ"""
        
        return self.generate_gpt4_report(prompt, context)
    
    def generate_heatmap_report(self, risk_df: pd.DataFrame) -> str:
        """Generate comprehensive heatmap report for bank loan officers"""
        
        if risk_df.empty:
            return "âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ìœ„í—˜ ìœ í˜•ë³„ í†µê³„ ê³„ì‚°
        upgrade_stats = {
            'mean': risk_df['upgrade_prob'].mean(),
            'max': risk_df['upgrade_prob'].max(),
            'min': risk_df['upgrade_prob'].min(),
            'std': risk_df['upgrade_prob'].std()
        }
        
        downgrade_stats = {
            'mean': risk_df['downgrade_prob'].mean(),
            'max': risk_df['downgrade_prob'].max(), 
            'min': risk_df['downgrade_prob'].min(),
            'std': risk_df['downgrade_prob'].std()
        }
        
        default_stats = {
            'mean': risk_df['default_prob'].mean(),
            'max': risk_df['default_prob'].max(),
            'min': risk_df['default_prob'].min(),
            'std': risk_df['default_prob'].std()
        }
        
        # ìµœê³ /ìµœì € ìœ„í—˜ ê¸°ì—… ì‹ë³„
        highest_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmax()]
        lowest_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmin()]
        highest_upgrade_firm = risk_df.loc[risk_df['upgrade_prob'].idxmax()]
        highest_downgrade_firm = risk_df.loc[risk_df['downgrade_prob'].idxmax()]
        
        # ëŒ€ì‹œë³´ë“œ í™”ë©´ í‘œì‹œ ë°ì´í„° ì „ì²´ ì •ë¦¬
        context = f"""
=== ëŒ€ì¶œì‹¬ì‚¬ìš© ìœ„í—˜ íˆíŠ¸ë§µ ë¶„ì„ ë°ì´í„° ===

ë¶„ì„ ëŒ€ìƒ: {len(risk_df)}ê°œ í•­ê³µì‚¬
íˆíŠ¸ë§µ êµ¬ì„±: ê¸°ì—…(í–‰) Ã— ìœ„í—˜ìœ í˜•(ì—´) ë§¤íŠ¸ë¦­ìŠ¤
ìƒ‰ìƒ ê°•ë„: ìœ„í—˜ë„ ë†’ì„ìˆ˜ë¡ ì§„í•œ ìƒ‰ìƒ í‘œì‹œ

=== ê° í•­ê³µì‚¬ë³„ ìœ„í—˜ ë§¤íŠ¸ë¦­ìŠ¤ (ëŒ€ì‹œë³´ë“œ íˆíŠ¸ë§µ ê¸°ì¤€) ===
"""
        
        for idx, row in risk_df.iterrows():
            # ê° ìœ„í—˜ìœ í˜•ë³„ ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚°
            upgrade_percentile = (risk_df['upgrade_prob'] <= row['upgrade_prob']).mean() * 100
            downgrade_percentile = (risk_df['downgrade_prob'] <= row['downgrade_prob']).mean() * 100
            default_percentile = (risk_df['default_prob'] <= row['default_prob']).mean() * 100
            overall_percentile = (risk_df['overall_risk'] <= row['overall_risk']).mean() * 100
            
            context += f"""
â—ˆ {row['company_name']} (ë“±ê¸‰: {row['current_rating']})
  [ìœ„í—˜ìœ í˜•ë³„ ì ˆëŒ€ì¹˜]
  - ë“±ê¸‰ìƒìŠ¹ í™•ë¥ : {row['upgrade_prob']:.3%} (ì—…ê³„ ìƒìœ„ {100-upgrade_percentile:.0f}%)
  - ë“±ê¸‰í•˜ë½ í™•ë¥ : {row['downgrade_prob']:.3%} (ì—…ê³„ ìƒìœ„ {100-downgrade_percentile:.0f}%)  
  - ë¶€ë„ë°œìƒ í™•ë¥ : {row['default_prob']:.3%} (ì—…ê³„ ìƒìœ„ {100-default_percentile:.0f}%)
  - ì „ì²´ë³€ë™ í™•ë¥ : {row['overall_risk']:.3%} (ì—…ê³„ ìƒìœ„ {100-overall_percentile:.0f}%)
  
  [íˆíŠ¸ë§µ ìƒ‰ìƒ í•´ì„]
  - ìƒìŠ¹ìœ„í—˜: {'ğŸŸ¢ ì—°í•œìƒ‰' if row['upgrade_prob'] < upgrade_stats['mean'] else 'ğŸŸ¡ ì¤‘ê°„ìƒ‰' if row['upgrade_prob'] < upgrade_stats['mean'] + upgrade_stats['std'] else 'ğŸŸ  ì§„í•œìƒ‰'}
  - í•˜ë½ìœ„í—˜: {'ğŸŸ¢ ì—°í•œìƒ‰' if row['downgrade_prob'] < downgrade_stats['mean'] else 'ğŸŸ¡ ì¤‘ê°„ìƒ‰' if row['downgrade_prob'] < downgrade_stats['mean'] + downgrade_stats['std'] else 'ğŸ”´ ì§„í•œìƒ‰'}
  - ë¶€ë„ìœ„í—˜: {'ğŸŸ¢ ì—°í•œìƒ‰' if row['default_prob'] < default_stats['mean'] else 'ğŸŸ¡ ì¤‘ê°„ìƒ‰' if row['default_prob'] < default_stats['mean'] + default_stats['std'] else 'ğŸ”´ ì§„í•œìƒ‰'}
"""
        
        context += f"""

=== í¬íŠ¸í´ë¦¬ì˜¤ ìœ„í—˜ ë¶„í¬ í†µê³„ ===

[ë“±ê¸‰ìƒìŠ¹ ìœ„í—˜ ë¶„í¬]
- í‰ê· : {upgrade_stats['mean']:.3%}
- ìµœëŒ€: {upgrade_stats['max']:.3%} ({highest_upgrade_firm['company_name']})
- ìµœì†Œ: {upgrade_stats['min']:.3%}
- í‘œì¤€í¸ì°¨: {upgrade_stats['std']:.3%}

[ë“±ê¸‰í•˜ë½ ìœ„í—˜ ë¶„í¬]  
- í‰ê· : {downgrade_stats['mean']:.3%}
- ìµœëŒ€: {downgrade_stats['max']:.3%} ({highest_downgrade_firm['company_name']})
- ìµœì†Œ: {downgrade_stats['min']:.3%}
- í‘œì¤€í¸ì°¨: {downgrade_stats['std']:.3%}

[ë¶€ë„ë°œìƒ ìœ„í—˜ ë¶„í¬]
- í‰ê· : {default_stats['mean']:.3%}
- ìµœëŒ€: {default_stats['max']:.3%}
- ìµœì†Œ: {default_stats['min']:.3%}  
- í‘œì¤€í¸ì°¨: {default_stats['std']:.3%}

=== ìœ„í—˜ ì§‘ì¤‘ë„ ë¶„ì„ ===
- ìµœê³  ì¢…í•©ìœ„í—˜: {highest_risk_firm['company_name']} ({highest_risk_firm['overall_risk']:.3%})
- ìµœì € ì¢…í•©ìœ„í—˜: {lowest_risk_firm['company_name']} ({lowest_risk_firm['overall_risk']:.3%})
- ìœ„í—˜ë„ ê²©ì°¨: {highest_risk_firm['overall_risk'] - lowest_risk_firm['overall_risk']:.3%}p

=== ëŒ€ì‹œë³´ë“œ íˆìŠ¤í† ê·¸ë¨ ì •ë³´ ===
- ë¶„í¬ êµ¬ê°„: 10êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ í‘œì‹œ
- ì•Œë¦¼ ì„ê³„ê°’: {RISK_THRESHOLD:.1%} (ë¹¨ê°„ ì ì„ ìœ¼ë¡œ í‘œì‹œ)
- ì„ê³„ê°’ ì´ˆê³¼ ê¸°ì—…: {len(risk_df[risk_df['overall_risk'] > RISK_THRESHOLD])}ê°œ
"""
        
        prompt = """ëŒ€ì‹œë³´ë“œì˜ Heatmap íƒ­ì—ì„œ í‘œì‹œë˜ëŠ” ê¸°ì—…Ã—ìœ„í—˜ìœ í˜• ë§¤íŠ¸ë¦­ìŠ¤ì™€ ìœ„í—˜ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ì„ ê¸°ë°˜ìœ¼ë¡œ,
        ì€í–‰ ëŒ€ì¶œì‹¬ì‚¬ ë° ì—¬ì‹ ê´€ë¦¬ ê´€ì ì—ì„œ ë‹¤ìŒ ì‚¬í•­ì„ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1) ìœ„í—˜ìœ í˜•ë³„(ìƒìŠ¹/í•˜ë½/ë¶€ë„) ìƒ‰ìƒ ê°•ë„ ê¸°ì¤€ ì—¬ì‹ ì‹¬ì‚¬ ì°¨ë“± ì •ì±… ìˆ˜ë¦½ ë°©ì•ˆ
        2) ê° í•­ê³µì‚¬ì˜ ìƒëŒ€ì  ìœ„í—˜ í¬ì§€ì…˜ ê¸°ë°˜ ì—¬ì‹ í•œë„ ë°°ë¶„ ì „ëµ
        3) í¬íŠ¸í´ë¦¬ì˜¤ ìœ„í—˜ ì§‘ì¤‘ë„ ë° ë¶„ì‚°íˆ¬ì ê°œì„  ë°©í–¥
        4) íˆìŠ¤í† ê·¸ë¨ ë¶„í¬ íŒ¨í„´ì„ í™œìš©í•œ ì—…ì¢…ë³„ ì—¬ì‹  ê°€ì´ë“œë¼ì¸ ì„¤ì •
        5) ìœ„í—˜ë„ ê²©ì°¨ ë¶„ì„ì„ í†µí•œ í”„ë¦¬ë¯¸ì—„/ë””ìŠ¤ì¹´ìš´íŠ¸ ê¸ˆë¦¬ ì ìš© ê¸°ì¤€"""
        
        return self.generate_gpt4_report(prompt, context)
    
    def generate_alerts_report(self, risk_df: pd.DataFrame, threshold: float) -> str:
        """Generate comprehensive alerts report for bank loan officers"""
        
        if risk_df.empty:
            return "âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # ìœ„í—˜ë„ë³„ ê¸°ì—… ë¶„ë¥˜
        high_risk_firms = risk_df[risk_df['overall_risk'] > threshold]
        warning_firms = risk_df[(risk_df['overall_risk'] >= threshold * 0.8) & (risk_df['overall_risk'] <= threshold)]
        safe_firms = risk_df[risk_df['overall_risk'] < threshold * 0.8]
        
        # ì•Œë¦¼ ì´ë ¥ ì •ë³´ (ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì—ì„œ)
        alert_history_count = len(st.session_state.get('alert_history', []))
        last_alert_time = st.session_state.get('alert_history', [])[-1]['timestamp'].strftime('%Y-%m-%d %H:%M') if alert_history_count > 0 else 'ì—†ìŒ'
        
        # ëŒ€ì‹œë³´ë“œ í™”ë©´ í‘œì‹œ ë°ì´í„° ì „ì²´ ì •ë¦¬
        context = f"""
=== ëŒ€ì¶œì‹¬ì‚¬ìš© ì•Œë¦¼ ê´€ë¦¬ ì‹œìŠ¤í…œ ë¶„ì„ ë°ì´í„° ===

í˜„ì¬ ì•Œë¦¼ ì„ê³„ê°’: {threshold:.1%}
ì´ ë¶„ì„ ëŒ€ìƒ: {len(risk_df)}ê°œ í•­ê³µì‚¬
ì‹œìŠ¤í…œ ìƒíƒœ: {'ğŸ”´ ì•Œë¦¼ ë°œìƒ' if len(high_risk_firms) > 0 else 'ğŸŸ¢ ì •ìƒ ìš´ì˜'}
ë§ˆì§€ë§‰ ì•Œë¦¼: {last_alert_time}
ì´ ì•Œë¦¼ ì´ë ¥: {alert_history_count}ê±´

=== ìœ„í—˜ë„ë³„ ê¸°ì—… ë¶„ë¥˜ í˜„í™© ===

ğŸ”´ ê³ ìœ„í—˜êµ° (ì„ê³„ê°’ {threshold:.1%} ì´ˆê³¼): {len(high_risk_firms)}ê°œ
ğŸŸ¡ ì£¼ì˜êµ° (ì„ê³„ê°’ì˜ 80%~100%): {len(warning_firms)}ê°œ  
ğŸŸ¢ ì•ˆì „êµ° (ì„ê³„ê°’ì˜ 80% ë¯¸ë§Œ): {len(safe_firms)}ê°œ

=== ê³ ìœ„í—˜ ê¸°ì—… ìƒì„¸ ì •ë³´ ===
"""
        
        if len(high_risk_firms) > 0:
            for idx, row in high_risk_firms.iterrows():
                excess_risk = row['overall_risk'] - threshold
                context += f"""
â—ˆ {row['company_name']} (ë“±ê¸‰: {row['current_rating']}) ğŸš¨ ì¦‰ì‹œëŒ€ì‘í•„ìš”
  - í˜„ì¬ ìœ„í—˜ë„: {row['overall_risk']:.3%}
  - ì„ê³„ê°’ ì´ˆê³¼í­: +{excess_risk:.3%}p ({excess_risk/threshold*100:+.1f}%)
  - ë“±ê¸‰ìƒìŠ¹ í™•ë¥ : {row['upgrade_prob']:.3%}
  - ë“±ê¸‰í•˜ë½ í™•ë¥ : {row['downgrade_prob']:.3%}
  - ë¶€ë„ë°œìƒ í™•ë¥ : {row['default_prob']:.3%}
  - ìœ„í—˜ë„ ë¶„ë¥˜: {row['risk_classification']}
  - ê¶Œê³ ì¡°ì¹˜: ì—¬ì‹ í•œë„ ì¬ê²€í† , ë‹´ë³´ë³´ê°•, ëª¨ë‹ˆí„°ë§ ê°•í™”
"""
        else:
            context += "âœ… í˜„ì¬ ê³ ìœ„í—˜ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.\n"
        
        context += "\n=== ì£¼ì˜ ê¸°ì—… ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ ===\n"
        
        if len(warning_firms) > 0:
            for idx, row in warning_firms.iterrows():
                remaining_buffer = threshold - row['overall_risk']
                context += f"""
â—ˆ {row['company_name']} (ë“±ê¸‰: {row['current_rating']}) âš¡ ì˜ˆë°©ì ëª¨ë‹ˆí„°ë§
  - í˜„ì¬ ìœ„í—˜ë„: {row['overall_risk']:.3%}
  - ì„ê³„ê°’ê¹Œì§€ ì—¬ìœ : {remaining_buffer:.3%}p
  - ì£¼ìš” ìœ„í—˜ìš”ì†Œ: {'ë“±ê¸‰í•˜ë½' if row['downgrade_prob'] > row['upgrade_prob'] else 'ë“±ê¸‰ìƒìŠ¹'}
  - ê¶Œê³ ì¡°ì¹˜: ì •ê¸°ì ê²€ ê°•í™”, ì¬ë¬´ì œí‘œ ë¶„ê¸°ë³„ ì œì¶œ
"""
        else:
            context += "âœ… í˜„ì¬ ì£¼ì˜ ìˆ˜ì¤€ì— í•´ë‹¹í•˜ëŠ” ê¸°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.\n"
        
        # í¬íŠ¸í´ë¦¬ì˜¤ í†µê³„
        context += f"""

=== í¬íŠ¸í´ë¦¬ì˜¤ ì•Œë¦¼ ì‹œìŠ¤í…œ í†µê³„ ===
- í‰ê·  ìœ„í—˜ë„: {risk_df['overall_risk'].mean():.3%}
- ìµœëŒ€ ìœ„í—˜ë„: {risk_df['overall_risk'].max():.3%} ({risk_df.loc[risk_df['overall_risk'].idxmax(), 'company_name']})
- ìµœì†Œ ìœ„í—˜ë„: {risk_df['overall_risk'].min():.3%} ({risk_df.loc[risk_df['overall_risk'].idxmin(), 'company_name']})
- ìœ„í—˜ë„ í‘œì¤€í¸ì°¨: {risk_df['overall_risk'].std():.3%}
- ì„ê³„ê°’ í™œìš©ë¥ : {len(high_risk_firms)/len(risk_df)*100:.1f}% (ì´ˆê³¼ ê¸°ì—… ë¹„ìœ¨)

=== ëŒ€ì‹œë³´ë“œ ì•Œë¦¼ ì„¤ì • ì •ë³´ ===
- Slack ì›¹í›…: {'âœ… ì—°ë™ì™„ë£Œ' if st.session_state.get('slack_webhook_url') else 'âŒ ë¯¸ì„¤ì •'}
- ìë™ìƒˆë¡œê³ ì¹¨: 30ì´ˆ ê°„ê²©
- ì•Œë¦¼ ë²„íŠ¼: ìˆ˜ë™ ë°œì†¡ ê°€ëŠ¥
- ì„ê³„ê°’ ì¡°ì •: 5%~30% ë²”ìœ„ì—ì„œ ì‹¤ì‹œê°„ ë³€ê²½ ê°€ëŠ¥
- ì•Œë¦¼ ì´ë ¥: ìµœê·¼ 5ê±´ í‘œì‹œ, ì„¸ì…˜ë³„ ì €ì¥

=== ìµœê·¼ ì•Œë¦¼ ì´ë ¥ ìš”ì•½ ===
"""
        
        if alert_history_count > 0:
            recent_alerts = st.session_state.get('alert_history', [])[-3:]  # ìµœê·¼ 3ê±´
            for i, alert in enumerate(reversed(recent_alerts), 1):
                context += f"""
[{i}] {alert['timestamp'].strftime('%m/%d %H:%M')} - {len(alert['firms'])}ê°œ ê¸°ì—… ì•Œë¦¼
    ëŒ€ìƒ: {', '.join(alert['firms'])}
"""
        else:
            context += "ì•„ì§ ë°œì†¡ëœ ì•Œë¦¼ì´ ì—†ìŠµë‹ˆë‹¤.\n"
        
        prompt = f"""ëŒ€ì‹œë³´ë“œì˜ Alerts íƒ­ì—ì„œ í‘œì‹œë˜ëŠ” ì•Œë¦¼ ê´€ë¦¬ ì‹œìŠ¤í…œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ,
        ì€í–‰ ëŒ€ì¶œì‹¬ì‚¬ ë° ì—¬ì‹ ê´€ë¦¬ ê´€ì ì—ì„œ ë‹¤ìŒ ì‚¬í•­ì„ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”:
        1) í˜„ì¬ ì„ê³„ê°’({threshold:.1%}) ê¸°ì¤€ ê³ ìœ„í—˜/ì£¼ì˜ ê¸°ì—…ì— ëŒ€í•œ ì¦‰ì‹œ ì—¬ì‹ ì¡°ì¹˜ ë°©ì•ˆ
        2) ì•Œë¦¼ ë°œìƒ ë¹ˆë„ì™€ íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ì¡°ê¸°ê²½ë³´ ì‹œìŠ¤í…œ íš¨ê³¼ì„± í‰ê°€  
        3) ìœ„í—˜ë„ë³„ ì°¨ë“± ëª¨ë‹ˆí„°ë§ ì£¼ê¸° ë° ë³´ê³ ì²´ê³„ ìˆ˜ë¦½ ë°©ì•ˆ
        4) Slack ì•Œë¦¼ ì—°ë™ì„ í†µí•œ ì‹¤ì‹œê°„ ëŒ€ì‘ì²´ê³„ êµ¬ì¶• ë° ìš´ì˜ í”„ë¡œì„¸ìŠ¤
        5) ì„ê³„ê°’ ì¡°ì • ë° ì•Œë¦¼ ë¯¼ê°ë„ ìµœì í™”ë¥¼ ìœ„í•œ ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ë°˜ì˜ ë°©ì•ˆ
        6) í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ ê´€ì ì—ì„œì˜ ìœ„í—˜ ì§‘ì¤‘ë„ ì™„í™” ë° ë¶„ì‚° ì „ëµ"""
        
        return self.generate_gpt4_report(prompt, context)
    
    def generate_hazard_curves(self, firms: List[FirmProfile]) -> go.Figure:
        """Generate hazard curves for all firms"""
        
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=['Overall Risk Over Time', 'Upgrade Probability', 'Downgrade Probability', 'Default Risk'],
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        # Generate time horizons (1 to 365 days)
        horizons = [30, 60, 90, 120, 180, 270, 365]
        colors = px.colors.qualitative.Set1
        
        # ğŸ”§ Data collection for dynamic scaling
        all_overall_risks = []
        all_upgrade_probs = []
        all_downgrade_probs = []
        all_default_probs = []
        firm_data = []  # Store data for each firm
        
        for i, firm in enumerate(firms):
            if self.risk_scorer is None:
                continue
                
            overall_risks = []
            upgrade_probs = []
            downgrade_probs = []
            default_probs = []
            
            for horizon in horizons:
                try:
                    risk_assessment = self.risk_scorer.score_firm(firm, horizon=horizon)
                    
                    # ğŸ” DEBUG: Graph value check
                    print(f"  ğŸ” GRAPH DEBUG {firm.company_name} @ {horizon}d:")
                    print(f"    - Overall: {risk_assessment['overall_change_probability']:.6f}")
                    print(f"    - Upgrade: {risk_assessment['upgrade_probability']:.6f}")  
                    print(f"    - Downgrade: {risk_assessment['downgrade_probability']:.6f}")
                    print(f"    - Default: {risk_assessment['default_probability']:.6f}")
                    
                    overall_risk = risk_assessment['overall_change_probability']
                    upgrade_prob = risk_assessment['upgrade_probability']
                    downgrade_prob = risk_assessment['downgrade_probability']
                    default_prob = risk_assessment['default_probability']
                    
                    overall_risks.append(overall_risk)
                    upgrade_probs.append(upgrade_prob)
                    downgrade_probs.append(downgrade_prob)
                    default_probs.append(default_prob)
                    
                    # ğŸ”§ Collect all values for dynamic scaling
                    all_overall_risks.append(overall_risk)
                    all_upgrade_probs.append(upgrade_prob)
                    all_downgrade_probs.append(downgrade_prob)
                    all_default_probs.append(default_prob)
                    
                except Exception as e:
                    print(f"âš ï¸ Error getting risk assessment for {firm.company_name}: {e}")
                    # Fallback to simulated curves
                    base_risk = 0.05 + i * 0.02
                    overall_risk = base_risk * (1 + horizon/365)
                    upgrade_prob = base_risk * 0.6 * (1 + horizon/365)
                    downgrade_prob = base_risk * 0.4 * (1 + horizon/365)
                    default_prob = base_risk * 0.1 * (1 + horizon/365)
                    
                    overall_risks.append(overall_risk)
                    upgrade_probs.append(upgrade_prob)
                    downgrade_probs.append(downgrade_prob)
                    default_probs.append(default_prob)
                    
                    # Collect fallback values too
                    all_overall_risks.append(overall_risk)
                    all_upgrade_probs.append(upgrade_prob)
                    all_downgrade_probs.append(downgrade_prob)
                    all_default_probs.append(default_prob)
            
            # Store data for this firm
            firm_data.append({
                'name': firm.company_name,
                'overall_risks': overall_risks,
                'upgrade_probs': upgrade_probs,
                'downgrade_probs': downgrade_probs,
                'default_probs': default_probs
            })
            
            color = colors[i % len(colors)]
            
            # Overall risk curve
            fig.add_trace(
                go.Scatter(x=horizons, y=overall_risks, name=firm.company_name, 
                          line=dict(color=color), legendgroup=firm.company_name),
                row=1, col=1
            )
            
            # Upgrade probability
            fig.add_trace(
                go.Scatter(x=horizons, y=upgrade_probs, name=firm.company_name, 
                          line=dict(color=color), legendgroup=firm.company_name, showlegend=False),
                row=1, col=2
            )
            
            # Downgrade probability
            fig.add_trace(
                go.Scatter(x=horizons, y=downgrade_probs, name=firm.company_name, 
                          line=dict(color=color), legendgroup=firm.company_name, showlegend=False),
                row=2, col=1
            )
            
            # Default risk
            fig.add_trace(
                go.Scatter(x=horizons, y=default_probs, name=firm.company_name, 
                          line=dict(color=color), legendgroup=firm.company_name, showlegend=False),
                row=2, col=2
            )
        
        # Update layout
        fig.update_layout(
            title="Korean Airlines Credit Risk Hazard Curves",
            height=800,
            showlegend=True
        )
        
        # ğŸ”§ Dynamic scale calculation with safety margins
        def calculate_dynamic_range(values, margin_factor=0.1, min_range=0.01):
            """Calculate dynamic range with margin"""
            if not values or all(v == 0 for v in values):
                return [0, min_range]
            
            min_val = min(values)
            max_val = max(values)
            
            # Add margin (10% by default)
            value_range = max_val - min_val
            margin = max(value_range * margin_factor, min_range * 0.1)
            
            # Ensure minimum range for visibility
            if value_range < min_range:
                center = (min_val + max_val) / 2
                return [max(0, center - min_range/2), center + min_range/2]
            
            return [max(0, min_val - margin), max_val + margin]
        
        # Calculate dynamic ranges for each subplot
        overall_range = calculate_dynamic_range(all_overall_risks, margin_factor=0.15)
        upgrade_range = calculate_dynamic_range(all_upgrade_probs, margin_factor=0.2, min_range=0.01)
        downgrade_range = calculate_dynamic_range(all_downgrade_probs, margin_factor=0.15)
        default_range = calculate_dynamic_range(all_default_probs, margin_factor=0.3, min_range=0.005)
        
        print(f"ğŸ”§ Dynamic ranges calculated:")
        print(f"  Overall: [{overall_range[0]:.4f}, {overall_range[1]:.4f}]")
        print(f"  Upgrade: [{upgrade_range[0]:.4f}, {upgrade_range[1]:.4f}]")
        print(f"  Downgrade: [{downgrade_range[0]:.4f}, {downgrade_range[1]:.4f}]")
        print(f"  Default: [{default_range[0]:.6f}, {default_range[1]:.6f}]")
        
        # Update axes with dynamic scales
        fig.update_xaxes(title_text="Days", row=1, col=1)
        fig.update_yaxes(title_text="Probability", range=overall_range, row=1, col=1)
        
        fig.update_xaxes(title_text="Days", row=1, col=2)
        fig.update_yaxes(title_text="Probability", range=upgrade_range, row=1, col=2)
        
        fig.update_xaxes(title_text="Days", row=2, col=1)
        fig.update_yaxes(title_text="Probability", range=downgrade_range, row=2, col=1)
        
        fig.update_xaxes(title_text="Days", row=2, col=2)
        fig.update_yaxes(title_text="Probability", range=default_range, row=2, col=2)
        
        return fig
    
    def create_risk_heatmap(self, risk_df: pd.DataFrame) -> go.Figure:
        """Create risk heatmap visualization"""
        
        if risk_df.empty:
            return go.Figure()
        
        # Prepare data for heatmap
        heatmap_data = risk_df[['company_name', 'upgrade_prob', 'downgrade_prob', 'default_prob']].copy()
        heatmap_data = heatmap_data.set_index('company_name').T
        
        fig = go.Figure(data=go.Heatmap(
            z=heatmap_data.values,
            x=heatmap_data.columns,
            y=['Upgrade Risk', 'Downgrade Risk', 'Default Risk'],
            colorscale='RdYlBu_r',
            text=np.round(heatmap_data.values, 3),
            texttemplate="%{text}",
            textfont={"size": 12},
            colorbar=dict(title="Probability")
        ))
        
        fig.update_layout(
            title="Risk Heatmap - Korean Airlines",
            xaxis_title="Airlines",
            yaxis_title="Risk Type",
            height=400
        )
        
        return fig
    
    def send_slack_alert(self, high_risk_firms: pd.DataFrame):
        """Send Slack webhook alert for high-risk firms"""
        
        if SLACK_WEBHOOK_URL is None:
            st.info("ğŸ’¡ Slack webhook not configured. Set SLACK_WEBHOOK_URL to enable alerts.")
            return False
        
        if high_risk_firms.empty:
            return True
        
        # Prepare alert message
        alert_text = "ğŸš¨ *Credit Rating Risk Alert - Korean Airlines*\n\n"
        alert_text += f"*High Risk Firms (>{RISK_THRESHOLD:.1%} change probability):*\n"
        
        for _, firm in high_risk_firms.iterrows():
            alert_text += (
                f"â€¢ *{firm['company_name']}* ({firm['current_rating']}): "
                f"{firm['overall_risk']:.1%} risk, "
                f"Downgrade: {firm['downgrade_prob']:.1%}\n"
            )
        
        alert_text += f"\n_Generated at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}_"
        
        # Slack message payload
        payload = {
            "text": alert_text,
            "username": "Credit Risk Monitor",
            "icon_emoji": ":warning:",
            "channel": "#risk-monitoring"
        }
        
        try:
            response = requests.post(SLACK_WEBHOOK_URL, json=payload, timeout=10)
            if response.status_code == 200:
                st.success(f"âœ… Slack alert sent for {len(high_risk_firms)} high-risk firms")
                
                # Log to session state
                st.session_state.alert_history.append({
                    'timestamp': datetime.now(),
                    'firms': high_risk_firms['company_name'].tolist(),
                    'message': alert_text
                })
                
                return True
            else:
                st.error(f"âŒ Slack alert failed: {response.status_code}")
                return False
                
        except Exception as e:
            st.error(f"âŒ Error sending Slack alert: {e}")
            return False
    
    def run_dashboard(self):
        """Main dashboard application"""
        
        logger.info("[DASHBOARD] Starting dashboard run...")
        logger.info(f"[DASHBOARD] Current session_state keys: {list(st.session_state.keys())}")
        
        # Page configuration (only set once)
        try:
            st.set_page_config(
                page_title="Korean Airlines Credit Risk Dashboard",
                page_icon="âœˆï¸",
                layout="wide",
                initial_sidebar_state="expanded"
            )
        except Exception as e:
            pass  # Config already set
        
        # Header
        st.title("âœˆï¸ Korean Airlines Credit Risk Dashboard")
        st.markdown("---")
        
        # Sidebar
        st.sidebar.header("ğŸ›ï¸ Control Panel")
        
        # Model loading/unloading using buttons
        if not st.session_state.models_loaded_status:
            if st.sidebar.button("ğŸ”„ Enable Models", key="enable_models_btn", help="Load and enable the risk models"):
                with st.spinner("ğŸ‹ï¸ Loading models..."):
                    success = self.load_models()
                    if success:
                        st.session_state.models_loaded_status = True
                        st.success("âœ… Models loaded successfully!")
                    else:
                        st.error("âŒ Failed to load models")
        else:
            st.sidebar.success("âœ… Models Enabled")
            if st.sidebar.button("ğŸ”´ Disable Models", key="disable_models_btn", help="Disable the risk models"):
                st.session_state.models_loaded_status = False
                self.risk_scorer = None
                st.info("ğŸ”„ Models disabled")
        
        # Data source information
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ“Š Data Source")
        
        try:
            # Try different import paths for config
            try:
                from config.config import USE_REAL_DATA
            except ImportError:
                from config import USE_REAL_DATA
            if USE_REAL_DATA:
                st.sidebar.success("ğŸ¯ **Real DART Data Mode**")
                st.sidebar.info("Using actual financial statements from DART API")
            else:
                st.sidebar.warning("âš¡ **Fast Dummy Data Mode**")
                st.sidebar.info("Using synthetic data for development")
        except ImportError:
            st.sidebar.warning("âš¡ **Fast Dummy Data Mode**")
            st.sidebar.info("Using synthetic data for development")
        
        st.sidebar.markdown("""
        **ğŸ’¡ To switch data mode:**
        Edit `config.py` and change:
        ```python
        USE_REAL_DATA = True   # Real data
        USE_REAL_DATA = False  # Dummy data
        ```
        Then restart the dashboard.
        """)
        
        # Risk threshold setting
        st.sidebar.markdown("---")
        global RISK_THRESHOLD, SLACK_WEBHOOK_URL
        old_threshold = RISK_THRESHOLD
        RISK_THRESHOLD = st.sidebar.slider(
            "âš ï¸ Alert Threshold", 
            min_value=0.05, 
            max_value=0.30, 
            value=RISK_THRESHOLD, 
            step=0.01,
            format="%.2f",
            key="risk_threshold_slider"
        )
        if old_threshold != RISK_THRESHOLD:
            logger.info(f"[SIDEBAR] Risk threshold changed from {old_threshold} to {RISK_THRESHOLD}")
        
        # Slack webhook configuration
        slack_url = st.sidebar.text_input(
            "ğŸ“± Slack Webhook URL", 
            value=SLACK_WEBHOOK_URL or "",
            type="password",
            help="Enter your Slack webhook URL for alerts"
        )
        
        if slack_url:
            SLACK_WEBHOOK_URL = slack_url
        
        # Auto-refresh
        auto_refresh = st.sidebar.checkbox("ğŸ”„ Auto Refresh (30s)", value=False, key="auto_refresh_checkbox")
        
        if auto_refresh:
            logger.info("[WIDGET] Auto-refresh enabled")
            st.sidebar.info("Auto-refresh enabled")
            # Note: In production, you'd implement proper auto-refresh
        
        # DART ë°ì´í„° ìºì‹œ ê´€ë¦¬
            st.sidebar.markdown("---")
            st.sidebar.subheader("ğŸ’¾ DART ë°ì´í„° ìºì‹œ")
        
        # ìºì‹œ ì‹œìŠ¤í…œ ìƒíƒœ í‘œì‹œ
        if CACHE_AVAILABLE:
            st.sidebar.success("âœ… ìºì‹œ ì‹œìŠ¤í…œ í™œì„±í™”")
            
            # ìºì‹œ í™œì„±í™”/ë¹„í™œì„±í™” í† ê¸€
            cache_enabled = st.sidebar.checkbox(
                "ğŸ’¾ ìºì‹œ ì‹œìŠ¤í…œ ì‚¬ìš©", 
                value=True, 
                key="cache_enabled_checkbox",
                help="DART API ë°ì´í„°ë¥¼ ìºì‹œí•˜ì—¬ ì¤‘ë³µ ìš”ì²­ì„ ë°©ì§€í•©ë‹ˆë‹¤"
            )
            
            try:
                cache = get_global_cache()
                cache_stats = cache.get_cache_stats()
                
                # ìºì‹œ í†µê³„ í‘œì‹œ
                st.sidebar.info(f"""
                **ğŸ“Š ìºì‹œ í˜„í™©**
                - ì´ ì—”íŠ¸ë¦¬: {cache_stats['total_entries']}ê°œ
                - ìœ íš¨í•œ ë°ì´í„°: {cache_stats['valid_entries']}ê°œ
                - ë§Œë£Œëœ ë°ì´í„°: {cache_stats['expired_entries']}ê°œ
                - ì´ í¬ê¸°: {cache_stats['total_size_mb']} MB
                - ìºì‹œ ê¸°ê°„: {cache_stats['cache_duration_hours']}ì‹œê°„
                """)
                
                # ìºì‹œ ê´€ë¦¬ ë²„íŠ¼ë“¤
                col1, col2 = st.sidebar.columns(2)
                
                with col1:
                    if st.button("ğŸ§¹ ë§Œë£Œ ì •ë¦¬", key="cleanup_cache_btn", help="ë§Œë£Œëœ ìºì‹œ ì—”íŠ¸ë¦¬ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤"):
                        removed_count = cache.cleanup_expired_cache()
                        if removed_count > 0:
                            st.success(f"âœ… {removed_count}ê°œ í•­ëª© ì •ë¦¬ë¨")
                        else:
                            st.info("ğŸ” ì •ë¦¬í•  ë§Œë£Œ í•­ëª© ì—†ìŒ")
                        st.rerun()
                
                with col2:
                    if st.button("ğŸ—‘ï¸ ì „ì²´ ì‚­ì œ", key="clear_all_cache_btn", help="ëª¨ë“  ìºì‹œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤"):
                        removed_count = cache.clear_all_cache()
                        if removed_count > 0:
                            st.success(f"âœ… {removed_count}ê°œ í•­ëª© ì‚­ì œë¨")
                        else:
                            st.info("ğŸ” ì‚­ì œí•  í•­ëª© ì—†ìŒ")
                        st.rerun()
                
                # ìºì‹œ ì„¤ì • ì •ë³´
                with st.sidebar.expander("âš™ï¸ ìºì‹œ ì„¤ì •"):
                    st.text(f"ğŸ“ ìºì‹œ ë””ë ‰í† ë¦¬: {cache.cache_dir}")
                    st.text(f"â±ï¸ ìºì‹œ ìœ íš¨ì‹œê°„: {cache.cache_duration.total_seconds() / 3600:.1f}ì‹œê°„")
                    st.text(f"ğŸ“Š ë©”íƒ€ë°ì´í„° íŒŒì¼: {os.path.basename(cache.metadata_file)}")
                
                # ìºì‹œ ì„¸ë¶€ ì •ë³´ (í™•ì¥ ê°€ëŠ¥)
                with st.sidebar.expander("ğŸ“‹ ìºì‹œ ì„¸ë¶€ ì •ë³´"):
                    entries = cache.list_cached_entries()
                    if entries:
                        for entry in entries[:5]:  # ìµœê·¼ 5ê°œë§Œ í‘œì‹œ
                            status = "âœ…" if entry['is_valid'] else "â°"
                            st.text(f"{status} {entry['company_name']} {entry['year']}")
                        
                        if len(entries) > 5:
                            st.text(f"...ë° {len(entries)-5}ê°œ ë”")
                    else:
                        st.text("ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                
            except Exception as e:
                st.sidebar.error(f"ìºì‹œ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            st.sidebar.error("âŒ ìºì‹œ ì‹œìŠ¤í…œ ë¹„í™œì„±í™”")
            st.sidebar.info("""
            **ìºì‹œ ì‹œìŠ¤í…œ í™œì„±í™” ë°©ë²•:**
            1. `src/data/dart_data_cache.py` íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            2. Python ê²½ë¡œ ì„¤ì • í™•ì¸
            3. ëŒ€ì‹œë³´ë“œ ì¬ì‹œì‘
            """)
        
        # RAG ì‹œìŠ¤í…œ ê´€ë¦¬
        st.sidebar.markdown("---")
        st.sidebar.subheader("ğŸ” RAG ì‹œìŠ¤í…œ (í•­ê³µì—…ê³„ ê²€ìƒ‰)")
        
        if self.rag_available:
            st.sidebar.success("âœ… RAG ì‹œìŠ¤í…œ í™œì„±í™”")
            
            try:
                # RAG ìºì‹œ ì •ë³´
                cache_info = self.rag_system.get_cache_info()
                
                # RAG ìƒíƒœ í‘œì‹œ
                status_icon = "âœ…" if cache_info['cache_valid'] else "â°"
                st.sidebar.info(f"""
                **ğŸ” RAG ì‹œìŠ¤í…œ í˜„í™©**
                - ìƒíƒœ: {status_icon} {'ìµœì‹  ì •ë³´' if cache_info['cache_valid'] else 'ì—…ë°ì´íŠ¸ í•„ìš”'}
                - ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {cache_info['last_update']}
                - ì²˜ë¦¬ëœ ê¸°ì‚¬: {cache_info['articles_processed']}ê°œ
                - ìƒíƒœ: {cache_info['status']}
                """)
                
                # RAG ì •ë³´ ì—…ë°ì´íŠ¸ ë²„íŠ¼
                if st.sidebar.button("ğŸ”„ í•­ê³µì—…ê³„ ì •ë³´ ì—…ë°ì´íŠ¸", key="update_rag_btn", help="ìµœì‹  í•­ê³µì—…ê³„ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤"):
                    with st.spinner("í•­ê³µì—…ê³„ ì •ë³´ ê²€ìƒ‰ ë° ìš”ì•½ ì¤‘..."):
                        try:
                            context = self.rag_system.get_airline_industry_context(force_update=True)
                            st.session_state.rag_context = context
                            st.session_state.rag_last_update = datetime.now()
                            st.success("âœ… í•­ê³µì—…ê³„ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                
                # RAG ìƒì„¸ ì •ë³´
                with st.sidebar.expander("ğŸ“‹ RAG ìƒì„¸ ì •ë³´"):
                    if st.session_state.rag_context:
                        context = st.session_state.rag_context
                        st.text("**ê²€ìƒ‰ í‚¤ì›Œë“œ:**")
                        for keyword in context.get('search_keywords', [])[:3]:
                            st.text(f"â€¢ {keyword}")
                        
                        st.text("**í•µì‹¬ í¬ì¸íŠ¸:**")
                        for point in context.get('key_points', [])[:3]:
                            st.text(f"â€¢ {point}")
                        
                        st.text("**ì •ë³´ ì¶œì²˜:**")
                        for source in context.get('sources', [])[:2]:
                            st.text(f"â€¢ {source[:50]}...")
                    else:
                        st.text("RAG ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
                
                # RAG ì„¤ì •
                with st.sidebar.expander("âš™ï¸ RAG ì„¤ì •"):
                    st.text(f"ğŸ“ ìºì‹œ ë””ë ‰í† ë¦¬: {self.rag_system.cache_dir}")
                    st.text(f"â±ï¸ ìºì‹œ ìœ íš¨ì‹œê°„: {self.rag_system.cache_duration}")
                    st.text(f"ğŸ” ê²€ìƒ‰ ì—”ì§„: ë„¤ì´ë²„ ë‰´ìŠ¤ + êµ¬ê¸€")
                    st.text(f"ğŸ“ ìš”ì•½ ëª¨ë¸: GPT-4o-mini")
                        
            except Exception as e:
                st.sidebar.error(f"RAG ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        else:
            st.sidebar.error("âŒ RAG ì‹œìŠ¤í…œ ë¹„í™œì„±í™”")
            st.sidebar.info("""
            **RAG ì‹œìŠ¤í…œ í™œì„±í™” ë°©ë²•:**
            1. `src/rag/` ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            2. OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            3. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: `pip install requests beautifulsoup4`
            4. ëŒ€ì‹œë³´ë“œ ì¬ì‹œì‘
            """)
        
        # í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ UI
        st.sidebar.subheader("ğŸ¤– GPT í”„ë¡¬í”„íŠ¸ ê´€ë¦¬")
        
        if PROMPT_MANAGER_AVAILABLE:
            st.sidebar.success("âœ… í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € í™œì„±í™”")
            
            try:
                prompt_manager = get_prompt_manager()
                prompt_info = prompt_manager.get_prompt_info()
                
                # í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì •ë³´ í‘œì‹œ
                st.sidebar.info(f"""
                **ğŸ“Š í”„ë¡¬í”„íŠ¸ í˜„í™©**
                - í˜„ì¬ ë‚ ì§œ: {prompt_info['market_context']['current_date']}
                - ì‹œì¥ ë‹¨ê³„: {prompt_info['market_context']['market_phase']}
                - ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸: {len(prompt_info['available_prompt_types'])}ê°œ
                - ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {prompt_info['last_updated'][:19]}
                """)
                
                # ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë²„íŠ¼
                if st.sidebar.button("ğŸ”„ ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸", key="update_market_context_btn", help="í˜„ì¬ ì‹œì¥ ìƒí™©ì„ ë°˜ì˜í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤"):
                    prompt_manager.update_market_context()
                    st.success("âœ… ì‹œì¥ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                    st.rerun()
                
                # í”„ë¡¬í”„íŠ¸ ì„¤ì • ì •ë³´
                with st.sidebar.expander("âš™ï¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •"):
                    st.text(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ë””ë ‰í† ë¦¬: {prompt_info['prompts_directory']}")
                    st.text(f"ğŸ“Š ì£¼ìš” ìš°ë ¤ì‚¬í•­: {', '.join(prompt_info['market_context']['key_concerns'][:3])}...")
                    st.text(f"ğŸ² ì‹œë‚˜ë¦¬ì˜¤ í™•ë¥ : ë‚™ê´€ {prompt_info['market_context']['scenario_probabilities']['optimistic']*100:.0%}, ê¸°ë³¸ {prompt_info['market_context']['scenario_probabilities']['baseline']*100:.0%}, ë¹„ê´€ {prompt_info['market_context']['scenario_probabilities']['pessimistic']*100:.0%}")
                
                # ì‹œì¥ íŠ¸ë Œë“œ ì •ë³´
                with st.sidebar.expander("ğŸ“ˆ ì‹œì¥ íŠ¸ë Œë“œ"):
                    for trend in prompt_info['market_context']['industry_trends']:
                        st.text(f"â€¢ {trend}")
                
            except Exception as e:
                st.sidebar.error(f"í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì˜¤ë¥˜: {e}")
        else:
            st.sidebar.error("âŒ í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ë¹„í™œì„±í™”")
            st.sidebar.info("""
            **í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € í™œì„±í™” ë°©ë²•:**
            1. `config/prompts.py` íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            2. Python ê²½ë¡œ ì„¤ì • í™•ì¸
            3. ëŒ€ì‹œë³´ë“œ ì¬ì‹œì‘
            """)
        
        # Main content
        if not MODEL_AVAILABLE:
            st.error("âŒ Model modules are not available. Please check your installation.")
            return
        
        if not st.session_state.models_loaded_status or self.risk_scorer is None:
            st.info("ğŸ’¡ Please enable models using the checkbox in the sidebar to start analysis.")
            return
        
        # Get current data
        firms = self.get_sample_firms()
        
        with st.spinner("ğŸ“Š Calculating current risk scores..."):
            risk_df = self.calculate_current_risks(firms)
        
        if risk_df.empty:
            st.error("âŒ No risk data available")
            return
        
        # Key metrics row
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_risk = risk_df['overall_risk'].mean()
            st.metric("ğŸ“Š Average Risk", f"{avg_risk:.1%}")
        
        with col2:
            high_risk_count = len(risk_df[risk_df['overall_risk'] > RISK_THRESHOLD])
            st.metric("âš ï¸ High Risk Firms", high_risk_count)
        
        with col3:
            max_risk_firm = risk_df.loc[risk_df['overall_risk'].idxmax(), 'company_name']
            max_risk_value = risk_df['overall_risk'].max()
            st.metric("ğŸ”¥ Highest Risk", f"{max_risk_firm}", f"{max_risk_value:.1%}")
        
        with col4:
            last_update = datetime.now().strftime("%H:%M:%S")
            st.metric("ğŸ• Last Update", last_update)
        
        st.markdown("---")
        
        # Tab interface
        tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ˆ Hazard Curves", "ğŸ“‹ Risk Table", "ğŸ”¥ Heatmap", "ğŸš¨ Alerts", "ğŸ“Š ì¢…í•©ë¦¬í¬íŠ¸"])
        
        with tab1:
            # Company selection
            company_names = [firm.company_name for firm in firms]
            selected_companies = st.multiselect(
                "âœˆï¸ Select Airlines to Display",
                options=company_names,
                default=company_names,  # All companies selected by default
                help="Choose which airlines to show in the hazard curves",
                key="hazard_companies_multiselect"
            )
            
            if selected_companies:
                # Filter firms based on selection
                selected_firms = [firm for firm in firms if firm.company_name in selected_companies]
                
                with st.spinner("Generating hazard curves..."):
                    hazard_fig = self.generate_hazard_curves(selected_firms)
                
                st.plotly_chart(hazard_fig, use_container_width=True)
            else:
                st.warning("âš ï¸ Please select at least one airline to display hazard curves.")
            
            # Interpretation
            st.info("""
            **ğŸ“Š How to read the curves:**
            - **Overall Risk**: Probability of any rating change
            - **Upgrade Probability**: Chance of rating improvement  
            - **Downgrade Probability**: Risk of rating deterioration
            - **Default Risk**: Probability of default event
            """)
        
        with tab2:
            # Company selection for risk table
            table_companies = st.multiselect(
                "âœˆï¸ Select Airlines for Risk Table",
                options=company_names,
                default=company_names,  # All companies selected by default
                help="Choose which airlines to include in the risk table",
                key="table_selection"
            )
            
            if table_companies:
                # Filter and sort by overall risk (descending)
                filtered_table_df = risk_df[risk_df['company_name'].isin(table_companies)]
                risk_df_sorted = filtered_table_df.sort_values('overall_risk', ascending=False)
            else:
                st.warning("âš ï¸ Please select at least one airline for the risk table.")
                return
            
            # Style the dataframe
            def style_risk_table(df):
                def highlight_risk(val):
                    if val > RISK_THRESHOLD:
                        return 'background-color: #ffcccc; font-weight: bold'
                    elif val > RISK_THRESHOLD * 0.7:
                        return 'background-color: #fff2cc'
                    return ''
                
                return df.style.map(highlight_risk, subset=['overall_risk', 'downgrade_prob'])
            
            # Display table
            st.dataframe(
                style_risk_table(risk_df_sorted),
                use_container_width=True,
                column_config={
                    "overall_risk": st.column_config.ProgressColumn(
                        "Overall Risk",
                        help="90-day rating change probability",
                        min_value=0,
                        max_value=0.5,
                        format="%.3f"
                    ),
                    "upgrade_prob": st.column_config.ProgressColumn(
                        "Upgrade â†—ï¸",
                        min_value=0,
                        max_value=0.3,
                        format="%.3f"
                    ),
                    "downgrade_prob": st.column_config.ProgressColumn(
                        "Downgrade â†˜ï¸",
                        min_value=0,
                        max_value=0.3,
                        format="%.3f"
                    ),
                    "default_prob": st.column_config.ProgressColumn(
                        "Default âŒ",
                        min_value=0,
                        max_value=0.1,
                        format="%.3f"
                    )
                }
            )
            
            # Export functionality
            csv = risk_df_sorted.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ Download CSV",
                data=csv,
                file_name=f"korean_airlines_risk_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
        
        with tab3:
            # Company selection for heatmap
            heatmap_companies = st.multiselect(
                "âœˆï¸ Select Airlines for Heatmap",
                options=company_names,
                default=company_names,  # All companies selected by default
                help="Choose which airlines to include in the heatmap",
                key="heatmap_selection"
            )
            
            if heatmap_companies:
                # Filter risk data based on selection
                filtered_risk_df = risk_df[risk_df['company_name'].isin(heatmap_companies)]
                heatmap_fig = self.create_risk_heatmap(filtered_risk_df)
                st.plotly_chart(heatmap_fig, use_container_width=True)
            else:
                st.warning("âš ï¸ Please select at least one airline for the heatmap.")
            
            # Risk distribution chart
            st.subheader("ğŸ“Š Risk Distribution")
            
            fig_dist = px.histogram(
                risk_df, 
                x='overall_risk', 
                nbins=10,
                title="Distribution of 90-Day Risk Scores",
                labels={'overall_risk': 'Risk Probability', 'count': 'Number of Firms'}
            )
            fig_dist.add_vline(x=RISK_THRESHOLD, line_dash="dash", line_color="red", 
                              annotation_text=f"Alert Threshold ({RISK_THRESHOLD:.1%})")
            
            st.plotly_chart(fig_dist, use_container_width=True)
        
        with tab4:
            # High risk firms
            high_risk_firms = risk_df[risk_df['overall_risk'] > RISK_THRESHOLD]
            
            if not high_risk_firms.empty:
                st.error(f"âš ï¸ {len(high_risk_firms)} firms exceed risk threshold ({RISK_THRESHOLD:.1%})")
                
                # Send alert button
                if st.button("ğŸ“± Send Slack Alert", key="send_slack_alert_btn"):
                    self.send_slack_alert(high_risk_firms)
                
                # Display high risk firms
                st.dataframe(high_risk_firms, use_container_width=True)
                
            else:
                st.success("âœ… No firms currently exceed the risk threshold")
            
            # Alert history
            st.subheader("ğŸ“œ Alert History")
            
            if st.session_state.alert_history:
                for i, alert in enumerate(reversed(st.session_state.alert_history[-5:])):  # Last 5 alerts
                    with st.expander(f"Alert {len(st.session_state.alert_history)-i}: {alert['timestamp'].strftime('%Y-%m-%d %H:%M')}"):
                        st.write(f"**Firms:** {', '.join(alert['firms'])}")
                        st.text(alert['message'])
            else:
                st.info("No alerts sent yet")
        
        with tab5:
            st.markdown("### ğŸ¯ ì¢…í•© ìœ„í—˜ ë¶„ì„ ë¦¬í¬íŠ¸")
            st.markdown("*í•œêµ­ í•­ê³µì—…ê³„ ì‹ ìš©ìœ„í—˜ ì¢…í•© í‰ê°€ ë° ëŒ€ì¶œ ê¶Œê³ ì‚¬í•­*")
            
            # í•­ê³µì‚¬ ì„ íƒ ì²´í¬ë°•ìŠ¤
            st.markdown("#### âœˆï¸ ë¶„ì„ ëŒ€ìƒ í•­ê³µì‚¬ ì„ íƒ")
            st.info("ğŸ’¡ ë¦¬í¬íŠ¸ ìƒì„± ì „ì— ë¶„ì„í•  í•­ê³µì‚¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”. (ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒ í•„ìˆ˜)")
            
            # ì²´í¬ë°•ìŠ¤ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜
            col1, col2, col3, col4, col5 = st.columns(5)
            
            selected_airlines = []
            with col1:
                if st.checkbox("ëŒ€í•œí•­ê³µ", key="report_kal", value=True):
                    selected_airlines.append("ëŒ€í•œí•­ê³µ")
            with col2:
                if st.checkbox("ì•„ì‹œì•„ë‚˜í•­ê³µ", key="report_asiana", value=True):
                    selected_airlines.append("ì•„ì‹œì•„ë‚˜í•­ê³µ")
            with col3:
                if st.checkbox("ì œì£¼í•­ê³µ", key="report_jeju", value=True):
                    selected_airlines.append("ì œì£¼í•­ê³µ")
            with col4:
                if st.checkbox("í‹°ì›¨ì´í•­ê³µ", key="report_tway", value=True):
                    selected_airlines.append("í‹°ì›¨ì´í•­ê³µ")
            with col5:
                if st.checkbox("ì—ì–´ë¶€ì‚°", key="report_airbusan", value=True):  
                    selected_airlines.append("ì—ì–´ë¶€ì‚°")
            
            # ì„ íƒëœ í•­ê³µì‚¬ í‘œì‹œ
            if selected_airlines:
                st.success(f"âœ… ì„ íƒëœ í•­ê³µì‚¬: {', '.join(selected_airlines)} ({len(selected_airlines)}ê°œ)")
            else:
                st.warning("âš ï¸ ë¶„ì„í•  í•­ê³µì‚¬ë¥¼ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
            
            # ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ (ì„ íƒëœ í•­ê³µì‚¬ê°€ ìˆì„ ë•Œë§Œ í™œì„±í™”)
            if selected_airlines:
                if st.button("ğŸ“‹ ì¢…í•©ë¦¬í¬íŠ¸ ìƒì„±í•˜ê¸°", key="comprehensive_report_btn", type="primary"):
                    # ì„ íƒëœ í•­ê³µì‚¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
                    selected_risk_df = risk_df[risk_df['company_name'].isin(selected_airlines)]
                    selected_firms = [firm for firm in firms if firm.company_name in selected_airlines]
                    
                    with st.spinner("ğŸ§  AIê°€ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                        comprehensive_report = self.generate_comprehensive_report(selected_risk_df, selected_firms)
                        st.session_state.comprehensive_report = comprehensive_report
                        st.session_state.last_selected_airlines = selected_airlines.copy()
                        
                    # ì„ íƒëœ í•­ê³µì‚¬ í™•ì¸ ë©”ì‹œì§€ ì¶”ê°€
                    st.info(f"ğŸ“Š ë¶„ì„ ì™„ë£Œ: {', '.join(selected_airlines)} ({len(selected_airlines)}ê°œ í•­ëª© ê¸°ì¤€ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„±)")
            else:
                st.button("ğŸ“‹ ì¢…í•©ë¦¬í¬íŠ¸ ìƒì„±í•˜ê¸°", key="comprehensive_report_btn_disabled", disabled=True, help="í•­ê³µì‚¬ë¥¼ ì„ íƒí•œ í›„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # ë¦¬í¬íŠ¸ í‘œì‹œ
            if 'comprehensive_report' in st.session_state and st.session_state.comprehensive_report:
                st.markdown("---")
                
                # ë¶„ì„ ëŒ€ìƒ í•­ê³µì‚¬ í‘œì‹œ
                if 'last_selected_airlines' in st.session_state:
                    selected_count = len(st.session_state.last_selected_airlines)
                    st.success(f"ğŸ¯ **ë¶„ì„ ëŒ€ìƒ**: {', '.join(st.session_state.last_selected_airlines)} (ì´ {selected_count}ê°œ í•­ê³µì‚¬)")
                
                st.markdown(st.session_state.comprehensive_report, unsafe_allow_html=True)
                
                # ë¦¬í¬íŠ¸ ì§€ìš°ê¸° ë²„íŠ¼
                if st.button("ğŸ—‘ï¸ ë¦¬í¬íŠ¸ ì§€ìš°ê¸°", key="clear_comprehensive_report"):
                    st.session_state.comprehensive_report = None
                    st.rerun()
            else:
                st.info("ğŸ’¡ ì¢…í•©ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ë ¤ë©´ ìœ„ì˜ ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”.")
        
        # Footer
        st.markdown("---")
        
        # Show data source information
        try:
            # Try different import paths for config
            try:
                from config.config import USE_REAL_DATA
            except ImportError:
                from config import USE_REAL_DATA
            data_source = "ğŸ¯ Real DART Financial Data" if USE_REAL_DATA else "âš¡ Fast Dummy Data (Development Mode)"
        except ImportError:
            data_source = "âš¡ Fast Dummy Data (Development Mode)"
        
        st.markdown(f"""
        **ğŸ¢ Korean Airlines Credit Risk Dashboard** | 
        Data refreshed: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} | 
        Model: Multi-State Hazard with Financial Covariates | 
        Source: {data_source}
        """)

def main():
    """Main application entry point"""
    # Create dashboard instance only once per session  
    if 'dashboard_instance' not in st.session_state:
        st.session_state.dashboard_instance = CreditRatingDashboard()
    
    st.session_state.dashboard_instance.run_dashboard()

if __name__ == "__main__":
    main() 